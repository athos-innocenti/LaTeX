\documentclass[10pt, a4paper]{report}
\usepackage[italian]{babel}
\usepackage{amsmath, amsfonts, amssymb, amsthm}
%\renewcommand\qedsymbol{$\blacksquare$}
\newtheorem{lemma}{Lemma}[chapter]
\newtheorem{theorem}{Teorema}[chapter]
\newtheorem{corollario}{Corollario}[chapter]
\newcommand\firsttab[1][0.5cm]{\hspace*{#1}}
\newcommand\secondtab[1][1cm]{\hspace*{#1}}
\newcommand\thirdtab[1][1.5cm]{\hspace*{#1}}
\newcommand\fourthtab[1][2cm]{\hspace*{#1}}
\newcommand\fifthtab[1][2.5cm]{\hspace*{#1}}
\begin{document}
\title{\Huge Algoritmi e Strutture Dati}\date{}
\maketitle
\tableofcontents
\chapter{Introduzione}
\section{Algoritmi}
Un \textbf{algoritmo} è una procedura di calcolo ben definita che prende un valore, o un insieme di valori, come \textbf{input} e genera un valore, o un insieme di valori, come \textbf{output}. Un algoritmo  è quindi una sequenza di passi computazionali che trasforma l'input in output e che risolve un \textbf{problema computazionale}  ben definito per ogni possibile istanza di input.

La descrizione di un problema computazionale specifica in termini generali la \textbf{relazione di ingresso/uscita} desiderata. L'algoritmo, quindi, descrive un modo per ottenere tale relazione.

Un algoritmo si dice \textbf{corretto} se, per ogni istanza di input, termina con l'output corretto. Si dice che un algoritmo  corretto \textbf{risolve} un problema computazionale  dato.
\section{Strutture dati}
Una \textbf{struttura dati} è un modo per memorizzare e organizzare i dati e semplificarne l'accesso e la modifica. Dunque consente un' organizzazione in memoria dei dati ed è caratterizzata da un insieme di operatori utilizzabili per:
\begin{itemize}
\item Manipolare la struttura. Quindi consentire operazioni come: aggiungere, rimuovere, modificare elementi e modificare la struttura stessa.
\item Accedere alla struttura per esempio per leggere o cercare elementi.
\end{itemize}
Tra le strutture dati elementari ci sono: il \textbf{vettore di memoria} (memorizza elementi dello stesso tipo), gli  \textbf{array} (vettori su più dimensioni) e i \textbf{record} (elementi di tipo diverso con nome proprio di cui non importa la posizione).\\Una possibile implementazione degli array è la memorizzazione standard per righe attraverso la quale, data la matrice \textit{A}[\textit{R}][\textit{C}], il generico elemento \textit{A}[\textit{i}][\textit{j}] è memorizzato in \textit{i} $\cdot$ C + \textit{j}. Se invece molti elementi sono nulli è più conveniente utilizzare le matrici sparse in cui si memorizzano le triplette (\textit{i},\,\textit{j},\,\textit{val}) per i soli elementi \textit{A}[\textit{i}][\textit{j}]\,$\neq$\,0. Nel primo caso, cioè se una matrice viene rappresentata per righe (o colonne), un matrice di n $\times$ n interi da 4 byte occupa $4 \cdot n^2$\,byte; se invece viene memorizzata come matrice sparsa contenente \textit{v} valori diversi da zero occupa $v \cdot 3 \cdot 4$ byte. In realtà se \textit{i} e \textit{j} sono grandi serviranno più di 4 byte. Le triplette vengono memorizzate con il dizionario.

Vi sono poi altre strutture dati più avanzate come gli \textbf{insiemi}, la \textbf{pila\,(stack)} e  la \textbf{coda}, il \textbf{dizionario} (implementabile come un array ordinato o un array non ordinato mantenuto con la tecnica del raddoppiamento-dimezzamento, consente operazioni quali inserimento, cancellazione e verifica dell'appartenenza di un elemento a un certo insieme) e il \textbf{grafo}. 

Negli \textbf{insiemi} ogni elemento è rappresentato da un oggetto i cui attributi possono essere esaminati e manipolati e può contenere \textbf{attributi} e \textbf{dati satelliti}. Per alcuni tipi di insiemi dinamici si suppone che uno degli attributi dell'oggetto sia una \textbf{chiave} di identificazione. In informatica, a differenza dell'insieme matematico che è immutabile, un insieme manipolato da un algoritmo è una entità \textbf{dinamica} che cresce, si riduce, cambia nel tempo e che può avere elementi uguali tra loro (non a caso viene detto \textbf{insieme dinamico}). Si distinguono insiemi ordinati (sequenza) e insiemi dinamici. Possono essere realizzati con vettori booleani, con liste non ordinate o con liste ordinate. I vettori booleani sono semplici ed efficienti per le operazioni di unione, intersezione e per verificare se un elemento appartiene all'insieme, tuttavia hanno lo svantaggio di avere molte operazioni inefficienti e un'occupazione di memoria indipendente dalla dimensione dell'insieme. Le liste non ordinate hanno il vantaggio di un'occupazione di memoria proporzionale alla dimensione dell'insieme e di avere efficienti operazioni di inserimento sia in testa che in coda (questo è dovuto al fatto che la lista non è ordinata). Gli svantaggi sono invece legati alle operazioni di ricerca e cancellazione (perché si deve scorrere la lista per trovare ed eliminare un elemento) nonché alle operazioni insiemistiche di unione, intersezione e differenza. Infine le liste ordinate hanno come vantaggi l'occupazione di memoria proporzionale alla dimensione dell'insieme (come per le liste non ordinate) e le operazioni di unione, intersezione e differenza mentre hanno come svantaggi la ricerca, l'inserimento e la cancellazione.

Una \textbf{stringa} è un tipo particolare di insieme ordinato contenente caratteri alfanumerici sulla quale possono essere eseguite operazioni specifiche e che può avere diverse implementazioni
\begin{itemize}
\item Terminare con \textsc{null}, come in C\\Ma in questo caso non si potrebbe rappresentare \textsc{null} stesso
\item Indicando prima la lunghezza, come in Pascal\\Questa implementazione ha la limitazione nel numero che codifica la lunghezza della stringa
\item Con lunghezza fissa\\In questo caso si ha il vantaggio di poter eseguire un accesso diretto
\end{itemize}

Lo \textbf{stack} e le \textbf{code} sono insiemi dinamici dove l'elemento che viene rimosso dall'operazione \textsc{Delete} è predeterminato; questo perché lo stack segue una politica LIFO (l'elemento cancellato è quello inserito per ultimo) e la coda una politica FIFO (l'elemento cancellato è quello inserito per primo). Possono essere implementate come liste bidirezionali, vettori o array circolari.

Un \textbf{dizionario\,(Map)} è una relazione univoca che associa ad ogni elemento di un insieme A un solo elemento di un insieme B ma non viceversa. In particolare, è un insieme S di coppie (\textit{chiave}\,,\,\textit{valore}) caratterizzato da:
\begin{itemize}
\item Una relazione \textit{R} : \textit{D} $\rightarrow$ \textit{C}
\item  Un dominio \textit{D} rappresentante le chiavi
\item Un codominio \textit{C} rappresentante i valori
\end{itemize}

I \textbf{grafi} e \textbf{alberi}, infine, sono una rappresentazione grafica di una interrelazione tra oggetti. Un grafo è un insieme di nodi e archi che connettono i nodi. Può essere rappresentato attraverso la lista degli archi, le liste di adiacenza o incidenza, le matrici di adiacenza o incidenza ecc. Su tale struttura dati è possibile eseguire molteplici operazioni tra cui la visita. Un albero ordinato è un caso particolare di grafo (grafo non orientato connesso e aciclico) formato da un insieme finito di elementi detti \textbf{nodi} tra i quali uno è designato come \textbf{radice} mentre i rimanenti sono partizionati in insiemi ordinati e disgiunti, anch'essi alberi ordinati.
\section{Dati}
Un \textbf{dato} è un valore che una variabile può assumere.\\Un \textbf{tipo di dato} è invece un modello matematico costituito da:
\begin{itemize}
\item Un insieme di valori
\item Un insieme di operazioni ammesse su tali valori
\end{itemize}
La specifica nasconde dettagli implementativi.
\chapter{Insertion sort}
\section{Il problema dell'ordinamento}
Il problema dell'ordinamento è un particolare problema che riceve in \textbf{input} una sequenza di n numeri $< a_1,a_2,a_3, ...\, , a_n >$ e restituisce come \textbf{output} una permutazione (riarrangiamento) $< a'_1,a'_2,a'_3, ...\, , a'_n >$ della sequenza di input tale che\,: $a'_1 \leq a'_2 \leq ... \leq a'_n$.\\La sequenza di input è detta \textbf{istanza} del problema dell'ordinamento; mentre i numeri da ordinare sono detti \textbf{chiavi}.\\In generale, l'\textbf{istanza di un problema} è formata dall'input (che soddisfa tutti i vincoli imposti nella definizione del problema) richiesto per calcolare una soluzione del problema.

La scelta dell'algoritmo più appropriato a una data applicazione dipende dal numero di elementi da ordinare, dal livello di ordinamento iniziale degli elementi, da eventuali vincoli sui valori degli elementi, dall'architettura del calcolatore e così via.
\section{L'algoritmo Insertion sort}
\textsc{Insertion-Sort} risolve il problema dell'ordinamento ed è un algoritmo efficiente per ordinare pochi elementi.

Opera nella stesso modo in cui si ordinano le carte da gioco: partendo con una mano vuota si prende via via una carta per volta dal tavolo e la si inserisce nella posizione corretta. Per trovare la posizione corretta di una carta la si confronta con le singole carte già ordinate in mano, da destra verso sinistra. In qualsiasi momento le carte tenute in mano sono ordinate; originariamente queste carte erano le prime della pila di carte da cui sono state estratte.

\textsc{Insertion-Sort} prende come parametro in input un array A[1\,...\,\textit{n}] contenente una sequenza di lunghezza n che deve essere ordinata (nel codice il numero \textit{n} di elementi di A è indicato con \textit{A.length}). L'algoritmo ordina i numeri di input \textbf{sul posto}: i numeri sono risistemati all'interno dell'array A avendo, in ogni istante, al più un numero costante di essi memorizzati all'esterno dell'array. Quando la procedura \textsc{Insertion-Sort}  è completata, l'array di input \textit{A} contiene la sequenza di output ordinata. Tramite un indice \textit{j} si indicherà l'elemento corrente che viene ordinato.\\\\
\textsc{Insertion-Sort(\textit{A})}\\
1\firsttab \textbf{for} \textit{j}  $\leftarrow$ 2 \textbf{to} \textit{A.length}\\
2\secondtab \textit{key} $\leftarrow$ \textit{A}[\textit{j}]\\
3\secondtab// Inserisce \textit{A}[\textit{j}] nella sequenza ordinata \textit{A}[1\,...\,\textit{j}\,-\,1]\\
4\secondtab \textit{i}  $\leftarrow$ \textit{j}  - 1\\
5\secondtab \textbf{while} \textit{i}  $>$ 0 and \textit{A}[\textit{i}] $>$ \textit{key}\\
6\thirdtab \textit{A}[\textit{i}\,+\,1] $\leftarrow$ \textit{A}[\textit{i}]\\
7\thirdtab \textit{i}  $\leftarrow$ \textit{i}  - 1\\
8\secondtab \textit{A}[\textit{i}\,+\,1] $\leftarrow$ \textit{key}\\\\
Commenti:
\begin{enumerate}
\item[1]Cicla su \textit{j} per scegliere la chiave da ordinare. Si parte dal secondo elemento supponendo che il $1^o$ sia già ordinato (cioè \textit{A}[1] ordinato). All'inizio di ogni iterazione del ciclo \textbf{for}, il cui indice è \textit{j}, il sottoarray che è formato dagli elementi \textit{A}[1\,...\,\textit{j}\,-\,1] costituisce il sottoinsieme di elementi già ordinati e gli elementi \textit{A}[\textit{j}\,+\,1\,...\,\textit{n}] corrispondono invece a tutti quegli elementi che devono ancora essere ordinati. Inoltre gli elementi \textit{A}[1\,...\,\textit{j}\,-\,1] sono quelli che originariamente occupavano le posizioni da 1 a \textit{j}\,-\,1, ma adesso sono ordinati
\item[2]All'inizio \textit{A}[2] = \textit{key}
\item[4]\textit{j} - 1 è l'ultimo elemento ordinato
\item[5\,-\,7]Cicla su \textit{i} per trovare la posizione giusta, sposta l'elemento \textit{j}-esimo nel posto giusto scambiando \textit{A}[\textit{i}\,+\,1] e \textit{A}[\textit{i}] se quello a sinistra è più grande. Sposta gli elementi più grandi di quello valutato nello stesso ordine in cui sono collocati
\end{enumerate}
\section{Correttezza}
Un algoritmo si dice \textbf{corretto} se, per ogni istanza di input, termina con l'output corretto.

Per algoritmi \textbf{iterativi} si usa spesso un' \textbf{invariante di ciclo}, ovvero una proposizione che vale prima, durante e alla fine di un ciclo. Nel caso di \textsc{Insertion-Sort} l'invariante di ciclo è la seguente:
\begin{quote}
\textit{All'inizio di ogni iterazione del ciclo for (righe 1\,-\,8)  il sottoarray $A[1\,...\,j\,-\,1]$ è ordinato ed è formato dagli stessi elementi che erano originariamente in $A[1\,...\,j\,-\,1]$  ma ordinati}
\end{quote}
Per verificare la correttezza di un algoritmo iterativo sfruttando l'invariante di ciclo bisogna dimostrare che tale invariante valga in tre casi:
\begin{description}
\item[Inizializzazione]È vera prima della prima iterazione del ciclo
\item[Conservazione]Se è vera prima di un'iterazione del ciclo, rimane vera prima della successiva iterazione
\item[Conclusione]Quando il ciclo termina, l'invariante fornisce una proprietà utile per mostrare che l'algoritmo è corretto
\end{description}
Quando le prime due proprietà sono valide, l'invariante di ciclo è vera prima di ogni iterazione del ciclo. Si nota un'analogia con l'induzione matematica dove, per verificare che una proprietà è valida, si prova un caso base e un passo induttivo. Caso base e passo induttivo corrispondono ad inizializzazione e conservazione, la conclusione è invece diversa perché nell'induzione matematica il passo induttivo è usato all'infinito mentre nell'invariante di ciclo si termina l'induzione quando il ciclo in esame termina.

Analizzando \textsc{Insertion-Sort} si verificano i tre casi dell'invariante di ciclo:
\begin{description}
\item[Inizializzazione]Prima della prima iterazione del ciclo, quando \textit{j} = 2, il sottoarray  \textit{A}[1\,...\,\textit{j}\,-\,1] è formato dal solo elemento \textit{A}[1], che infatti è l'elemento originale in \textit{A}[1]. Inoltre, questo sottoarray è ordinato (ovviamente) e ciò dimostra che l'invariante di ciclo è vera prima della prima iterazione del ciclo
\item[Conservazione]Il ciclo \textbf{for} esterno opera spostando \textit{A}[\textit{j}\,-\,1], \textit{A}[\textit{j}\,-\,2], \textit{A}[\textit{j}\,-\,3] e così via di una posizione verso destra, finché non troverà la posizione appropriata per \textit{A}[\textit{j}] (righe 4\,-\,7), dove inserirà il valore di \textit{A}[\textit{j}] (riga 8). Il sottoarray \textit{A}[1\,...\,\textit{j}] quindi è ordinato ed è formato dagli stessi elementi che originariamente erano in \textit{A}[1\,...\,\textit{j}]. Dunque l'incremento di \textit{j} per la successiva iterazione del ciclo for preserva l'invariante di ciclo
\item[Conclusione]La condizione che determina la conclusione del ciclo for è $ \textit{j} > A.\textit{length}  = \textit{n}$. Poiché ogni iterazione del ciclo aumenta \textit{j} di 1, alla fine del ciclo si avrà \textit{j} = \textit{n} + 1. Sostituendo \textit{j} con \textit{n} + 1 nella formulazione dell'invariante di ciclo, si ottiene che il sottoarray \textit{A}[1\,...\,\textit{n}] è formato dagli elementi \textbf{ordinati} che si trovavano originariamente in \textit{A}[1\,...\,\textit{n}]. Ma il sottoarray \textit{A}[1\,...\,\textit{n}] è l'intero array e dunque tutto l'array è ordinato.
\end{description}
Pertanto l'algoritmo è \textbf{corretto}.
\section{Analisi degli algoritmi}
Analizzare un algoritmo significa prevedere le risorse che l'algoritmo richiede. Raramente sono di primaria importanza risorse come la memoria, la larghezza di banda nelle comunicazioni o l'hardware nei computer, mentre più frequentemente è più importante misurare il \textbf{tempo di elaborazione}. Prima di analizzare un algoritmo, bisogna avere un modello della tecnologia di implementazione che sarà utilizzata, incluso un modello per le risorse di tale tecnologia e dei loro costi. Nella maggior parte dei casi si considera come tecnologia di implementazione un generico modello di calcolo a un processore che viene chiamato \textbf{random-access machine\,(RAM)}. In tale modello le istruzioni sono eseguite una dopo l'altra, senza operazioni contemporanee. Il modello RAM dispone di istruzioni comuni eseguite in tempo costante (no sort), ha una quantità infinita di celle di memoria di dimensione finita, consente un accesso in memoria in tempo costante e rappresenta i dati con parole di dimensioni limitate.

In generale, il tempo richiesto da un algoritmo cresce con la dimensione dell'input, quindi è tradizione descrivere il tempo di esecuzione di un programma come una funzione della dimensione del suo input.

La definizione migliore della \textbf{dimensione dell'input} dipende dal problema che si sta studiando. Per la maggior parte dei problemi, come l'ordinamento, la misura più naturale è il numero di elementi dell'input.

Il \textbf{tempo di esecuzione} di un algoritmo per un particolare input è il numero di operazioni primitive (o passi) che vengono eseguite. Per eseguire una riga dello pseudocodice occorre una quantità costante di tempo. Una riga può richiedere una quantità di tempo diversa da un'altra riga, tuttavia si supporrà che ogni esecuzione dell'\textit{i}-esima riga richieda un tempo $\textit{c}_i$, dove $\textit{c}_i$ è una costante.
\subsection{Analisi di Insertion sort}
Il tempo richiesto dalla procedura \textsc{Insertion-Sort} dipende dall'input, in particolare dalla sua dimensione. Inoltre può richiedere quantità di tempo differenti per ordinare due sequenze di input della stessa dimensione a seconda di come gli elementi siano già ordinati.\\\\
\textsc{Insertion-Sort(\textit{A})}\\
\begin{tabular}{lcl}
\em  & Costo & Numero di volte \\
1\firsttab \textbf{for} \textit{j}  $\leftarrow$ 2 \textbf{to} \textit{A.length} & $c_1$ & \textit{n} \\
2\secondtab \textit{key} $\leftarrow$ \textit{A}[\textit{j}] &$c_2$ &\textit{n}\,-\,1 \\
3\secondtab// Inserisce \textit{A}[\textit{j}] nella sequenza ordinata \textit{A}[1\,...\,\textit{j}\,-\,1] &$0$ &\textit{n}\,-\,1\\
4\secondtab \textit{i}  $\leftarrow$ \textit{j}  - 1 &$c_4$ &\textit{n}\,-\,1\\
5\secondtab \textbf{while} \textit{i}  $>$ 0 and \textit{A}[\textit{i}] $>$ \textit{key} &$c_5$ &$\sum_{j=2}^{n} t_j$\\
6\thirdtab \textit{A}[\textit{i}\,+\,1] $\leftarrow$ A[\textit{i}] &$c_6$ &$\sum_{j=2}^{n} (t_j\,-\,1)$\\
7\thirdtab \textit{i}  $\leftarrow$ \textit{i}  - 1 &$c_7$ &$\sum_{j=2}^{n} (t_j\,-\,1)$\\
8\secondtab \textit{A}[\textit{i}\,+\,1] $\leftarrow$ \textit{key} &$c_8$ &\textit{n}\,-\,1
\end{tabular}
\\\\\\Commenti:
\begin{enumerate}
\item[2-4]Eseguite \textit{n}\,-\,1 volte perché non si considera \textit{A}[1]
\item[5]$t_j$ indica il numero di volte che si entra nel ciclo while ovvero il numero di volte che viene eseguito il test del while
\item[5-7]Si utilizza la sommatoria perché il ciclo dipende dai dati (dai valori in input)
\end{enumerate}

Il tempo di esecuzione dell'algoritmo è la somma dei tempi di esecuzione per ogni istruzione eseguita; un'istruzione che richiede $c_i$ passi e viene eseguita \textit{n} volte contribuirà con $c_i\cdot n$ al tempo di esecuzione totale.
\begin{equation*}
costo\;= \sum_{istruzioni} c_i \cdot (volte\,che\,viene\,eseguita)
\end{equation*}
Per calcolare\,\textit{T}(\textit{n}), il tempo di esecuzione di \textsc{Insertion-Sort} con un input di \textit{n} valori, si sommano i prodotti delle colonne costo e numero di volte, ottenendo:
\begin{equation*}
T(n) = c_1n \,+\, c_2(n-1) \,+\, c_4(n-1) \,+\, c_5 \sum_{j=2}^{n} t_j \,+\, c_6\sum_{j=2}^{n} (t_j - 1) \,+\, c_7\sum_{j=2}^{n} (t_j - 1) \,+\, c_8(n-1)
\end{equation*}
\textit{T}(\textit{n}) dipende da $t_j$ che dipende dai valori in input.

In \textsc{Insertion-Sort} il caso migliore si verifica quando l'array è già ordinato. Per ogni \textit{j} = 2,\,3,\,...\,, \textit{n}, si verifica che nella riga 5 \textit{A}[\textit{i}] $\leq$ \textit{key}, quando \textit{i} ha il suo valore iniziale \textit{j} - 1. Quindi $t_j$ = 1 per \textit{j} = 2,\,3,\,...\,, \textit{n} e il tempo di esecuzione nel caso migliore è (non si entra mai nel while quindi $c_6 = c_7 = 0$):
\begin{equation*}
\begin{aligned}
T(n) &= c_1n + c_2(n-1) + c_4(n-1) + c_5(n-1) + c_8(n-1) \\
&= (c_1 + c_2 + c_4 + c_5 + c_8)n - (c_2 + c_4 + c_5 + c_8) \\
\end{aligned}
\end{equation*}
Dunque il tempo di esecuzione nel caso migliore di \textsc{Insertion-Sort} può essere espresso come $T(n) = an + b$, con le costanti \textit{a} e \textit{b} che dipendono dai costi  $c_i$ delle istruzioni; quindi è una funzione lineare di \textit{n} con \textit{b} che all'infinito diventa irrilevante.

Se l'array è ordinato in senso inverso - cioè in ordine decrescente, per cui si verifica sempre $A[\textit{i}] > \textit{key}$\;- allora si verifica il caso peggiore. Si dovrà confrontare \textit{A}[\textit{j}], cioè \textit{key}, con ogni elemento dell'intero sottoarray ordinato \textit{A}[1\,...\,\textit{j}\,-\,1] ovvero con tutti i \textit{j} - 1 elementi alla sinistra di \textit{j} e quindi $t_j$ = \textit{j} per \textit{j} = 2,\,3,\,...\,, \textit{n}. Poiché
\begin{equation*}
\sum_{j=2}^{n} t_j = \sum_{j=2}^{n} j = \Biggl(\,\sum_{j=1}^{n} j\Biggr) - 1 =  \frac{n(n+1)}{2} - 1
\end{equation*}
\begin{equation*}
\sum_{j=2}^{n} (t_j-1) = \sum_{j=2}^{n} (j-1) = \sum_{k=1}^{n-1}k =  \frac{n(n-1)}{2}
\end{equation*}
Avendo posto $k = j - 1$. Si ottiene che il tempo di esecuzione di \textsc{Insertion-Sort}  nel caso peggiore è:
\begin{equation*}
\begin{aligned}
T(n) &= c_1n + c_2(n-1) + c_4(n-1) + c_5\Bigr(\frac{n(n+1)}{2}-1\Bigr) + c_6\Bigl(\frac{n(n-1)}{2}\Bigr) + c_7\Bigl(\frac{n(n-1)}{2}\Bigr) + c_8(n-1) \\
&= c_1n + (c_2 + c_4 + c_8)(n-1) + c_5\Bigl(\frac{n(n+1)}{2}-1\Bigr) + (c_6 + c_7)\Bigl(\frac{n(n-1)}{2}\Bigr) \\
&= \Bigl(\frac{c_5}{2} + \frac{c_6}{2} + \frac{c_7}{2}\Bigr)n^2 + \Bigl(c_1 + c_2 + c_4 + \frac{c_5}{2} - \frac{c_6}{2} - \frac{c_7}{2} + c_8\Bigr)n - (c_2 + c_4 + c_5 + c_8)
\end{aligned}
\end{equation*}
Questo tempo di esecuzione può essere espresso come $T(n) = an^2 + bn + c$, con le costanti \textit{a}, \textit{b} e \textit{c} che dipendono dai costi $c_i$ delle istruzioni; quindi è una funzione quadratica di \textit{n}.

In relazione al caso peggiore si ha il tempo di esecuzione più lungo per qualsiasi input di dimensione \textit{n}. Non a caso di solito si utilizza proprio il caso peggiore per eseguire l'analisi di un algoritmo, questo essenzialmente per tre motivi:
\begin{itemize}
\item Il tempo di esecuzione nel caso peggiore di un algoritmo è un \textbf{limite superiore} al tempo di esecuzione per qualsiasi input. Conoscendo questo tempo si ha la garanzia che l'algoritmo non potrà impiegare di più.
\item Per alcuni algoritmi il caso peggiore si verifica molto spesso, per esempio la ricerca di un elemento assente.
\item Il caso medio spesso è altrettanto cattivo del peggiore. Per esempio dati in input \textit{n} numeri a caso su cui applicare \textsc{Insertion-Sort} si avrà che in media metà degli elementi di \textit{A}[1\,...\,\textit{j}\,-\,1] sono più piccoli di \textit{A}[\textit{j}], mentre gli altri elementi sono più grandi. In media quindi, si verificherà solo metà del sottoarray \textit{A}[1\,...\,\textit{j}\,-\,1], pertanto $t_j$ vale circa $\frac{j}{2}$ cioè circa la metà del caso peggiore ma sempre una funzione quadratica di \textit{n}.
\end{itemize}
In alcuni casi particolari sarà più importante determinare il tempo di esecuzione nel \textbf{caso medio} di un algoritmo.

Nell'ambito dell'analisi degli algoritmi un'astrazione semplificativa molto utilizzata è il \textbf{tasso di crescita} che rappresenta la velocità con cui cresce il tempo di esecuzione di un algoritmo e che viene definita solo in relazione al \textbf{termine principale} di una formula, cioè in relazione al termine di grado maggiore ignorando le costanti (i termini di grado inferiore sono insignificanti per grandi valori di \textit{n}). È proprio il tasso di crescita il termine di paragone tra i vari algoritmi. Per \textsc{Insertion-Sort} si avrà dunque:
\begin{equation*}
T(n) = an^2 + bn + c \Rightarrow an^2 \Rightarrow n^2
\end{equation*}
Il tempo di esecuzione \textbf{cresce come} $n^2$, non è uguale a $n^2$. Il tasso di crescita è invece: $n^2 \Rightarrow \Theta(n^2)$.
\chapter{Merge sort}
\section{Progettare gli algoritmi}
Ci sono varie tecniche per progettare gli algoritmi. Per \textsc{Insertion-Sort}, algoritmo \textbf{iterativo}, si utilizza un approccio \textbf{incrementale}: dopo aver ordinato il sottoarray \textit{A}[1\,...\,\textit{j}\,-\,1], si inserisce il singolo elemento \textit{A}[\textit{j}] nella posizione appropriata, ottenendo il sottoarray ordinato \textit{A}[1\,...\,\textit{j}].\\Nel caso degli algoritmi \textbf{ricorsivi}, invece, si utilizza un altro approccio detto \textbf{divide et impera}.
\subsection{Il metodo divide et impera}
Gli algoritmi ricorsivi, per risolvere un determinato problema, chiamano sé stessi in modo ricorsivo, una o più volte, per trattare sottoproblemi dello stesso tipo. Attraverso il metodo divide et impera suddividono il problema in vari sottoproblemi, che sono simili al problema di partenza, ma di dimensioni più piccole, risolvono i sottoproblemi in modo ricorsivo e, poi, combinano le soluzioni per costruire una soluzione del problema originale. Tale paradigma prevede tre passi ad ogni livello di ricorsione:
\begin{description}
\item[Divide] Il problema viene diviso in un certo numero di sottoproblemi, che sono istanze più piccole dello stesso problema
\item[Impera]I sottoproblemi vengono risolti in modo ricorsivo. Comunque, quando i sottoproblemi hanno una dimensione sufficientemente piccola, essi vengono risolti direttamente
\item[Combina]Le soluzioni dei sottoproblemi vengono combinate per generare la soluzione del problema originale
\end{description}
Un esempio:
\subsubsection{Fattoriale}
L'algoritmo per il calcolo del fattoriale di un numero \textit{n} può essere implementato sia in forma iterativa che ricorsiva.\;In entrambi i casi la sua correttezza può essere verificata mediante l'invariante di ciclo.\\\\
\begin{tabular}{ll}
\em Iterativo & \em Ricorsivo \\
\textsc{Fatt(\textit{n})} & \textsc{Fatt(\textit{n})}\\
1\firsttab \textbf{if} \textit{n} = 1 &1\firsttab \textbf{if} \textit{n} = 1\\
2\secondtab \textbf{return} 1 &2\secondtab \textbf{return} 1\\
3\firsttab \textit{Fat} $\leftarrow$ 1&3\firsttab \textbf{else return} $\textit{n} \cdot \textsc{Fatt}(n-1)$\\
4\firsttab \textbf{for} \textit{i} $\leftarrow$ 1 \textbf{to} \textit{n}\\
5\secondtab \textit{Fat} $\leftarrow \textit{Fat} \cdot \textit{i}$\\
6\firsttab \textbf{return} \textit{Fat}\\
\end{tabular}
\\\\La versione ricorsiva rappresenta un algoritmo ricorsivo \textbf{in coda} nel senso che la ricorsione è in fondo (potrebbe essere trasformato in un algoritmo iterativo) e come si nota si passerà come argomento di \textsc{Fatt} un valore più piccolo di quello considerato.

Asintoticamente le due versioni costano uguale ma a livello di programma costa di più quello ricorsivo perché deve richiamare sé stesso e allocare nello stack.

Facendo un'analisi delle due versioni si dimostra che per entrambe il tempo di esecuzione cresce come \textit{n}:
\begin{equation*}
T(n) = cn\Rightarrow n
\end{equation*}
Nel caso iterativo si cicla su \textit{n} valori eseguendo operazioni costanti quindi ottenendo un costo \textit{cn}. Analogamente nel caso ricorsivo si ottiene \textit{cn}.

Per quanto riguarda la correttezza, l'invariante di ciclo è la seguente:
\begin{quote}
\textit{Ad ogni iterazione del ciclo \textbf{for} la variabile \textit{Fat} contiene il prodotto dei primi i valori}
\end{quote}
\section{L'algoritmo Merge sort}
L'algoritmo \textsc{Merge-Sort} è conforme al paradigma divide et impera e opera nel modo seguente:
\begin{description}
\item[Divide]Divide la sequenza degli \textit{n} elementi da ordinare in due sottosequenze di \textit{n}/2 elementi ciascuna
\item[Impera]Ordina le due sottosequenze in modo ricorsivo utilizzando l'algoritmo \textsc{Merge-Sort}
\item[Combina]Fonde le due sottosequenze ordinate per generare la sequenza completa ordinata
\end{description}
La ricorsione \textsl{tocca il fondo} quando la sequenza da ordinare ha grandezza 1, nel qual caso non c'è più nulla da fare, in quanto ogni sequenza di lunghezza 1 è già ordinata.

L'operazione chiave dell'algoritmo \textsc{Merge-Sort} è la fusione di due sottosequenze ordinate nella passo \textsl{combina}. Per effettuare la fusione si utilizza la funzione	\textsc{Merge(\textit{A},\textit{\,p,\,q,\,r})}, dove \textit{A} è un array e \textit{p}, \textit{q}, \textit{r} sono indici dell'array tali che $p \leq q < r$. La funzione assume che i sottoarray \textit{A}[\textit{p}\,...\,\textit{q}] e \textit{A}[\textit{q}\,+\,1\,...\,\textit{r}] siano ordinati; li \textbf{fonde} per formare un unico sottoarray  ordinato che sostituisce il sottoarray corrente \textit{A}[\textit{p}\,...\,\textit{r}].

La procedura \textsc{Merge} impiega un tempo $\Theta(n)$, dove $n = r - p \,+\, 1$ è il numero totale di elementi da fondere.

L'algoritmo \textsc{Merge-Sort} ordina il vettore in input \textit{A}[\textit{p}\,...\,\textit{r}]. Se $p \geq r$, l'array ha al massimo un elemento e quindi è già ordinato; altrimenti, il passo \textsl{divide} calcola un indice \textit{q} che separa \textit{A}[\textit{p}\,...\,\textit{r}] in due sottoarray: \textit{A}[\textit{p}\,...\,\textit{q}] che contiene $\lceil n/2 \rceil$ elementi, e \textit{A}[\textit{q} + 1\,...\,\textit{r}] che contiene $\lfloor n/2 \rfloor$ elementi. Riassumendo:
\begin{description}
\item[Divide]Divide \textit{A}[\textit{p}\,...\,\textit{r}] in \textit{A}[\textit{p}\,...\,\textit{q}] e \textit{A}[\textit{q} + 1\,...\,\textit{r}], \textit{q} è il punto di mezzo di \textit{A}[\textit{p}\,...\,\textit{r}]
\item[Impera]Ordina ricorsivamente \textit{A}[\textit{p}\,...\,\textit{q}] e \textit{A}[\textit{q} + 1\,...\,\textit{r}]
\item[Combina]Fonde i due sottoarray ordinati \textit{A}[\textit{p}\,...\,\textit{q}] e \textit{A}[\textit{q} + 1\,...\,\textit{r}] in un singolo array ordinato \textit{A}[\textit{p}\,...\,\textit{r}]
\end{description}
\textsc{Merge-Sort(\textit{A},\,\textit{p},\,\textit{r})}\\
1\firsttab \textbf{if} \textit{p} $<$ \textit{r}\\
2\secondtab \textit{q} $\leftarrow$ $\lfloor (p + r)/2 \rfloor$\\
3\secondtab \textsc{Merge-Sort(\textit{A},\textit{\,p,\,q})}\\
4\secondtab \textsc{Merge-Sort(\textit{A},\textit{\,q + 1,\,r})}\\
5\secondtab \textsc{Merge(\textit{A},\textit{\,p,\,q,\,r})}\\\\
La riga 1 controlla il caso base (se il sottoarray ha dimensione 1), la riga 2 corrisponde a \textsl{divide}, le righe 3\,-\,4 a \textsl{impera} e infine la riga 5 a \textsl{combina}.\\\\
\textsc{Merge(\textit{A},\,\textit{p},\,\textit{q},\,\textit{r})}\\
1\firsttab $n_1 \leftarrow q - p + 1$\\
2\firsttab $n_2 \leftarrow r - q$\\
3\firsttab // Crea array \textit{L}[1\,..\,$n_1 + 1$] e \textit{R}[1\,..\,$n_2 + 1$]\\
4\firsttab \textbf{for} \textit{i} $\leftarrow$ 1 \textbf{to} $n_1$\\
5\secondtab \textit{L}[\textit{i}] $\leftarrow$ \textit{A}[$p + i - 1$]\\
6\firsttab  \textbf{for} \textit{j} $\leftarrow$ 1 \textbf{to} $n_2$\\
7\secondtab \textit{R}[\textit{j}] $\leftarrow$ \textit{A}[$q + j$]\\
8\firsttab \textit{L}[$n_1 + 1$] $\leftarrow \infty $\\
9\firsttab \textit{R}[$n_2 + 1$] $\leftarrow \infty $\\
10\firsttab $i \leftarrow 1$\\
11\firsttab $j \leftarrow 1$\\
12\firsttab  \textbf{for} \textit{k} $\leftarrow$ \textit{p} \textbf{to} \textit{r}\\
13\secondtab \textbf{if} \textit{L}[\textit{i}] $\leq$ \textit{R}[\textit{j}]\\
14\thirdtab \textit{A}[\textit{k}] $\leftarrow$ \textit{L}[\textit{i}]\\
15\thirdtab $i \leftarrow i + 1$\\
16\secondtab \textbf{else} \textit{A}[\textit{k}] $\leftarrow$ \textit{R}[\textit{j}]\\
17\thirdtab $j \leftarrow j + 1$\\\\
Commenti:
\begin{enumerate}
\item[1-2]$n_1$ e $n_2$ sono le dimensioni dei due sottoarray \textit{A}[\textit{p}\,...\,\textit{q}] e \textit{A}[\textit{q} + 1\,...\,\textit{r}]
\item[3]Sia in \textit{L} che in \textit{R} c'è +1 per poter mettere le due \textbf{sentinelle} (permettono di evitare di mettere due \textbf{if} che peserebbero di più)
\item[4-5]Copia in \textit{L} la parte sinistra di \textit{A}, cioè \textit{A}[\textit{p}\,...\,\textit{q}]
\item[6-7]Copia in \textit{R} la parte destra di \textit{A}, cioè \textit{A}[\textit{q} + 1\,...\,\textit{r}]
\item[8-9]Si definiscono le due sentinelle poste alla fine degli array \textit{L} e \textit{R}. Vengono poste uguali a $\infty$ per essere sicuri che abbiano un valore più grande di tutti gli elementi presenti nell'array. Si usano le sentinelle nel caso in cui i due sottoarray non hanno la stessa dimensione e dunque avanzano valori che dovranno essere copiati
\item[10-11]Si inizializzano gli indici per scorrere i due sottoarray
\item[12]\textit{k} scorre sulle posizioni finali (verranno eseguiti $n = r - p +1$ passi)
\item[13-17]Trova il minore tra i due valori puntati e incrementa il puntatore di una delle due parti
\end{enumerate}
\section{Correttezza}
L'ultimo ciclo \textbf{for} di \textsc{Merge} segue la seguente invariante di ciclo:
\begin{quote}
\textit{All'inizio di ogni iterazione del ciclo \textbf{for} (righe 12 - 17), il sottoarray $A[p\,..\,k - 1]$ contiene ordinati i k - p elementi più piccoli di $L[1\,..\,n_1 + 1]$ e $R[1\,...\,n_2 + 1]$. Inoltre $L[i]$ e $R[j]$ sono i più piccoli elementi dei loro array che non sono stati copiati in A}
\end{quote}
Si dimostra ora la sua validità:
\begin{description}
\item[Inizializzazione]Prima della prima iterazione del ciclo, si ha $k = p$ quindi il sottoarray \textit{A}[\textit{p}\,...\,\textit{k} - 1] è vuoto. Questo sottoarray vuoto contiene dunque $k - p = 0$ elementi più piccoli di \textit{L} e \textit{R}; poiché $i = j = 1$, \textit{L}[\textit{i}] e \textit{R}[\textit{j}] sono i più piccoli elementi, nei rispettivi array, tra quelli che non sono ancora stati copiati in \textit{A}
\item[Conservazione]Se \textit{L}[\textit{i}] $\leq$ \textit{R}[\textit{j}] (quindi \textit{L}[\textit{i}] è l'elemento più piccolo che non è stato ancora copiato in \textit{A}), poiché \textit{A}[\textit{p}\,...\,\textit{k} - 1] contiene i $k - p$ elementi più piccoli, dopo la riga 14 ha copiato \textit{L}[\textit{i}] in \textit{A}[\textit{k}], il sottoarray \textit{A}[\textit{p}\,...\,\textit{k}] conterrà i $k - p + 1$ elementi più piccoli. Incrementando \textit{k} (aggiornamento nel ciclo \textbf{for}) e \textit{i} (riga 15), si ristabilisce l'invariante di ciclo per la successiva iterazione. Se invece \textit{L}[\textit{i}] $>$ \textit{R}[\textit{j}], allora le righe 16 - 17 svolgono l'azione appropriata per conservare l'invariante di ciclo
\item[Conclusione]Alla fine del ciclo $k = r + 1$. Per l'invariante di ciclo, il sottoarray \textit{A}[\textit{p}\,...\,\textit{k} - 1], che è \textit{A}[\textit{p}\,...\,\textit{r}], contiene $k - p = r - p + 1$ elementi ordinati che sono i più piccoli di \textit{L}[1\,...\,$n_1 + 1$] e \textit{R}[1\,...\,$n_2 + 1$]. Assieme, gli array \textit{L} e \textit{R} contengono $n_1 + n_2 + 2 = r - p + 3$ elementi. Tutti gli elementi, tranne i due più grandi, sono stati copiati in \textit{A}; questi due elementi sono le sentinelle
\end{description}
Per verificare che \textsc{Merge} viene eseguita nel tempo $\Theta(n)$, con $n = r - p + 1$, si nota che ciascuna delle righe 1 - 3 e  8 - 11 impiega un tempo costante, i cicli \textbf{for} (righe 4 - 7) impiegano un tempo $\Theta(n_1 + n_2) = \Theta(n)$, e ci sono \textit{n} iterazioni del ciclo \textbf{for} (righe 12 - 17), ciascuna delle quali impiega un tempo costante. Dunque il tempo totale necessario ad eseguire \textsc{Merge} è $\Theta(n)$. Il ciclo \textbf{for} (righe 12 - 17) non dipende dai dati, se non ci fossero le sentinelle si dovrebbero usare degli \textbf{if} andando così ad aumentare il costo ed inoltre in tal caso il ciclo dipenderebbe dai dati per cui si avrebbe che il caso migliore è quando il valore massimo di un sottoarray è maggiore del valore minimo dell'altro sottoarray.
\section{Analisi degli algoritmi divide et impera}
Quando un algoritmo contiene una chiamata ricorsiva a sé stesso, il suo tempo di esecuzione spesso può essere descritto con una \textbf{equazione di ricorrenza} o \textbf{ricorrenza}, che esprime il tempo di esecuzione totale di un problema di dimensione \textit{n} in funzione del tempo di esecuzione per input più piccoli. Una ricorrenza  per il tempo di esecuzione di un algoritmo divide et impera si basa sui tre passi del paradigma di base. Si suppone che\,\textit{T}(\textit{n}) sia il tempo di esecuzione di un problema di dimensione \textit{n}:
\begin{equation*}
T(n) = tempo\;di\;esecuzione\;per\;il\;problema\;di\;dimensione\;\textit{n}
\end{equation*}
Se la dimensione del problema è sufficientemente piccola: $n \leq c$ per qualche costante \textit{c}, ci si trova nel caso base che richiede un tempo costante indicato con $\Theta(1)$. Altrimenti, si suppone che la suddivisione dei problema generi \textit{a} sottoproblemi e che la dimensione di ciascuno di essi sia $1/b$ volte la dimensione del problema originale. Serve un tempo\,\textit{T}(\textit{n\,/\,\textit{b}}) per risolvere un sottoproblema di dimensione $n/b$ e quindi, per risolverne \textit{a}, serve tempo \textit{aT}(\textit{n\,/\,\textit{b}}). Se si impiega un tempo\,\textit{D}(\textit{n}) per dividere il problema in sottoproblemi e un tempo\,\textit{C}(\textit{n}) per combinare le soluzioni dei sottoproblemi nella soluzione del problema originale, si ottiene la ricorrenza:\\
\begin{equation*}
T(n) = \left\{
\begin{array}{ll}
\Theta(1) & \text{se $n \leq c$} \\
\textit{aT}(\textit{n\,/\,\textit{b}}) + \textit{D}(\textit{n}) + \textit{C}(\textit{n}) & \text{altrimenti}
\end{array}\right.
\end{equation*}
\subsection{Analisi di Merge sort}
Si suppone che la dimensione \textit{n} del problema sia un potenza del 2. Ogni passo \textsl{divide} genera due sottosequenze di dimensione esattamente pari a $n/2$ (questa ipotesi non influisce sul tasso di crescita della soluzione della ricorrenza).

Per trovare la ricorrenza per\,\textit{T}(\textit{n}), il tempo di esecuzione nel caso peggiore di \textsc{Merge-Sort} con \textit{n} numeri, si può fare il seguente ragionamento. L'algoritmo \textsc{Merge-Sort} applicato a un solo elemento (caso base $ n = 1$) impiega un tempo costante. Se invece si hanno $n \geq 2$ elementi, si suddivide il tempo di esecuzione secondo i passi divide et impera:
\begin{description}
\item[Divide]Calcola \textit{q}, ciò richiede un tempo costante, quindi\,\textit{D}(\textit{n}) = $\Theta(1)$.
\item[Impera]Risolve in modo ricorsivo i due sottoproblemi di dimensione $n/2$, ciò contribuisce con $2T(n/2)$.
\item[Combina]Fonde un array con \textit{n} elementi, come visto \textsc{Merge}  richiede un tempo $\Theta(n)$, quindi\,\textit{C}(\textit{n}) = $\Theta(n)$.
\end{description}
Sommando le funzioni\,\textit{D}(\textit{n}) e\,\textit{C}(\textit{n}) si ottiene:
\begin{equation*}
D(n) + C(n) = \Theta(1) + \Theta(n) = \Theta(n)
\end{equation*}
Sommando al termine $2T(n/2)$ del passo \textsl{impera} si ottiene la ricorrenza per il tempo di esecuzione\,\textit{T}(\textit{n}) nel caso peggiore di \textsc{Merge-Sort}:
\begin{equation}
T(n) = \left\{
\begin{array}{ll}
c & \text{se $n =  1$} \\
2\,T(n/2) + cn & \text{se $n > 1$}
\end{array}\right.
\label{ricorrenza}
\end{equation}
La costante \textit{c} rappresenta sia il tempo richiesto per risolvere i problemi di dimensione 1 sia il tempo per elemento dell'array dei passi \textsl{divide} e \textsl{combina}.

Un possibile modo per risolvere la ricorrenza è attraverso la costruzione di un \textbf{albero di ricorsione} che permette di visualizzare le espansioni successive: il termine \textit{cn} è la radice (il costo sostenuto al primo livello di ricorsione) e i due sottoalberi della radice sono le due ricorrenze più piccole $T(n/2)$. Il costo sostenuto per ciascuno dei due sottonodi al secondo livello di ricorsione è $cn/2$. Continuando ad espandere i nodi dell'albero suddividendolo nelle sue componenti come stabilisce la ricorrenza si arriva al caso base in cui le dimensioni dei problemi si riducono a 1 e ciascuno di essi ha costo \textit{c}.

A questo punto si sommano i costi per ogni livello dell'albero. Il primo livello in alto ha un costo totale $cn$, il secondo livello ha un costo totale $c(n/2) + c(n/2) = cn$, il terzo livello ha un costo totale $c(n/4) + c(n/4) + c(n/4) + c(n/4) = cn$ e così via (ad ogni livello raddoppiano i sottoproblemi ma si dimezza il costo per ognuno di essi). In generale, il livello \textit{i} ha $2^i$ nodi, ciascuno dei quali ha un costo $2^ic(n/2^i) = cn$ (al livello \textit{i} la dimensione è pari a $\frac{n}{2^i}$). All'ultimo livello in basso ci sono \textit{n} nodi, ciascuno con un costo \textit{c}, per un costo totale di $cn$.

Il numero totale di livelli dell'albero di ricorsione è $lg\,n \,+\, 1$, dove \textit{n} è il numero di foglie che è anche uguale alla dimensione dell'input. Per calcolare il costo totale dalla ricorrenza \eqref{ricorrenza} basta sommare i costi di tutti i livelli. Ci sono $lg\,n \,+\, 1$ livelli, ciascuno di costo $cn$, per un costo totale di $cn\,(lg\,n + 1) = cn\,lg\,n + cn$. Ignorando il termine di ordine inferiore e la costante \textit{c}, si ottiene il risultato $\Theta(n\,lg\,n)$.
\chapter{Crescita delle funzioni}
Le notazioni che si utilizzano per descrivere il tempo di esecuzione asintotico di un algoritmo sono definite in termini di funzioni il cui dominio è l'insieme dei numeri naturali $\mathbb{N}$ = \{0,\,1,\,2,\,...\}. Tali notazioni sono comode per descrivere la funzione $T(n)$, tempo di esecuzione nel caso peggiore, che di solito è definita soltanto con dimensioni intere dell'input. A volte, però, è possibile abusare di tale notazione asintotica ed estenderla al dominio dei numeri reali $\mathbb{R}$ o limitata a un sottoinsieme dei numeri naturali.
\section{Notazione $O$}
Viene utilizzata quando si ha un \textbf{limite asintotico superiore}. Per una data funzione $g(n)$, si indica con $O(g(n))$ l'insieme delle funzioni:
\begin{equation*}
O(g(n)) = \{\,f(n) :\,\exists \,c\in\mathbb{R^+},\,n_0\in\mathbb{N}\;t.c.\;0\leq f(n)\leq c\cdot g(n)\;\forall\;n\geq n_0\,\}
\end{equation*}
$g(n)$ è un \textbf{limite asintotico superiore} per $f(n)$.\\
La notazione $O$ si usa per assegnare un limite superiore ad una funzione, a meno di un fattore costante. Per qualsiasi valore \textit{n} a destra di $n_0$, il valore della funzione $f(n)$ coincide o sta sotto $cg(n)$. Si scrive $f(n) = O(g(n))$ per indicare che una funzione $f(n)$ è un membro dell'insieme $O(g(n))$, ovvero che $f(n) \in O(g(n))$.\\\\
Esempi:
\begin{itemize}
\item$2n^2 = O(n^3),\;con\;c = 1\;e\;n_0 = 2$
\item Funzioni in $O(n^2)$
\begin{itemize}
\item$n$
\item$n^{1.99}$
\item$n^2$
\item$n^2 + n$
\item$1000n^2 + 100n$
\end{itemize}
\end{itemize}
\section{Notazione $\Omega$}
Così come $O$ fornisce un limite asintotico superiore, la notazione $\Omega$ fornisce un \textbf{limite asintotico inferiore}. Per una data funzione $g(n)$, si indica con $\Omega(g(n))$ l'insieme delle funzioni:
\begin{equation*}
\Omega(g(n)) = \{\,f(n) :\,\exists \,c\in\mathbb{R},\,n_0\in\mathbb{N}\;t.c.\;0\leq c\cdot g(n)\leq f(n)\;\forall\;n\geq n_0\,\}
\end{equation*}
$g(n)$ è un \textbf{limite asintotico inferiore} per $f(n)$.\\
Per tutti i valori di \textit{n} a destra di $n_0$, il valore di $f(n)$ coincide o sta sopra $cg(n)$.\\\\
Esempi:
\begin{itemize}
\item$\sqrt{n} = \Omega(lg\,n)$
\item Funzioni in $\Omega(n^2)$
\begin{itemize}
\item$n^2$
\item$n^2 \pm n$
\item$1000n^2 \pm 100n$
\item$n^3$
\item$n^{2.001}$
\item$n^2\;lg\,lg\,lg\,n$
\end{itemize}
\end{itemize}
\section{Notazione $\Theta$}
Per una data funzione $g(n)$, si indica con $\Theta(g(n))$ l'insieme delle funzioni:
\begin{equation*}
\Theta(g(n)) = \{\,f(n) :\,\exists \,c_1,c_2,n_0\in\mathbb{N}\;t.c.\;0\leq c_1\cdot g(n)\leq f(n)\leq c_2\cdot g(n)\;\forall\;n\geq n_0\,\}
\end{equation*}
$g(n)$ è un \textbf{limite asintoticamente stretto} per $f(n)$.\\
Una funzione $f(n)$ appartiene all'insieme $\Theta(g(n))$ se esistono delle costanti positive $c_1$ e $c_2$ tali che essa possa essere racchiusa fra $c_1\,g(n)$ e $c_2\,g(n)$, per valori sufficientemente grandi di \textit{n}. Per tutti i valori di \textit{n} a destra di $n_0$, il valore di $f(n)$ coincide o sta sopra $c_1\,g(n)$ e coincide o sta sotto $c_2\,g(n)$. In altre parole, per ogni $n \geq n_0$, la funzione $f(n)$ è uguale a $g(n)$ a meno di un fattore costante.

La definizione di $\Theta(g(n))$ richiede che ogni membro di $f(n) \in \Theta(g(n))$ sia \textbf{asintoticamente non negativo}, ovvero che $f(n)$ sia non negativa quando \textit{n} è sufficientemente grande. Di conseguenza, la funzione $g(n)$ stessa deve essere asintoticamente non negativa, altrimenti l'insieme $\Theta(g(n))$ è vuoto.
\begin{theorem}
Per ogni coppia di funzioni $f(n)$ e $g(n)$, si ha $f(n) = \Theta(g(n))$ se e soltanto se $f(n) = O(g(n))$ e $f(n) = \Omega(g(n))$.
\end{theorem}
\section{Notazione $o$}
Si utilizza la notazione \textit{o} per denotare un limite superiore che \textbf{non} è asintoticamente stretto.
\begin{equation*}
o(g(n)) = \{\,f(n) :\,\forall \,c > 0 \in\mathbb{R}\;\exists \,n_0 > 0 \in\mathbb{N}\;t.c.\;0\leq f(n) < c\cdot g(n)\;\forall\;n\geq n_0\,\}
\end{equation*}
Nella notazione \textit{o} la funzione $f(n)$ diventa insignificante rispetto a $g(n)$ quando \textit{n} tende all'infinito; ovvero:
\begin{equation*}
\lim_{n\to \infty} \frac{f(n)}{g(n)} = 0
\end{equation*}
Esempi:
\begin{itemize}
\item$2n = o(n^2)$
\item$2n^2 \neq o(n^2)$
\item Funzioni in $o(n^2)$
\begin{itemize}
\item$n^{1.999}$
\item$\frac{n^2}{lg\,n}$
\end{itemize}
\end{itemize}
\section{Notazione $\omega$}
Si utilizza la notazione $\omega$ per indicare un limite inferiore che \textbf{non} è asintoticamente stretto.
\begin{equation*}
o(g(n)) = \{\,f(n) :\,\forall \,c > 0 \in\mathbb{R}\;\exists \,n_0 > 0 \in\mathbb{N}\;t.c.\;0\leq c\cdot g(n) < f(n)\;\forall\;n\geq n_0\,\}
\end{equation*}
La relazione $f(n) = \omega(g(n))$ implica che:
\begin{equation*}
\lim_{n\to \infty} \frac{f(n)}{g(n)} = \infty
\end{equation*}
se il limite esiste; cioè $f(n)$ diventa arbitrariamente grande rispetto a $g(n)$ quando \textit{n} tende all'infinito.\\\\
Esempi:
\begin{itemize}
\item$\frac{n^2}{2} = \omega(n)$
\item$n^2 \neq \omega(n^2)$
\item Funzioni in $\omega(n^2)$
\begin{itemize}
\item$n^{2.0001}$
\item$n^2\,lg\,n$
\end{itemize}
\end{itemize}
\section{Confronto di funzioni}
Date due funzioni $f(n)$ e $g(n)$ assunte \textbf{asintoticamente positive} si definiscono le seguenti proprietà:
\begin{itemize}
\item[]\textbf{Transitività}
\begin{enumerate}
\item[] $f(n) = O(g(n))$ e $g(n) = O(h(n))$ \;$\Rightarrow$\; $f(n) = O(h(n))$
\item[] $f(n) = \Omega(g(n))$ e $g(n) = \Omega(h(n))$ \;$\Rightarrow$\; $f(n) = \Omega(h(n))$
\item[] $f(n) = \Theta(g(n))$ e $g(n) = \Theta(h(n))$ \;$\Rightarrow$\; $f(n) = \Theta(h(n))$
\item[] $f(n) = o(g(n))$ e $g(n) = o(h(n))$ \;$\Rightarrow$\; $f(n) = o(h(n))$
\item[] $f(n) = \omega(g(n))$ e $g(n) = \omega(h(n))$ \;$\Rightarrow$\; $f(n) = \omega(h(n))$
\end{enumerate}
\item[]\textbf{Riflessività}
\begin{enumerate}
\item[] $f(n) = O(g(n))$
\item[] $f(n) = \Omega(g(n))$
\item[] $f(n) = \Theta(g(n))$
\end{enumerate}
\item[]\textbf{Simmetria}
 \begin{enumerate}
 \item[] $f(n) = \Theta(g(n)) \;\Leftrightarrow\; g(n) = \Theta(f(n))$
 \end{enumerate}
\item[]\textbf{Simmetria Trasposta}
\begin{enumerate}
 \item[] $f(n) = O(g(n)) \;\Leftrightarrow\; g(n) = \Omega(f(n))$
\item[] $f(n) = o(g(n)) \;\Leftrightarrow\; g(n) = \omega(f(n))$
\end{enumerate}
\end{itemize}
Intuitivamente:
\begin{enumerate}
\item[] $f(n)$ = $O(g(n))$ \,equivale a\, $a \leq b$
\item[] $f(n)$ = $\Omega(g(n))$ \,equivale a\, $a \geq b$
\item[] $f(n)$ = $\Theta(g(n))$ \,equivale a\, $a = b$
\item[] $f(n)$ = $o(g(n))$ \,equivale a\, $a < b$
\item[] $f(n)$ = $\omega(g(n))$ \,equivale a\, $a > b$
\end{enumerate}
Per il confronto tra funzioni \textbf{non} vale la proprietà di \textbf{tricotomia}: se \textit{a} e \textit{b} sono due numeri reali qualsiasi allora $a < b$ o $a > b$ o $a = b$.\\\\
$f(n)$ è \textbf{asintoticamente più piccola} di $g(n)$ se $f(n) = o(g(n))$.\\
$f(n)$ è \textbf{asintoticamente più grande} di $g(n)$ se $f(n) = \omega(g(n))$.
\subsection{Logaritmi}
Per i logaritmi si segue la seguente notazione:
\begin{enumerate}
\item[]$lg\,n$ = $\log_{2}{n}$
\item[]$ln\,n$ = $\log_{e}{n}$
\item[]$lg^k\,n$ = $(lg\,n)^k$
\end{enumerate}
Per tutti i numeri reali $a > 0$, $b > 0$, $c > 0$ e $n \neq 1$:
\begin{enumerate}
\item[]a = $b^{\,log_{b}{\,a}}$
\item[]$log_{c}{(ab)}$ = $log_{c}{\,a} + log_{c}{\,b}$
\item[]$log_{b}{(a^n)}$ = $n$\,$log_{b}{\,a}$
\item[]$log_{b}{\,a}$ = $\frac{log_{c}{\,a}}{log_{c}{\,b}}$
\item[]$log_{b}{\,\frac{1}{a}}$ = $-\,log_{b}{\,a}$
\item[]$log_{b}{\,a}$ = $\frac{1}{log_{a}{\,b}}$
\item[]$a^{log_{b}{\,c}}$ = $c^{\,log_{b}{\,a}}$
\end{enumerate}
\chapter{Ricorrenze}
Come già visto, con il metodo divide et impera un problema viene risolto in modo ricorsivo, applicando tre passi a ogni livello di ricorsione:
\begin{description}
\item[Divide] Il problema viene diviso in un certo numero di sottoproblemi, che sono istanze più piccole dello stesso problema
\item[Impera]I sottoproblemi vengono risolti in modo ricorsivo. Comunque, quando i sottoproblemi hanno una dimensione sufficientemente piccola, essi vengono risolti direttamente
\item[Combina]Le soluzioni dei sottoproblemi vengono combinate per generare la soluzione del problema originale
\end{description}
Quando i sottoproblemi sono abbastanza grandi da essere risolti ricorsivamente, si ha il cosiddetto \textbf{caso ricorsivo}. Una volta che i sottoproblemi diventano sufficientemente piccoli da non richiedere ricorsione, si dirà che la ricorsione ha \textsl{toccato il fondo} e che si è raggiunto il \textbf{caso base}. A volte, oltre ai sottoproblemi che sono istanze più piccole dello stesso problema, si devono risolvere dei sottoproblemi che non sono uguali al problema originale. La risoluzione di tali problemi farà parte del passo \textsl{combina}.
\section{Cos'è una ricorrenza}
Le ricorrenze offrono un modo naturale per caratterizzare i tempi di esecuzione degli algoritmi divide et impera. Una \textbf{ricorrenza} è un'equazione o disequazione che descrive una funzione in termini del suo valore con input più piccoli. In genere in termini di uno o più casi base e di sé stessa, con argomenti più piccoli.
\begin{equation}
T(n) = \left\{
\begin{array}{ll}
\Theta(1) & \text{se $n = 1$} \\
\textit{aT\,}(\textit{n\,/\,\textit{b}}) + \textit{f\,}(\textit{n}) & \text{se $n > 1$}
\end{array}\right.
\label{contorno}
\end{equation}
Le ricorrenze possono assumere varie forme. I sottoproblemi non devono necessariamente essere una frazione costante della dimensione del problema originale.

Alcune ricorrenze non sono uguaglianze, ma disuguaglianze, per esempio:
\begin{equation*}
T(n) \leq 2\,T(n/2) + \Theta(n)
\end{equation*}
In tal caso, poiché tali ricorrenze stabiliscono soltanto un limite superiore su $T(n)$, si esprimerà la soluzione utilizzando la notazione $O$ anziché la notazione $\Theta$. Analogamente, se la disuguaglianza è del tipo:
\begin{equation*}
T(n) \geq 2\,T(n/2) + \Theta(n)
\end{equation*}
poiché la ricorrenza fornisce soltanto un limite inferiore su $T(n)$, si utilizzerà la notazione $\Omega$ nella sua soluzione.

Esistono dei metodi per risolvere le ricorrenze - cioè per ottenere dei limiti asintotici $\Theta$, $\Omega$ o $O$ per la soluzione:
\begin{description}
\item[Metodo di sostituzione] Si ipotizza un limite e poi si utilizza l'induzione matematica per dimostrare che l'ipotesi è corretta
\item[Metodo dell'albero di ricorsione] Converte la ricorrenza in un albero i cui nodi rappresentano i costi ai vari livelli della ricorsione; per risolvere la ricorrenza si adotteranno delle tecniche che limitano le sommatorie
\item[Metodo dell'esperto] Fornisce i limiti per ricorrenze della forma
\begin{equation}
T(n) = a\,T(n/b) + f(n)
\label{esperto}
\end{equation}
dove $a \geq 1$, $b > 1$ e $f(n)$ è una funzione data.$\;$Queste ricorrenze si presentano frequentemente. Una ricorrenza della forma \eqref{esperto} caratterizza un algoritmo divide et impera che crea \textit{a} sottoproblemi, ciascuno dei quali ha un dimensione pari a $1/b$ quella del problema originale e in cui i passi \textsl{divide} e \textsl{combina} insieme richiedono un tempo $f(n)$
\end{description}
Le \textbf{condizioni al contorno} rappresentano una classe di dettagli che tipicamente vengono trascurati. Poiché il tempo di esecuzione di un algoritmo con un input di dimensione costante è una costante, le ricorrenze che derivano dai tempi di esecuzione degli algoritmi, generalmente, hanno $T(n) = \Theta(1)$ per valori sufficientemente piccoli di \textit{n}. Per comodità, quindi, di solito si omettono le definizioni delle condizioni al contorno delle ricorrenze e si assumerà che $T(n)$ sia costante per \textit{n} piccolo. Così facendo la ricorrenza \eqref{contorno} viene definita come:
\begin{equation*}
T(n) = a\,T(n/b) + \Theta(n)
\end{equation*}
\section{Metodo di sostituzione}
Il \textbf{metodo di sostituzione} per risolvere le ricorrenze richiede due passi:
\begin{itemize}
\item Ipotizzare la forma della soluzione
\item Usare l'induzione matematica per trovare le costanti e dimostrare che la soluzione funziona
\end{itemize}
È un metodo potente ma ovviamente può essere applicato soltanto nei casi in cui sia facile immaginare la forma della soluzione. Può essere usato per determinare il limite inferiore o superiore di una ricorrenza. Si distinguono due soluzioni:
\begin{description}
\item[Soluzione Esatta] Se nella definizione della ricorrenza compare una funzione esatta, la soluzione della ricorrenza sarà esatta
\begin{equation*}
T(n) = \left\{
\begin{array}{ll}
1 & \text{se $n = 1$} \\
2\textit{T\,}(\textit{n}\,/\,2) + \textit{n} & \text{se $n > 1$}
\end{array}\right.
\end{equation*}
\begin{enumerate}
\item \textbf{Ipotesi} Si ipotizza la soluzione $T(n) = n\,lg\,n + n$.
\item \textbf{Induzione} si dimostra la correttezza dell'ipotesi:
\begin{itemize}
\item[-]\textbf{Caso base}: $n = 1 \Rightarrow n\,lg\,n + n = 1 = T(n)$
\item[-]\textbf{Passo induttivo}: ipotesi induttiva $T(k) = k\,lg\,k + k \;\forall k < n$\\Usa l'ipotesi induttiva per $k = (n/2)$
\begin{align*}
T(n) &= 2\,T\Bigl(\frac{n}{2}\Bigr) + n = 2\Bigl(\frac{n}{2}\,lg\,\frac{n}{2} + \frac{n}{2}\Bigr) + n \\
&= n\,lg\,\frac{n}{2} + n + n = n(lg\,n - lg\,2) + n + n \\
&=n\,lg\,n - n + n + n = n\,lg\,n + n 
\end{align*}
\end{itemize}
\end{enumerate}
\item[Soluzione Asintotica] È la soluzione usata più spesso
\begin{equation*}
T(n) = \left\{
\begin{array}{ll}
O(1) & \text{se \textit{n} sufficientemente piccolo} \\
2\textit{T\,}(\textit{n}\,/\,2) + \Theta(n) & \text{altrimenti}
\end{array}\right.
\end{equation*}
Viene data una soluzione con notazione asintotica: $T(n) = \Theta(n\,lg\,n)$. Non si dimostra in dettaglio il caso base
\begin{itemize}
\item[-]$T(n)$ è costante $\forall \,n$ costante
\item[-]Interessa la soluzione asintotica quindi si può sempre scegliere un caso base $O(1)$. 
\end{itemize}
\end{description}
\subsubsection{Esempio 1}
Data $T(n) = 2\,T(n/2) + \Theta(n)$ si dovrà dare un \textbf{nome} alla costante per $\Theta(n)$ e mostrare il limite superiore ($O$) e inferiore ($\Omega$) separatamente. Si suppone $T(n) = \Theta(n\,lg\,n)$.\\\\La limitazione superiore di $T(n) = 2\,T(n/2) + O(n)$ è data dalla disuguaglianza $T(n) \leq 2\,T(n/2) + cn$ per qualche costante positiva \textit{c} (definizione di $O(n)$). Si ipotizza la soluzione $T(n) = O(n\,lg\,n)$ cioè $T(n) \leq d\cdot n\cdot lg\,n$ per $d > 0$ costante. Se si trova \textit{d} costante tale che la ricorrenza è verificata, allora si verifica che $T(n) = O(n\,lg\,n)$. \textit{c} è una costante che dipende da molteplici fattori ed è data, \textit{d} invece è un valore che soddisfa la definizione di $O$. Si procede con la sostituzione:
\begin{align*}
T(n) &\leq 2\,T\Bigl(\frac{n}{2}\Bigr) + cn \\
&\leq 2\Bigl(d\,\frac{n}{2}\,lg\,\frac{n}{2}\Bigr) + cn \\
&= d\,n\,lg\,\frac{n}{2} + cn \\
&= d\,n\,lg\,n - d\,n + cn \\
&\leq d\,n\,lg\,n
\end{align*}
$\Rightarrow T(n) = O(n\,lg\,n)$ (valido se $-dn + cn \leq 0$ cioè $d \geq c$).\\\\La limitazione inferiore è data dalla disuguaglianza $T(n) \geq 2\,T(n/2) + cn$ per qualche costante positiva \textit{c} (definizione di $\Omega(n)$). Si ipotizza $T(n) \geq d\cdot n\cdot lg\,n$ per qualche $d > 0$ costante. Si procede con la sostituzione:
\begin{align*}
T(n) &\geq 2\,T\Bigl(\frac{n}{2}\Bigr) + cn \\
&\geq 2\Bigl(d\,\frac{n}{2}\,lg\,\frac{n}{2}\Bigr) + cn \\
&= d\,n\,lg\,\frac{n}{2} + cn \\
&= d\,n\,lg\,n - d\,n + cn \\
&\geq d\,n\,lg\,n
\end{align*}
$\Rightarrow T(n) = \Omega(n\,lg\,n)$ (valido se $-dn + cn \geq 0$ cioè $d \leq c$).\\\\Avendo verificato che $T(n) = O(n\,lg\,n)$ nel limite superiore e $T(n) = \Omega(n\,lg\,n)$ nel limite inferiore, si ottiene che $T(n) = \Theta(n\,lg\,n)$ come si aveva supposto.\\\\Ci sono casi in cui è possibile ipotizzare correttamente un limite asintotico per la soluzione di una ricorrenza, ma in qualche modo sembra che i calcoli matematici non tornino nell'induzione. Di solito, il problema è che l'ipotesi induttiva non è abbastanza forte  per dimostrare il limite esatto. Quando ci si imbatte in simili ostacoli, spesso basta correggere l'ipotesi sottraendo un termine di ordine inferiore per far tornare i conti.
\subsubsection{Esempio 2}
Data $T(n) = 4\,T(n/2) + n$, tale ricorrenza indica che ogni nodo avrà 4 figli e che la somma dei costi delle operazioni \textsl{divide} e \textsl{combina} è \textit{n}. Tramite una \textbf{stima conservativa} si suppone $T(n) = O(n^3)$ quindi si dovrà verificare che $T(n) \leq c\,n^3$. Si procede con la sostituzione supponendo $T(k) \leq c\,k^3$ per $k < n$:
\begin{align*}
T(n) &= 4\,T\Bigl(\frac{n}{2}\Bigr) + n \leq 4\,c\Bigl(\frac{n}{2}\Bigr)^3 + n \\
&= \frac{c}{2}n^3 + n \\
&= \underbrace{cn^3}_{desiderato} - \underbrace{\Bigl(\Bigl(\frac{c}{2}\Bigr)n^3 - n\Bigr)}_{residuo} \\
&\leq cn^3
\end{align*}
$\Rightarrow T(n) = O(n^3)$ (valido se residuo $(\frac{c}{2})n^3 - n \geq 0$).\\Provando ora il limite più stretto $T(n) = O(n^2)$, si suppone $T(k) \leq c\,k^2$ per $k < n$:
\begin{align*}
T(n) &= 4\,T\Bigl(\frac{n}{2}\Bigr) + n \leq 4\,c\Bigl(\frac{n}{2}\Bigr)^2 + n \\
&= cn^2 + n = O(n^2) \;\textbf{FALSO!!}
\end{align*}
L'uguaglianza è vera perché si trascurano gli ordini inferiori ma si voleva arrivare a dimostrare \textbf{esattamente} la stessa forma dell'ipotesi induttiva: $T(n) \leq cn^2$. Ciò significa che $\nexists$\,c tale che $cn^2 + n \leq cn^2$. \textit{c} dovrebbe dipendere da n dunque non sarebbe costante. È quindi opportuno irrobustire l'ipotesi induttiva andando a sottrarre un termine di ordine inferiore. Partendo dall'ipotesi $T(k) \leq c_1k^2 + c_2k$ per $k < n$ si ottiene:
\begin{align*}
T(n) &= 4\,T\Bigl(\frac{n}{2}\Bigr) + n \\
&\leq 4\,\Bigl(c_1\Bigl(\frac{n}{2}\Bigr)^2 - c_2\Bigl(\frac{n}{2}\Bigr)\Bigl) + \,n\\
&= c_1n^2 - 2\,c_2n + n \\
&= c_1n^2 - c_2n - (c_2n - n) \\
&\leq c_1n^2 - c_2n
\end{align*}
$\Rightarrow T(n) = O(n^2)$ (valido se $c_2 \geq 1$).\\Analogamente si dimostra per il limite inferiore arrivando a verificare che per la ricorrenza considerata $T(n) = \Theta(n^2)$.
\section{Metodo dell'albero di ricorsione}
In un \textbf{albero di ricorsione} ogni nodo rappresenta il costo di un singolo sottoproblema da qualche parte nell'insieme delle chiamate ricorsive di funzione. Sommando i costi all'interno di ogni livello dell'albero si ottiene un insieme di costi per livello; sommando poi tutti i costi per livello si determina il costo totale di tutti i livelli della ricorsione.

Un albero di ricorsione è un ottimo metodo per ottenere una buona ipotesi, che poi viene verificata con il metodo di sostituzione. Quando si usa un albero di ricorsione per generare una buona ipotesi, spesso si tollera una certa dose di \textsl{approssimazione}, in quanto l'ipotesi sarà verificata in un secondo momento.

Il metodo dell'albero di ricorsione dà solo l'intuizione della soluzione, non dà la soluzione esatta.
\subsubsection{Esempio 1}
Data $T(n) = T(n/4) + T(n/2) + n^2$, i primi due termini corrispondono all'operazione di \textsl{impera} mentre $n^2$ alle operazioni di \textsl{divide} e \textsl{combina}. Questa ricorrenza richiama sé stessa due volte con argomenti diversi. La radice dell'albero di ricorsione ha costo $n^2$ che, come detto, corrisponde alle operazioni di \textsl{divide} e \textsl{combina}. La radice ha due figli: uno associato al sottoproblema avente dimensione $n/4$ volte quella del problema originale, l'altro associato al sottoproblema avente dimensione $n/2$ volte quella del problema originale. A tale livello corrisponderà un costo dato da $(n/4)^2 + (n/2)^2 = \frac{5}{16}n^2$. Passando al livello successivo, il nodo $(n/4)^2$ avrà due figli: $(n/16)^2$ e $(n/8)^2$, invece il nodo $(n/2)^2$ avrà figli: $(n/8)^2$ e $(n/4)^2$. A tale livello corrisponderà quindi un costo pari a $(n/16)^2 + (n/8)^2 + (n/8)^2 + (n/4)^2 = \frac{25}{256}n^2$. Continuando a sviluppare l'albero di ricorsione fino ad arrivare ad avere foglie che rappresentano il caso base ($\Theta(1)$) si verifica che l'albero non è bilanciato, cioè l'altezza dal nodo principale alle foglie non è uguale per tutte le foglie, in particolare si nota che il lato sinistro dell'albero ha altezza $(1/4)^i$ mentre il lato destro ha altezza $(1/2)^i$ risultando dunque più profondo del sinistro. Andando ora a sommare i costi per livello si ottiene:
\begin{equation}
Totale = n^2\Bigr(1 + \frac{5}{16} + \Bigr(\frac{5}{16}\Bigl)^2 + \Bigr(\frac{5}{16}\Bigl)^3 + \Bigr(\frac{5}{16}\Bigl)^4 + \;... \Bigl)
\label{geometrica}
\end{equation}
dove l'argomento della parentesi rappresenta una serie geometrica  che converge a  $\frac{1}{1 \,-\, \frac{5}{16}} \approx 1.42$. Tuttavia l'uguaglianza \eqref{geometrica} è vera solo al livello in cui termina il lato sinistro dell'albero che, come detto, è più corto che lato destro. Questo significa che il valore ottenuto da tale equazione \textbf{non} è il risultato della ricorrenza ma solo una stima inferiore oltre la quale non si può fare di meglio, corrisponde quindi ad un $\Omega$. Il lato destro, che terminerà invece ad un livello avente costo unitario (caso base), dà una stima superiore corrispondente quindi ad un $O$. Il caso peggiore di questa ricorrenza corrisponde ad un triangolo pieno che avrebbe altezza $lg\,n$.
\subsubsection{Esempio 2}
Data $T(n) = T(n/3) + T(2n/3) + \Theta(n)$, il limite superiore ($O$) è definito dalla disuguaglianza $T(n) \leq T(n/3) + T(2n/3) + cn$, quello inferiore ($\Omega$), invece, da $T(n) \geq T(n/3) + T(2n/3) + cn$. La radice ha costo $cn$ e ha due figli: $c(n/3)$ e $c(2n/3)$. Il costo per livello è pari a $c(n/3) + c(2n/3) = cn$. A loro volta $c(n/3)$ avrà figli $c(n/9)$ e $c(2n/9)$, mentre $c(2n/3)$ avrà figli $c(2n/9)$ e $c(4n/9)$. Ogni livello ha costo $cn$ e l'albero ha $log_{3}{\,n}$ livelli pieni, questo perché l'albero non è bilanciato, il lato sinistro è più corto e ha altezza $3^x = n \Rightarrow x = log_{3}{\,n}$. Il lato destro, e quindi l'albero, ha altezza $log_{3/2}{\,n}$. Si ottiene quindi:
\begin{itemize}
\item Idea per \textbf{limite superiore}: $\leq d\,n\,log_{3/2}{\,n} = O(n\,lg\,n)$
\item Idea per \textbf{limite inferiore}: $\geq d\,n\,log_{3}{\,n} = \Omega(n\,lg\,n)$
\end{itemize}
Nel caso del limite superiore si ipotizza $T(n) \leq d\,n\,lg\,n$:
\begin{align*}
T(n) &\leq T\Bigr(\frac{n}{3}\Bigl) + T\Bigr(\frac{2n}{3}\Bigl) + cn \leq d\Bigr(\frac{n}{3}\Bigl)lg\frac{n}{3} + d\Bigr(\frac{2n}{3}\Bigl)lg\frac{2n}{3} + cn \\
&= \Bigr(d\Bigr(\frac{n}{3}\Bigl)lg\,n - d\Bigr(\frac{n}{3}\Bigl)lg\,3\Bigl) + \Bigr(d\Bigr(\frac{2n}{3}\Bigl)lg\,n - d\Bigr(\frac{2n}{3}\Bigl)lg\frac{3}{2}\Bigl) + \,cn \\
&= d\,n\,lg\,n - d\Bigr(\Bigr(\frac{n}{3}\Bigl)lg\,3 + \Bigr(\frac{2n}{3}\Bigl)lg\frac{3}{2}\Bigl) + \,cn \\
&= d\,n\,lg\,n - d\Bigr(\Bigr(\frac{n}{3}\Bigl)lg\,3 + \Bigr(\Bigr(\frac{2n}{3}\Bigl)lg\,3 - \Bigl(\frac{2n}{3}\Bigl)lg\,2 \Bigl) + \,cn \\
&= d\,n\,lg\,n - dn\Bigr(lg\,3 - \frac{2}{3}\Bigr) + \,cn \\
&\leq d\,n\,lg\,n
\end{align*}
$\Rightarrow T(n) = O(n\,lg\,n)$ (valido se $-dn(lg\,3 - 2/3) + cn \leq 0$, cioè per $d \geq \frac{c}{lg\,3 - 2/3}$).\\
Nel caso del limite inferiore si ipotizza $T(n) \geq d\,n\,lg\,n$:
\begin{align*}
T(n) &\geq T\Bigr(\frac{n}{3}\Bigl) + T\Bigr(\frac{2n}{3}\Bigl) + cn \leq d\Bigr(\frac{n}{3}\Bigl)lg\frac{n}{3} + d\Bigr(\frac{2n}{3}\Bigl)lg\frac{2n}{3} + cn \\
&= \Bigr(d\Bigr(\frac{n}{3}\Bigl)lg\,n - d\Bigr(\frac{n}{3}\Bigl)lg\,3\Bigl) + \Bigr(d\Bigr(\frac{2n}{3}\Bigl)lg\,n - d\Bigr(\frac{2n}{3}\Bigl)lg\frac{3}{2}\Bigl) + \,cn \\
&= d\,n\,lg\,n - d\Bigr(\Bigr(\frac{n}{3}\Bigl)lg\,3 + \Bigr(\frac{2n}{3}\Bigl)lg\frac{3}{2}\Bigl) + \,cn \\
&= d\,n\,lg\,n - d\Bigr(\Bigr(\frac{n}{3}\Bigl)lg\,3 + \Bigr(\Bigr(\frac{2n}{3}\Bigl)lg\,3 - \Bigl(\frac{2n}{3}\Bigl)lg\,2 \Bigl) + \,cn \\
&= d\,n\,lg\,n - dn\Bigr(lg\,3 - \frac{2}{3}\Bigr) + \,cn \\
&\geq d\,n\,lg\,n
\end{align*}
$\Rightarrow T(n) = \Omega(n\,lg\,n)$ (valido per $0 < d \leq \frac{c}{lg\,3 - 2/3}$).\\Poiché si è verificato che $T(n) = O(n\,lg\,n)$ e $T(n) = \Omega(n\,lg\,n)$, si è dunque dimostrato che $T(n) = \Theta(n\,lg\,n)$.
\section{Metodo dell'esperto}
Il \textbf{metodo dell'esperto} risolve le ricorrenze della forma
\begin{equation*}
T(n) = a\,T(n/b) + f(n)
\end{equation*}
dove $a \geq 1$ e $b > 1$ sono costanti e $f(n)$ è una funzione asintoticamente positiva ($f(n) > 0$ per $n > n_0$). La ricorrenza considerata descrive il tempo di esecuzione di un algoritmo che divide un problema di dimensione \textit{n} in \textit{a} sottoproblemi, ciascuno di dimensione $n/b$, dove \textit{a} e \textit{b} sono costanti positive. I sottoproblemi vengono risolti in modo ricorsivo, ciascuno nel tempo $T(n/b)$. La funzione $f(n)$ comprende il costo per dividere il problema e combinare i risultati dei sottoproblemi. $T(n/b)$ indica $\lfloor n/b\rfloor$ o $\lceil n/b\rceil$.

Con il metodo dell'esperto $T(n)$ può essere asintoticamente limitata distinguendo tre casi:
\begin{enumerate}
\item Se $f(n) = O(n^{log_{b}{a} - \epsilon})$ per qualche costante $\epsilon > 0$, allora $T(n) = \Theta(n^{log_{b}{a}})$. In questo caso il costo è dominato dal numero delle foglie, cresce dalla radice alle foglie ed $\epsilon$ indica che la soluzione sta abbastanza sotto $n^{log_{b}{a}}$.
\item Se $f(n) = \Theta(n^{log_{b}{a}})$, allora $T(n) = \Theta(n^{log_{b}{a}} \,lg\,n)$. In questo caso il costo è all'incirca lo stesso in ognuno dei $log_{b}{\,n}$ livelli.
\item Se $f(n) = \Omega(n^{log_{b}{a} + \epsilon})$ per qualche costante $\epsilon > 0$ e se $f(n)$ è tale che $af(n/b) \leq cf(n)$ per qualche  costante $c < 1$ e $\forall\,n \geq n_0$ (\textbf{condizione di regolarità}), allora $T(n) = \Theta(f(n))$. In questo caso il costo è dominato dalla radice, decresce dalla radice alle foglie (numero delle foglie decresce velocemente) ed $\epsilon$ indica che la soluzione sta abbastanza sopra $n^{log_{b}{a}}$.
\end{enumerate}

Si può ottenere un'intuizione del teorema dell'esperto a partire dall'albero di ricorsione relativo a
\begin{equation*}
T(n) = a\,T(n/b) + f(n)
\end{equation*}
La radice dell'albero ha costo $f(n)$ mentre il costo per livello è dato da $a^if(n/b^i)$ fino ad arrivare alle foglie aventi costo $T(1)$ alle quali è associato un costo per livello pari a $n^{log_{b}{a}}T(1)$. Si arriva alle foglie quando $n/b^n = 1 \Rightarrow n = b^h \Rightarrow h = log_{b}{n}$, quindi l'altezza dell'albero è $h = log_{b}{n}$ e il numero di foglie è $a^h = a^{log_{b}{n}} = n^{log_{b}{a}}$.

In ciascuno dei tre casi, si confronta $n^{log_{b}{a}}$ con $f(n)$ e la soluzione dipende dalla \textbf{più grande} delle due. Se, come nel caso 1, la funzione $n^{log_{b}{a}}$ è la più grande, allora la soluzione è $T(n) = \Theta(n^{log_{b}{a}})$. Se, come nel caso 3, la funzione $f(n)$ è la più grande, allora la soluzione è $T(n) = \Theta(f(n))$. Se, come nel caso 2, le due funzioni hanno la stessa dimensione, si moltiplica per un fattore logaritmico e la soluzione è $T(n) = \Theta(n^{log_{b}{a}} \,lg\,n) = \Theta(f(n) \,lg\,n)$.

Nel primo caso, $f(n)$ non solo deve essere più piccola di $n^{log_{b}{a}}$, ma deve essere polinomialmente più piccola; ovvero $f(n)$ deve essere asintoticamente più piccola di $n^{log_{b}{a}}$ per un fattore $n^\epsilon$ per qualche costante $\epsilon > 0$. Nel terzo caso, $f(n)$ non solo deve essere più grande di $n^{log_{b}{a}}$, ma deve essere polinomialmente più grande e soddisfare anche la condizione di regolarità $af(n/b) \leq cf(n)$. Questa condizione è soddisfatta dalla maggior parte delle funzioni polinomialmente limitate.

I tre casi \textbf{non coprono} tutte le funzioni possibili. C'è un intervallo fra i casi 1 e 2 in cui $f(n)$ è minore di $n^{log_{b}{a}}$ ma non in modo polinomiale. Analogamente, c'è un intervallo fra i casi 2 e 3 in cui $f(n)$ è maggiore di $n^{log_{b}{a}}$ ma non in modo polinomiale. Se la funzione $f(n)$ ricade in uno di questi intervalli o se la condizione di regolarità nel caso 3 non è soddisfatta, il metodo dell'esperto non può essere usato per risolvere la ricorrenza.
\begin{theorem}
La \textbf{condizione di regolarità} che compare nel terzo caso vale sempre se $f(n) = n^k$ e $f(n) = \Omega(n^{log_{b}{a} + \epsilon})$ per qualche costante $\epsilon > 0$. Quindi è soddisfatta se $f(n)$ è un polinomio.
\end{theorem}
\begin{proof}
Si considerano $f(n) = \Omega(n^{log_{b}{a} + \epsilon})$ e $f(n) = n^k$
\begin{itemize}
\item[]$\Rightarrow n^k > n^{log_{b}{a} + \epsilon} = n^{log_{b}{a}} \,n^\epsilon > n^{log_{b}{a}}$
\item[]$\Rightarrow k > log_{b}{a}$
\item I due lati come esponenti con base \textit{b}:
\item[]$b^k > b^{log_{b}{a}} = a \Rightarrow a/b^k < 1$
\item \textit{a}, \textit{b}, \textit{k} costanti $\Rightarrow$ si sceglie $c = a/b^k \Rightarrow c < 1$ costante
\item$af(n/b) = a(n/b)^k = (a/b^k)n^k = cf(n)$
\item[]$\Rightarrow$ condizione di regolarità soddisfatta
\end{itemize}
\end{proof}
\subsubsection{Esempio 1}
$T(n) = 4\,T(\frac{n}{2}) + n$\\
Questa ricorrenza ha $a = 4$ e $b = 2 \Rightarrow n^{log_{b}{a}} = n^2$ e $f(n) = n$.\\\textbf{Caso 1:} $f(n) = O(n^{2 - \epsilon})$ con $\epsilon = 1 \Rightarrow \,T(n) = \Theta(n^2)$.
\subsubsection{Esempio 2}
$T(n) = 4\,T(\frac{n}{2}) + n^2$\\
Questa ricorrenza ha $a = 4$ e $b = 2 \Rightarrow n^{log_{b}{a}} = n^2$ e $f(n) = n^2$.\\\textbf{Caso 2:} $f(n) = \Theta(n^2) \Rightarrow \,T(n) = \Theta(n^2\,lg\,n)$.
\subsubsection{Esempio 3}
$T(n) = 4\,T(\frac{n}{2}) + n^3$\\
Questa ricorrenza ha $a = 4$ e $b = 2 \Rightarrow n^{log_{b}{a}} = n^2$ e $f(n) = n^3$.\\\textbf{Caso 3:} $f(n) = \Omega(n^{2 + \epsilon})$ con $\epsilon = 1$ e condizione di regolarità $4(\frac{n}{2})^3 \leq cn^3$ con $c = \frac{1}{2} \Rightarrow T(n) = \Theta(n^3)$.
\subsubsection{Esempio 4}
$T(n) = 4\,T(\frac{n}{2}) + \frac{n^2}{lg\,n}$\\
Questa ricorrenza ha $a = 4$ e $b = 2 \Rightarrow n^{log_{b}{a}} = n^2$ e $f(n) = \frac{n^2}{lg\,n} \Rightarrow n^2$ vs. $\frac{n^2}{lg\,n}$.
\begin{itemize}
\item Sicuramente $\frac{n^2}{lg\,n} \neq \Omega(n^2)$ quindi \textbf{non} può essere \textbf{caso 2} e \textbf{caso 3}.
\item Potrebbe essere \textbf{caso 1} ?
\item[]Dovrebbe essere: $f(n) = O(n^{2 - \epsilon}) \Rightarrow \frac{n^2}{lg\,n} < \frac{n^2}{n^\epsilon} \Rightarrow n^\epsilon < lg\,n$ ma $\forall\, \epsilon > 0$ si ha $n^\epsilon = \omega(lg\,n) \Rightarrow$ non si applica il metodo dell'esperto!
\end{itemize}
\subsection{Ricerca binaria}
Trovare un elemento in un array ordinato:
\begin{description}
\item[Divide]Verificare l'elemento di mezzo
\item[Impera]Cercare ricorsivamente in un sottoarray
\end{description}
La \textbf{ricorrenza} per la ricerca binaria è la seguente:
\begin{equation*}
T(n) = 1\,T(n/2) + \Theta(1)
\end{equation*}
1 è il numero di foglie e ogni livello ha costo costante $\Theta(1)$.\\
Dal teorema dell'esperto: $n^{log_{b}{a}} = n^{log_{2}{1}} = n^0 = 1 \Rightarrow$ \textbf{Caso 2:} $T(n) = \Theta(lg\,n)$.
\subsection{Potenza intera}
Il problema consiste nel calcolare $a^n$, dove $n \in \mathbb{N}$.\\L'algoritmo intuitivo ha costo $\Theta(n)$, invece l'algoritmo divide et impera è definito come:
\begin{equation*}
a^n = \left\{
\begin{array}{ll}
a^{n/2} \cdot a^{n/2}  & \text{se \textit{n} pari} \\
a^{n/2} \cdot a^{n/2} \cdot a & \text{se \textit{n} dispari}
\end{array}\right.
\end{equation*}
$T(n) = T(n/2) + \Theta(1) \Rightarrow T(n) = \Theta(lg\,n)$.\\Non si può applicare il metodo dell'esperto perché $T(n)=T(n - 1) + c$. È sufficiente calcolare $a^{n/2}$ una sola volta.
\subsection{Moltiplicazione di matrici}
Date due matrici \textit{A} e \textit{B}, di dimensione $n \times n$, aventi elementi $a_{ij}$ e $b_{ij}$ la matrice $C = A \cdot B$ si può calcolare per $i,j = 1,\,2,\,...\,,\,n$ con:
\begin{equation*}
c_{ij} = \sum_{k=1}^{n}a_{ik}\cdot b_{kj}
\end{equation*}
In totale si calcolano $n^2$ elementi ciascuno dei quali è la somma di \textit{n} valori. Questa modalità ha costo $\Theta(n^3)$. 

L'algoritmo \textsc{Square-Matrix-Multiply(\textit{A},\,\textit{B})} calcola il prodotto tra le matrici \textit{A} e \textit{B} richiedendo un tempo $\Theta(n^3)$. L'algoritmo di Strassen moltiplica due matrici richiedendo un tempo $o(n^3)$(in realtà $\Theta(n^{lg\,7})$). $O(n^{2.81})$ è asintoticamente migliore di \textsc{Square-Matrix-Multiply}. Il motivo per cui \textsc{Square-Matrix-Multiply} costa $\Theta(n^3)$ è dovuto al fatto che nei tre cicli \textbf{for} non ci sono condizioni di uscita, quindi ciascuno di essi esegue esattamente \textit{n} iterazioni e ciascuna esecuzione della riga 7 richiede un tempo costante.\\\\
\textsc{Square-Matrix-Multiply(\textit{A},\,\textit{B})}\\
1\firsttab $n \leftarrow$ A.\textit{rows}\\
2\firsttab Sia \textit{C} una nuova matrice $n \times n$\\
3\firsttab\textbf{for} $i \leftarrow 1$ \textbf{to} \textit{n}\\
4\secondtab\textbf{for} $j \leftarrow 1$ \textbf{to} \textit{n}\\
5\thirdtab$c_{ij} \leftarrow 0$\\
6\thirdtab\textbf{for} $k \leftarrow 1$ \textbf{to} \textit{n}\\
7\firsttab\thirdtab$c_{ij} \leftarrow c_{ij} + a_{ik} \cdot b_{kj}$\\
8\firsttab\textbf{return} \textit{C}\\\\
Per l'algoritmo divide et impera per moltiplicare matrici si suppone che \textit{n} sia un \textbf{potenza esatta di 2} (finché $n \geq 2$ si ha $n/2$ intero). Si dividono le matrici \textit{A}, \textit{B} e \textit{C} in quattro matrici $n/2 \times n/2$.
\begin{displaymath}
A =\left(\begin{array}{cc}
A_{1\,1} &A_{1\,2}\\
A_{2\,1} &A_{2\,2}
\end{array}\right)
\;B = \left(\begin{array}{cc}
B_{1\,1} &B_{1\,2}\\
B_{2\,1} &B_{2\,2}
\end{array}\right)
\;C = \left(\begin{array}{cc}
C_{1\,1} &C_{1\,2}\\
C_{2\,1} &C_{2\,2}
\end{array}\right)
\end{displaymath}
L'equazione $C = A \cdot B$ può essere scritta come:
\begin{displaymath}
\left(\begin{array}{cc}
C_{1\,1} &C_{1\,2}\\
C_{2\,1} &C_{2\,2}
\end{array}\right) = \left(\begin{array}{cc}
A_{1\,1} &A_{1\,2}\\
A_{2\,1} &A_{2\,2}
\end{array}\right) \cdot \left(\begin{array}{cc}
B_{1\,1} &B_{1\,2}\\
B_{2\,1} &B_{2\,2}
\end{array}\right)
\end{displaymath}
Che corrisponde alle quattro equazioni:\\\\
$C_{1\,1} = A_{1\,1} \cdot B_{1\,1} + A_{1\,2} \cdot B_{2\,1}$ \\
$C_{1\,2} = A_{1\,1} \cdot B_{1\,2} + A_{1\,2} \cdot B_{2\,2}$ \\
$C_{2\,1} = A_{2\,1} \cdot B_{1\,1} + A_{2\,2} \cdot B_{2\,1}$ \\
$C_{2\,2} = A_{2\,1} \cdot B_{1\,2} + A_{2\,2} \cdot B_{2\,2}$ \\\\
Ciascuna di queste quattro equazioni specifica due prodotti di matrici $n/2 \times n/2$ e la somma dei loro prodotti $n/2 \times n/2$. È possibile utilizzare queste equazioni per creare un algoritmo ricorsivo divide et impera:\\\\
\textsc{Square-Matrix-Multiply-Recursive(\textit{A},\,\textit{B})}\\
1\firsttab $n \leftarrow$ A.\textit{rows}\\
2\firsttab Sia \textit{C} una nuova matrice $n \times n$\\
3\firsttab\textbf{if} $n = 1$\\
4\secondtab$c_{1\,1} = a_{1\,1} \cdot b_{1\,1}$\\
5\firsttab\textbf{else} suddividi \textit{A}, \textit{B} e \textit{C} \\
6\secondtab\textit{$C_{1\,1}$} = \textsc{SMMR(\textit{$A_{1\,1}$},\,\textit{$B_{1\,1}$})} + \textsc{SMMR(\textit{$A_{1\,2}$},\,\textit{$B_{2\,1}$})} \\
7\secondtab\textit{$C_{1\,2}$} = \textsc{SMMR(\textit{$A_{1\,1}$},\,\textit{$B_{1\,2}$})} + \textsc{SMMR(\textit{$A_{1\,2}$},\,\textit{$B_{2\,2}$})} \\
8\secondtab\textit{$C_{2\,1}$} = \textsc{SMMR(\textit{$A_{2\,1}$},\,\textit{$B_{1\,1}$})} + \textsc{SMMR(\textit{$A_{2\,2}$},\,\textit{$B_{2\,1}$})} \\
9\secondtab\textit{$C_{2\,2}$} = \textsc{SMMR(\textit{$A_{2\,1}$},\,\textit{$B_{1\,2}$})} + \textsc{SMMR(\textit{$A_{2\,2}$},\,\textit{$B_{2\,2}$})} \\
10\firsttab\textbf{return} \textit{C}\\\\
Nella riga 5 la suddivisione delle matrici avviene utilizzando il calcolo degli indici: si andrà ad identificare una sottomatrice mediante un intervallo di indici di riga e un intervallo di indici di colonna della matrice originale. Alla fine si otterrà ogni sottomatrice specificando solo un intervallo di indici ed è proprio questa modalità che consente di eseguire la riga 5 impiegando un tempo non $\Theta(n^2)$ ma $\Theta(1)$. Nelle righe 6 - 9 intervengono somme tra matrici $n/2 \times n/2$ che costano molto.

Si indica con $T(n)$ il tempo per moltiplicare due matrici $n \times n$ utilizzando la procedura \textsc{Square-Matrix-Multiply-Recursive}. Nel caso base, quando $n = 1$, si esegue l'unica moltiplicazione scalare nella riga 4, e quindi $T(1) = \Theta(1)$. Il caso ricorsivo si ha per $n > 1$. La divisione delle matrici nella riga 5 richiede un tempo $\Theta(1)$ se si utilizza il calcolo degli indici. Le righe 6 - 9 chiamano ricorsivamente  \textsc{Square-Matrix-Multiply-Recursive} otto volte in totale. Poiché ogni chiamata ricorsiva moltiplica due matrici $n/2 \times n/2$, apportando un contributo di $T(n/2)$ al tempo di esecuzione totale, il tempo richiesto da tutte e otto le chiamate ricorsive è $8\,T(n/2)$. Bisogna anche considerare le quattro somme di matrici nelle righe 6 - 9. Ciascuna di queste matrici contiene $n^2/4$ elementi; quindi ciascuna delle quattro somme di matrici richiede un tempo $\Theta(n^2)$. Poiché il numero di somme di matrici è una costante, il tempo totale impiegato per sommare le matrici nelle righe 6 - 9 è $\Theta(n^2)$. Il tempo totale per il caso ricorsivo, quindi, è la somma del tempo per dividere le matrici, del tempo per eseguire tutte le chiamate ricorsive e del tempo per sommare le matrici risultanti dalle chiamate ricorsive:
\begin{align*}
T(n) &= \Theta(1) + 8\,T(n/2) + \Theta(n^2) \\
&= 8\,T(n/2) + \Theta(n^2)
\end{align*}
La ricorrenza per il tempo di esecuzione di \textsc{Square-Matrix-Multiply-Recursive} è:
\begin{equation*}
T(n) = \left\{
\begin{array}{ll}
\Theta(1) & \text{se \textit{n} = 1} \\
8\,T(n/2) + \Theta(n^2) & \text{se \textit{n} $>$ 1}
\end{array}\right.
\end{equation*}
che ha soluzione $T(n) = \Theta(n^3)$. Quindi \textsc{Square-Matrix-Multiply-Recursive} non è più veloce della procedura \textsc{Square-Matrix-Multiply}.
\subsubsection{Metodo di Strassen}
Rende \textbf{meno ramificato} l'albero di ricorsione; ovvero, anziché eseguire otto moltiplicazioni ricorsive di matrici  $n/2 \times n/2$, ne saranno eseguite soltanto sette. Il metodo di Strassen è composto da quattro passi:
\begin{enumerate}
\item Divide le matrici \textit{A}, \textit{B} e \textit{C} in sottomatrici $n/2 \times n/2$ richiedendo un tempo $\Theta(1)$.
\item Crea dieci matrici $S_1, \,S_2, \,S_3, ... \,S_{10}$, ciascuna delle quali ha dimensione $n/2 \times n/2$ ed è la somma o differenza di due matrici create nel passo 1. Per creare tutte e dieci le matrici impiega un tempo $\Theta(n^2)$.
\item Utilizzando le sottomatrici create nel passo 1 e le dieci matrici create nel passo 2, calcola ricorsivamente sette matrici prodotto  $P_1, \,P_2, \,P_3, ... \,P_{7}$ ciascuna avente dimensione $n/2 \times n/2$.
\item Calcola le sottomatrici $C_{1\,1}, \,C_{1\,2}, \,C_{2\,1}, \,C_{2\,2}$ della matrice \textit{C} sommando e/o sottraendo varie combinazioni delle matrici $P_i$. Richiede un tempo $\Theta(n^2)$.
\end{enumerate}
Si suppone che, quando la dimensione della matrice \textit{n} si riduce a 1, si esegua un semplice prodotto scalare, come nella riga 4 della procedura \textsc{Square-Matrix-Multiply-Recursive}. Quando $n > 1$, i passi 1 2 e 4 richiedono un tempo totale di $\Theta(n^2)$, e il passo 3 richiede di eseguire sette moltiplicazioni di matrici $n/2 \times n/2$. Quindi si ottiene la seguente ricorrenza per il tempo di esecuzione $T(n)$ dell'algoritmo di Strassen:
\begin{equation*}
T(n) = \left\{
\begin{array}{ll}
\Theta(1) & \text{se \textit{n} = 1} \\
7\,T(n/2) + \Theta(n^2) & \text{se \textit{n} $>$ 1}
\end{array}\right.
\end{equation*}
Si è scambiato una moltiplicazione di matrici con un numero costante di somme di matrici. Questo scambio porta a un tempo di esecuzione asintotico più basso. Per il metodo dell'esperto la ricorrenza ottenuta ha soluzione $T(n) = \Theta(n^{lg\,7})$.\\\\
\textbf{Passo 2}\\
$S_1 \leftarrow B_{1\,2} - B_{2\,2} $\\
$S_2 \leftarrow A_{1\,1} + A_{1\,2} $\\
$S_3 \leftarrow A_{2\,1} + A_{2\,2} $\\
$S_4 \leftarrow B_{2\,1} - B_{1\,1} $\\
$S_5 \leftarrow A_{1\,1} + A_{2\,2} $\\
$S_6 \leftarrow B_{1\,1} + B_{2\,2} $\\
$S_7 \leftarrow A_{1\,2} - A_{2\,2} $\\
$S_8 \leftarrow B_{2\,1} + B_{2\,2} $\\
$S_9 \leftarrow A_{1\,1} - A_{2\,1} $\\
$S_{10} \leftarrow B_{1\,1} + B_{1\,2}$ \\\\
\textbf{Passo 3}\\
$P_1 \leftarrow A_{1\,1} \cdot S_1 = A_{1\,1} \cdot B_{1\,2} - A_{1\,1} \cdot B_{2\,2} $ \\
$P_2 \leftarrow S_{2} \cdot B_{2\,2} = A_{1\,1} \cdot B_{2\,2} + A_{1\,2} \cdot B_{2\,2} $ \\
$P_3 \leftarrow S_{3} \cdot B_{1\,1} = A_{2\,1} \cdot B_{1\,1} + A_{2\,2} \cdot B_{1\,1} $ \\
$P_4 \leftarrow A_{2\,2} \cdot S_4 = A_{2\,2} \cdot B_{2\,1} - A_{2\,2} \cdot B_{1\,1} $ \\
$P_5 \leftarrow S_5 \cdot S_6 = A_{1\,1} \cdot B_{1\,1} + A_{1\,1} \cdot B_{2\,2} + A_{2\,2} \cdot B_{1\,1} + A_{2\,2} \cdot B_{2\,2} $ \\
$P_6 \leftarrow S_7 \cdot S_8 = A_{1\,2} \cdot B_{2\,1} + A_{1\,2} \cdot B_{2\,2} - A_{2\,2} \cdot B_{2\,1} - A_{2\,2} \cdot B_{2\,2} $ \\
$P_7 \leftarrow S_9 \cdot S_{10} = A_{1\,1} \cdot B_{1\,1} + A_{1\,1} \cdot B_{1\,2} - A_{2\,1} \cdot B_{1\,1} - A_{2\,1} \cdot B_{1\,2} $ \\\\
\textbf{Passo 4}\\
$C_1 \leftarrow  P_5 + P_4 - P_2 + P_6$ \\
$C_2 \leftarrow P_1 + P_2$ \\
$C_3 \leftarrow P_3 + P_4$ \\
$C_4 \leftarrow P_5 + P_1 - P_3 - P_7$
\chapter{Analisi probabilistica e algoritmi randomizzati}
\section{Il problema delle assunzioni}
Si suppone di dover assumere un nuovo impiegato rivolgendosi a un'agenzia di selezione del personale che invia un candidato al giorno. Dopo il colloquio si decide subito se assumere o meno il candidato e, in caso positivo, si licenzierà l'attuale impiegato. Si deve pagare all'agenzia un compenso per avere un colloquio con il candidato, tale costo per candidato viene indicato con $c_c$. L'assunzione effettiva di un candidato costa di più perché si dovrà licenziare l'attuale impiegato e pagare un consistente compenso all'agenzia; tale costo di assunzione viene indicato con $c_a$. Si suppone inoltre $c_a > c_c$ e che si vada ad assumere sempre il miglior candidato visto. L'obiettivo è quello di andare a determinare il costo di questa procedura che viene chiamata \textsc{Hire-Assistant}.

I candidati sono numerati da 1 a \textit{n}. La procedura suppone che, dopo avere avuto un colloquio con il candidato \textit{i}, si è subito in grado di determinare se questo candidato è il migliore fra quelli intervistati fino a quel momento. All'inizio, la procedura crea un candidato fittizio (con numero 0), che è sempre assunto.\\\\
\textsc{Hire-Assistant(\textit{n})}\\
1\firsttab $best \leftarrow 0$\\
2\firsttab\textbf{for} $i \leftarrow 1$ \textbf{to} \textit{n}\\
3\secondtab Colloquio con il candidato \textit{i}\\
4\secondtab\textbf{if} (il candidato \textit{i} è migliore del candidato \textit{best})\\
5\thirdtab$best \leftarrow i$\\
6\thirdtab Assumi candidato \textit{i}\\\\
Nel raggiungimento dell'obiettivo non si è interessati al tempo di esecuzione di \textsc{Hire-Assistant}, ma bensì ai costi richiesti per il colloquio e l'assunzione. Le tecniche analitiche adottate sono identiche sia quando si valutano i costi sia quando si valuta il tempo di esecuzione. In entrambi i casi si conta il numero di volte che vengono eseguite determinate operazioni elementari.

Se, su \textit{n} candidati, se ne assumono \textit{m}, il costo totale associato all'algoritmo è $O(n\,c_c + m\,c_a)$. Indipendentemente dal numero di persone assunte, si dovrà sempre avere un colloquio con \textit{n} candidati e quindi si avrà sempre il costo $n\,c_c$ associato ai colloqui. Quindi si concentrerà l'attenzione sul costo di assunzione $m\,c_a$. Questa quantità varia ogni volta che viene eseguito l'algoritmo, ovvero, dipende dall'\textbf{ordine} dei candidati.

Nel caso peggiore, si assume ogni candidato con il quale si ha il colloquio. Questa situazione si verifica se i candidati si presentano in ordine strettamente crescente di qualità, nel qual caso si effettuano \textit{n} assunzioni, con un costo totale per le assunzioni pari a $O(n\,c_a)$.

Nel caso migliore, invece, il primo assunto è il migliore, quindi si farà una solo assunzione.
\section{Analisi probabilistica}
L'\textbf{analisi probabilistica} è l'uso della probabilità nell'analisi dei problemi. Tipicamente, si utilizza l'analisi probabilistica per analizzare il tempo di esecuzione di un algoritmo. A volte, la si utilizza per analizzare altre grandezze. Per svolgere un'analisi probabilistica si deve conoscere la distribuzione degli input o almeno fare delle ipotesi su tale distribuzione. Si analizza quindi l'algoritmo calcolando un tempo di esecuzione nel caso medio, dove la media è fatta sulla distribuzione degli input possibili. Quindi si sta mediando il tempo di esecuzione su tutti gli input possibili. Questo tempo di esecuzione è detto \textbf{tempo di esecuzione nel caso medio}.

Per il problema delle assunzioni è possibile supporre che i candidati arrivino in ordine casuale. Si suppone di poter confrontare due candidati qualsiasi e decidere quale dei due abbia i requisiti migliori; ovvero c'è un ordine totale nei candidati. Di conseguenza, è possibile classificare ogni candidato con un numero d'ordine unico da 1 a \textit{n}, utilizzando \textbf{rango(\textit{i})} per indicare il \textbf{numero d'ordine (rango)} del candidato \textit{i}, e adottare la convenzione che a un rango più alto corrisponda un candidato più qualificato. La lista ordinata $\langle rango(1),\,rango(2),\,...\,,\,rango(n)\rangle$ è una permutazione della lista $\langle 1,\,2,\,...\,,\,n\rangle$. Dire che i candidati si presentano in ordine casuale equivale a dire che questa lista di ranghi ha la stessa probabilità di essere una qualsiasi delle $n!$ permutazioni dei numeri da 1 a \textit{n}. In alternativa, si può dire che i ranghi formano una \textbf{permutazione casuale uniforme}, ovvero che ciascuna delle $n!$ possibili permutazioni si presenta con uguale probabilità.
\section{Variabili casuali indicatrici}
Dato uno spazio dei campioni \textit{S} e un evento \textit{A}, si definisce la variabile casuale indicatrice:
\begin{equation*}
I\{A\} = \left\{
\begin{array}{ll}
1 & \text{se si verifica \textit{A}} \\
0 & \text{se non si verifica \textit{A}}
\end{array}\right.
\end{equation*}
Queste variabili offrono un metodo comodo per la conversione tra probabilità e valori attesi. Il valore atteso di una variabile casuale indicatrice associata a un evento \textit{A} è uguale alla probabilità che si verifichi \textit{A}.
\begin{lemma}
Se \textit{S} è lo spazio dei campioni e \textit{A} è un evento nello spazio dei campioni \textit{S}, ponendo $X_A = I\{A\}$, si ha $E[X_A] = Pr\{A\}$.
\end{lemma}
\begin{proof}
È possibile dimostrare tale lemma considerando le definizioni di valore atteso e della variabile casuale indicatrice ed indicando con $\overline{A} = S - A$ il complementare di A:
\begin{align*}
E[X_A] &= E[I\{A\}] \\
&= 1 \cdot Pr\{A\} + 0 \cdot Pr\{\overline{A}\} \\
&= Pr\{A\}
\end{align*}
\end{proof}
Si fa una media ponderata dei possibili valori di $I\{A\}$. Queste variabili sono utili per analizzare situazioni in cui si effettuano ripetutamente delle prove casuali.
\subsubsection{Numero atteso di teste lanciando una moneta una volta}
Si considera una moneta imparziale.\\Lo spazio dei campioni è definito da $S = \{ T,\,C\}$ mentre la probabilità che esca testa, uguale alla probabilità che esca croce, è $Pr\{T\} = Pr\{C\} = 1/2$. Si definisce la variabile casuale indicatrice $X_T = I\{T\}$ dove $X_T$ conta il numero di teste in un lancio. Dal lemma si ottiene:\\$E[X_T] = Pr\{T\} = 1/2$.
\subsubsection{Numero atteso di teste in \textit{n} lanci}
Questo numero NON è una probabilità!\\Si definisce \textit{X} una variabile casuale per il numero di teste in \textit{n} lanci a cui è associato un valore atteso:
\begin{equation*}
E[X] = \sum_{k=0}^{n} k\cdot Pr\{X = k\}
\end{equation*}
La variabile casuale indicatrice $X_I = I\{$ \textit{i}-mo lancio è evento \textit{T} $\}$.
\begin{equation*}
X = \sum_{i=1}^{n}X_i
\end{equation*}
Il numero atteso di teste (\textit{T}) è:
\begin{equation*}
E[X] = E[\sum_{i=1}^{n}X_i] = \sum_{i=1}^{n}E[X_i] = \sum_{i=1}^{n}Pr\{T\} = \sum_{i=1}^{n}1/2 = n/2
\end{equation*}
Per la linearità dei valori attesi, il valore atteso della somma è uguale alla somma dei valori attesi.
\subsection{Analisi del problema delle assunzioni}
Si vuole calcolare il numero previsto di volte che si assume un nuovo impiegato. Per applicare l'analisi probabilistica si suppone che i candidati arrivino in ordine \textbf{casuale}. Sia \textit{X} la variabile casuale il cui valore è uguale al numero di volte che si assume un nuovo impiegato. Applicando la definizione di valore atteso si ottiene:
\begin{equation*}
E[X] = \sum_{x=1}^{n}x\cdot Pr\{X = x\}
\end{equation*}
Il calcolo di questa espressione non è semplice, per questo motivo su utilizzano le variabili casuali indicatrici per semplificarlo notevolmente.

Per utilizzare le variabili casuali indicatrici, anziché calcolare $E[X]$ definendo una variabile associata al numero di volte che si assume un nuovo impiegato, si definiscono \textit{n} variabili correlate al fatto che il candidato venga assunto oppure no. In particolare, si indica con $X_i$ la variabile casuale indicatrice associata all'evento in cui l'\textit{i}-esimo candidato sia assunto, ovvero:
\begin{equation*}
X_i = I\{\,\text{il candidato \textit{i} è assunto}\,\} = \left\{
\begin{array}{ll}
1 & \text{se il candidato \textit{i} è assunto} \\
0 & \text{se il candidato \textit{i} non è assunto}
\end{array}\right.
\end{equation*}
E
\begin{equation*}
X = X_1 + X_2 + X_3 + ... + X_n
\end{equation*}
Per il lemma precedentemente dimostrato si ottiene che:
\begin{equation*}
E[X_i] = Pr\{\,\text{il candidato \textit{i} è assunto}\,\}
\end{equation*}
Quindi si deve calcolare la probabilità che le righe 5 - 6 di \textsc{Hire-Assistant} siano eseguite. Ovvero, si deve calcolare $Pr\{$\,il candidato \textit{i} è assunto\,$\}$.

Il candidato \textit{i} è assunto se e solo se è migliore di tutti i precedenti candidati da 1 a $i - 1$. Poiché si è ipotizzato che i candidati arrivino in ordine casuale, i primi \textit{i} candidati si sono presentati in ordine casuale. Uno qualsiasi dei primi \textit{i} candidati ha la stessa probabilità di essere classificato come il migliore di tutti. Il candidato \textit{i} ha la probabilità $1/i$ di essere qualificato migliore dei candidati da 1 a $i - 1$ e, quindi, ha la probabilità $1/i$ di essere assunto (prima arriva più ha una alta probabilità di essere assunto). Per il lemma si conclude che:
\begin{equation*}
E[X_i] = \frac{1}{i}
\end{equation*}
Adesso è possibile calcolare $E[X]$:
\begin{align*}
E[X] &= E\Biggl[\sum_{i=1}^{n}X_i\Biggr] \\
&= \sum_{i=1}^{n}E[X_i] \\
&= \sum_{i=1}^{n}\frac{1}{i} \\
&= ln\,n + O(1)
\end{align*}
Questo perchè $\sum_{k=1}^{n}\frac{1}{k}$ è la serie armonica.\\Nonostante vengano intervistati \textit{n} candidati, ne verranno assunti soltanto approssimativamente lg\,\textit{n}, in media. Quindi, supponendo che i candidati si presentino in ordine casuale, l'algoritmo \textsc{Hire-Assistant} ha un costo totale per le assunzioni pari a $O(c_a\,lg\,n)$. Il costo per le assunzioni nel caso medio è un significativo miglioramento rispetto al costo $O(n\,c_a)$ per le assunzioni nel caso peggiore.
\section{Algoritmi randomizzati}
Per poter utilizzare l'analisi probabilistica, si deve sapere qualcosa sulla distribuzione degli input. In molti casi però si hanno scarse (se non nulle) informazioni su tale distribuzione. Anche quando si hanno delle informazioni  sulla distribuzione degli input, si potrebbe non essere in grado di modellare computazionalmente questa conoscenza. È però spesso possibile utilizzare la probabilità e la causalità come strumento per progettare e analizzare gli algoritmi, rendendo casuale il comportamento di parte dell'algoritmo.

In generale si dice che un algoritmo è \textbf{randomizzato} se il suo comportamento è determinato non soltanto dal suo input, ma anche dai valori prodotti da un \textbf{generatore di numeri casuali}. Si suppone di avere a disposizione un generatore di numeri casuali, chiamato \textsc{Random}. Una chiamata di \textsc{Random(\textit{a},\,\textit{b})} restituisce un numero intero compreso tra \textit{a} e \textit{b} estremi inclusi; ciascuno di questi numeri interi ha la stessa probabilità di essere generato. Ogni intero generato da \textsc{Random} è indipendente dagli interi generati nelle precedenti chiamate.

Quando si analizza il tempo di esecuzione di un algoritmo randomizzato, si considera il valore atteso del tempo di esecuzione rispetto alla distribuzione dei valori restituiti dal generatore di numeri casuali. Si distinguono questi algoritmi da quelli in cui l'input è casuale, chiamando il tempo di esecuzione di un algoritmo randomizzato \textbf{tempo di esecuzione atteso}. In generale, si considera il tempo di esecuzione nel caso medio quando la distribuzione della probabilità riguarda gli input dell'algoritmo, mentre si considera il tempo di esecuzione atteso quando l'algoritmo stesso effettua delle scelte casuali.
\subsection{Problema delle assunzioni randomizzato}
Nel problema delle assunzioni, sembra che i candidati si presentino in ordine casuale, tuttavia non si ha modo di sapere se ciò sia vero o no. Quindi, per sviluppare un algoritmo randomizzato per il problema delle assunzioni, si deve avere un controllo maggiore sull'ordine in cui si svolgono i colloqui con i candidati; per questo motivo, si modificherà leggermente il modello. Si suppone, infatti, che l'agenzia di selezione del personale abbia \textit{n} candidati e che invii in anticipo una lista dei candidati. Sebbene non si abbiano informazioni sui candidati, si ha un significativo cambiamento. Anziché fare affidamento sull'ipotesi che i candidati si presentino in ordine casuale, si ha ora il controllo del processo e si può quindi imporre un ordine casuale.

Anziché ipotizzare una distribuzione degli input, se ne impone una. In pratica, prima di eseguire l'algoritmo, si permutano casualmente i candidati per imporre la proprietà che ogni permutazione sia egualmente probabile. Benché l'algoritmo sia stato modificato, ci si aspetta ancora di assumere un nuovo impiegato approssimativamente $lg\,n$ volte. Ma ora ci si aspetta che questo accada per ogni input e non soltanto per quelli estratti da una particolare distribuzione.

Ogni volta che si esegue l'algoritmo, l'esecuzione dipende dalle scelte casuali fatte ed è probabile che sia diversa dalle precedenti esecuzioni. Per questo algoritmo e per molti altri algoritmi randomizzati, nessun input particolare determina il caso peggiore. L'algoritmo randomizzato si comporta male soltanto se il generatore di numeri casuali produce una permutazione sventurata.

Per il problema delle assunzioni, l'unica modifica da apportare al codice è permutare casualmente l'array.\\\\
\textsc{Randomized-Hire-Assistant(\textit{n})}\\
1\firsttab Permutare casualmente la lista dei candidati\\
2\firsttab\textsc{Hire-Assistant(\textit{n})}\\\\
Ovvero\\\\
\textsc{Randomized-Hire-Assistant(\textit{n})}\\
1\firsttab Permutare casualmente la lista dei candidati\\
2\firsttab $best \leftarrow 0$\\
3\firsttab\textbf{for} $i \leftarrow 1$ \textbf{to} \textit{n}\\
4\secondtab Colloquio con il candidato \textit{i}\\
5\secondtab\textbf{if} (il candidato \textit{i} è migliore del candidato \textit{best})\\
6\thirdtab$best \leftarrow i$\\
7\thirdtab Assumi candidato \textit{i}\\\\
Con questa modifica è stato creato un algoritmo  randomizzato le cui prestazioni corrispondono a quelle ottenute supponendo che i candidati si presentino in ordine casuale. Il costo previsto per assumere nuovi impiegati nella procedura \textsc{Randomized-Hire-Assistant} è $O(c_a\,ln\,n)$, perché avendo permutato l'array di input si ha una situazione identica all'analisi probabilistica di \textsc{Hire-Assistant} deterministico.

La permutazione casuale di un array si realizza tramite permutazioni \textbf{sul posto}. Si vuole una \textbf{permutazione casuale uniforme}:\\\\
\textsc{Randomize-In-Place(\textit{n})}\\
1\firsttab$n \leftarrow$ A.\textit{length}\\
2\firsttab\textbf{for} $i \leftarrow 1$ \textbf{to} \textit{n}\\
3\secondtab scambia A[\textit{i}] $\leftrightarrow$ A[\textsc{Random(\textit{i\,,\,n})}]\\\\
Richiede un tempo $O(1)$ per ogni iterazione, dunque $O(n)$ totale.
\chapter{Quicksort}
\textsc{Quicksort} è un algoritmo di ordinamento il cui tempo di esecuzione nel caso peggiore (quando gli elementi sono già ordinati) è $\Theta(n^2)$ con un array di input di \textit{n} numeri. Nonostante questo tempo di esecuzione nel caso peggiore sia molto alto, \textsc{Quicksort} spesso è la soluzione pratica migliore per effettuare un ordinamento, perché mediamente è molto efficiente: il suo tempo di esecuzione atteso è $\Theta(n\,lg\,n)$ e i fattori costanti nascosti nella notazione $\Theta(n\,lg\,n)$ sono molto piccoli. Inoltre ha il vantaggio di ordinare \textbf{sul posto} e funziona bene anche in ambienti con memoria virtuale. 
\section{L'algoritmo Quicksort}
L'algoritmo \textsc{Quicksort}, come \textsc{Merge-Sort}, è basato sul paradigma divide et impera. Per ordinare \textit{A}[\textit{p}\,...\,\textit{r}]:
\begin{description}
\item[Divide]Partiziona l'array \textit{A}[\textit{p}\,...\,\textit{r}] in due sottoarray \textit{A}[\textit{p}\,...\,\textit{q} - 1] e \textit{A}[\textit{q} + 1\,...\,\textit{r}], eventualmente vuoti, tali che ogni elemento di \textit{A}[\textit{p}\,...\,\textit{q} - 1] sia minore o uguale del \textbf{pivot} \textit{A}[\textit{q}] che, a sua volta, è minore o uguale a ogni elemento del sottoarray \textit{A}[\textit{q} + 1\,...\,\textit{r}]. È in questa fase che viene calcolato \textit{q}
\item[Impera]Ordina i due sottoarray \textit{A}[\textit{p}\,...\,\textit{q} - 1] e \textit{A}[\textit{q} + 1\,...\,\textit{r}] chiamando ricorsivamente \textsc{Quicksort}
\item[Combina]Poiché i sottoarray sono già ordinati, non occorre alcun lavoro per combinarli: l'intero array \textit{A}[\textit{p}\,...\,\textit{r}] è ordinato
\end{description}
Per ordinare un intero array \textit{A}, la chiamata iniziale è \textsc{Quicksort(\textit{A},\,1,\,\textit{A.length})}.\\La seguente procedura implementa \textsc{Quicksort}.\\\\
\textsc{Quicksort(\textit{A},\,\textit{p},\,\textit{r})}\\
1\firsttab\textbf{if} $p < r$\\
2\secondtab\textit{q} $\leftarrow$ \textsc{Partition(\textit{A},\,\textit{p},\,\textit{r})}\\
3\secondtab\textsc{Quicksort(\textit{A},\,\textit{p},\,$q-1$)}\\
4\secondtab\textsc{Quicksort(\textit{A},\,$q+1$,\,\textit{r})}\\\\
L'elemento chiave dell'algoritmo è la procedura \textsc{Partition} che riarrangia il sottoarray \textit{A}[\textit{p}\,...\,\textit{r}] sul posto.\\\\
\textsc{Partition(\textit{A},\,\textit{p},\,\textit{r})}\\
1\firsttab\textit{x} $\leftarrow$ \textit{A}[\textit{r}]\\
2\firsttab$i \leftarrow p - 1$\\
3\firsttab\textbf{for} $j \leftarrow p$ \textbf{to} $r - 1$\\
4\secondtab\textbf{if} \textit{A}[\textit{j}] $\leq x$\\
5\thirdtab$i \leftarrow i + 1$\\
6\thirdtab \textit{A}[\textit{i}] $\leftrightarrow$ \textit{A}[\textit{j}]\\
7\firsttab \textit{A}[$i + 1$] $\leftrightarrow$ \textit{A}[\textit{r}]\\
8\firsttab\textbf{return} $i + 1$\\\\
Commenti:
\begin{enumerate}
\item[0]\textsc{Partition} è una funzione ausiliaria. Mette a sinistra gli elementi minori del pivot \textit{A}[\textit{r}] e a destra quelli maggiori
\item[2]La sottoparte minore del pivot va da \textit{p} ad \textit{i}
\item[3]La sottoparte maggiore del pivot va da $i + 1$ a $j - 1$
\item[7]Sposta il pivot nella posizione corretta
\end{enumerate}
\textsc{Partition} seleziona sempre un elemento \textit{x} = \textit{A}[\textit{r}] come \textbf{pivot} intorno al quale partizionare il sottoarray \textit{A}[\textit{p}\,...\,\textit{r}]. Durante l'esecuzione della procedura, l'array viene suddiviso in quattro regioni (eventualmente vuote). All'inizio di ogni iterazione del ciclo \textbf{for} (righe 3 - 6) ogni regione soddisfa l'invariante di ciclo:
\begin{quote}
\textit{All'inizio di ogni iterazione del ciclo \textbf{for}, righe 3 - 6, si verifica che:}
\begin{enumerate}
\item$A[r] \leftarrow pivot$
\item$\forall\,A[x] \in A[\textit{p}\,..\,\textit{i}] : A[x] \leq pivot$
\item$\forall\,A[x] \in A[\textit{i} + 1\,..\,\textit{j} - 1] : A[x] > pivot$
\item$\forall\,A[x] \in A[\textit{j}\,..\,\textit{r} - 1] : A[x]$ \textit{non è stato esaminato}
\end{enumerate}
\end{quote}
Si dimostra ora la sua validità:
\begin{description}
\item[Inizializzazione]Prima della prima iterazione del ciclo, $i = p - 1$ e $j = p$. Non ci sono valori fra \textit{p} ed \textit{i} né fra $i + 1$ e $j - 1$, quindi la seconda e la terza condizione dell'invariante di ciclo sono soddisfatte. L'assegnazione della riga 1 soddisfa la prima
\item[Conservazione]Ci sono due casi da considerare a seconda del risultato del test nella riga 4. Se \textit{A}[\textit{j}] $>$ \textit{pivot}, l'unica azione nel ciclo è incrementare \textit{j}. Dopo l'incremento di \textit{j} la terza condizione è soddisfatta per \textit{A}[$j - 1$] e tutte le altre posizioni non cambiano. Se invece \textit{A}[\textit{j}] $\leq$ \textit{pivot}, viene incrementato l'indice \textit{i}, vengono scambiati \textit{A}[\textit{i}] e \textit{A}[\textit{j}] e successivamente viene incrementato l'indice \textit{j}. In seguito allo scambio si ha \textit{A}[\textit{i}] $\leq x$ e la seconda condizione è soddisfatta. Analogamente, anche \textit{A}[$j - 1$] $> x$, in quanto l'elemento che è stato spostato in \textit{A}[$j - 1$] è, per l'invariante di ciclo, più grande di \textit{x}
\item[Conclusione]Alla fine del ciclo $j = r$. Pertanto, ogni posizione dell'array si trova in uno dei tre insiemi descritti dall'invariante: quelli minori o uguali a \textit{x}, quelli maggiori di \textit{x} e un insieme di un solo elemento che contiene \textit{x}
\end{description}
L'output di \textsc{Partition} soddisfa le specifiche del passo \textsl{divide}. In effetti, esso soddisfa una condizione un po' più severa: dopo la riga 2 di \textsc{Quicksort}, \textit{A}[\textit{q}] è strettamente minore di \textit{A}[\textit{q} + 1\,...\,\textit{r}].

Il tempo di esecuzione di \textsc{Partition} con il sottoarray \textit{A}[\textit{p}\,...\,\textit{r}] è $\Theta(n)$, dove $n = r - p + 1$ è la dimensione dell'array di interesse.
\section{Prestazioni di Quicksort}
Il tempo di esecuzione di \textsc{Quicksort} dipende dal fatto che il partizionamento sia bilanciato o sbilanciato e questo, a sua volta, dipende da quali elementi vengono utilizzati per il partizionamento. Se il partizionamento è \textbf{bilanciato}, l'algoritmo viene eseguito con la stessa velocità asintotica di \textsc{Merge-Sort}. Se il partizionamento è \textbf{sbilanciato}, l'algoritmo può essere asintoticamente lento quanto \textsc{Insertion-Sort}. Il caso medio è analogo a \textsc{Merge-Sort}.
\subsection{Partizionamento nel caso peggiore}
Il comportamento nel caso peggiore di \textsc{Quicksort} si verifica quando la routine di partizionamento produce un sottoproblema con $n - 1$ elementi e uno con $0$ elementi, quindi sottoarray completamente sbilanciati. Si suppone ora che tale sbilanciamento si verifichi in ogni chiamata ricorsiva. Il partizionamento costa $\Theta(n)$ in termini di tempo. Poiché per una chiamata ricorsiva su un array vuoto $T(0) = \Theta(1)$, la ricorrenza per il tempo di esecuzione può essere espressa così:
\begin{align*}
T(n) &= T(n -1) + T(0) + \Theta(n) \\
&= T(n - 1) + \Theta(n) \\
&= \Theta(n^2)
\end{align*}
Applicando il metodo di sostituzione alla ricorrenza si arriva al risultato $\Theta(n^2)$.

In definitiva, il tempo di esecuzione nel caso peggiore di \textsc{Quicksort} non è migliore di quello di \textsc{Insertion-Sort}. Inoltre, il tempo di esecuzione $\Theta(n^2)$ si ha quando l'array di input è già completamente ordinato - una situazione tipica in cui \textsc{Insertion-Sort} è eseguito nel tempo $O(n)$, non a caso è il suo caso migliore.
\subsection{Partizionamento nel caso migliore}
Nel caso di bilanciamento massimo, cioè quando il pivot è il valore di mezzo, \textsc{Partition} produce due sottoproblemi, ciascuno di dimensione non maggiore di $n/2$, in quanto uno ha dimensione $\lfloor n/2 \rfloor$ e l'altro ha dimensione $\lceil n/2 \rceil - 1$. In questo caso, \textsc{Quicksort} viene eseguito molto più velocemente. La ricorrenza per il tempo di esecuzione è
\begin{equation*}
T(n) = 2\,T(n/2) + \Theta(n)
\end{equation*}
Che per il \textbf{caso 2} del teorema dell'esperto, ha soluzione $T(n) = \Theta(n\,lg\,n)$. Dunque, il perfetto bilanciamento dei due lati della partizione a ogni livello di ricorsione produce un algoritmo asintoticamente più veloce.
\subsection{Partizionamento bilanciato}
Il tempo di esecuzione nel caso medio di \textsc{Quicksort} è molto più vicino al caso migliore che al caso peggiore.

Supponendo, per esempio, che l'algoritmo di partizionamento produca sempre una ripartizione proporzionale 9 a 1, in questo caso si ottiene la ricorrenza
\begin{equation*}
T(n) = T(9n/10) + T(n/10) + \Theta(n) 
\end{equation*}
Che corrisponde alla disuguaglianza
\begin{equation*}
T(n) \leq T(9n/10) + T(n/10) + cn
\end{equation*}
Ogni livello ha un costo \textit{cn}, finché non viene raggiunta una condizione al contorno alla profondità $log_{10}{\,n} = \Theta(lg\,n)$, dopo la quale i livelli hanno al massimo un costo $cn$. Questo perché si hanno $log_{10}{\,n}$ livelli pieni e $log_{10/9}{\,n}$ non vuoti.

La ricorsione termina alla profondità $log_{10/9}{\,n} = \Theta(lg\,n)$. Il costo totale di \textsc{Quicksort} è dunque $O(n\,lg\,n)$. Pertanto, con una partizione proporzionale 9 a 1 ad ogni livello di ricorsione, \textsc{Quicksort} viene eseguito nel tempo $O(n\,lg\,n)$ - asintoticamente uguale a quello che si ha nel caso di partizione esattamente a metà. Qualsiasi ripartizione con proporzionalità costante produce un albero di ricorsione di profondità $\Theta(lg\,n)$, dove il costo in ogni livello è $O(n)$. Il tempo di esecuzione è quindi $O(n\,lg\,n)$ quando la ripartizione ha proporzionalità costante.
\subsection{Intuizione sul caso medio}
Il comportamento di \textsc{Quicksort} è determinato dall'ordinamento relativo dei valori degli elementi dell'array che sono dati come input, non dai particolari valori dell'array. Si suppone di alternare dei tagli buoni (ripartizione bilanciata - caso migliore) e cattivi (ripartizione molto sbilanciata - caso peggiore). Ciò significa che si alternano casi in cui il pivot è il valore di mezzo (bilanciato) e casi in cui il pivot è il valore massimo o minimo (completamente sbilanciato). L'albero di ripartizione ha radice con costo del partizionamento uguale a \textit{n} e i sottoarray prodotti hanno dimensione $0$ e $n - 1$, ovvero il caso peggiore. Nel livello successivo il sottoarray di dimensione $n - 1$ è ripartito in due sottoarray di dimensioni $\frac{n - 1}{2} - 1$ e $\frac{n - 1}{2}$, ovvero il caso migliore. Si suppone che il costo della condizione al contorno sia 1 per il sottoarray di dimensione 0.

La combinazione della ripartizione cattiva del caso peggiore, seguita dalla ripartizione buona del caso migliore, produce tre sottoarray di dimensioni pari a $0$, $\frac{n - 1}{2} - 1$ e $\frac{n - 1}{2}$ con un costo di partizionamento complessivo dato da $\Theta(n) + \Theta(n - 1) = \Theta(n)$ (ogni nodo a sinistra ha $\Theta(n) + \Theta(n - 1) = \Theta(n)$, invece ogni nodo a destra $\Theta(n)$). Intuitivamente, il costo $\Theta(n - 1)$ del caso peggiore può essere assorbito nel costo $\Theta(n)$ del caso migliore, quindi la ripartizione risultante è buona. In definitiva, il tempo di esecuzione di \textsc{Quicksort}, quando i livelli si alternano tra buone e cattive ripartizioni, è come il tempo di esecuzione nel caso in cui le ripartizioni siano soltanto buone: $O(n\,lg\,n)$ ma con una costante un po' più grande nascosta dalla notazione $O$.
\section{Quicksort randomizzato}
Nell'analisi del comportamento di \textsc{Quicksort} nel caso medio, si è supposto che tutte le permutazioni dei numeri di input fossero  ugualmente probabili. Nella pratica però, non è possibile aspettarsi che questo sia sempre vero. come già visto, a volte è possibile aggiungere la randomizzazione a un algoritmo per ottenere una buona prestazione attesa con tutti gli input. Per \textsc{Quicksort} si adotta un metodo di randomizzazione chiamato \textbf{campionamento casuale} che consente di semplificare l'analisi. Anziché utilizzare sempre \textit{A}[\textit{r}] come pivot, si utilizzerà un elemento scelto a caso dal sottoarray \textit{A}[\textit{p}\,...\,\textit{r}]. Per fare questo, si scambierà l'elemento \textit{A}[\textit{r}] con un elemento scelto a caso da \textit{A}[\textit{p}\,...\,\textit{r}]. Questa modifica, con la quale si campiona a caso l'intervallo \textit{p}\,...\,\textit{r}, assicura che l'elemento pivot \textit{x} = \textit{A}[\textit{r}] avrà la stessa probabilità di essere uno qualsiasi degli $r - p + 1$ elementi del sottoarray. Poiché il pivot viene scelto a caso, ci si aspetta che la ripartizione dell'array di input sia ben bilanciata in media.

Nella nuova procedura di partizionamento, si implementerà semplicemente lo scambio prima dell'effettivo partizionamento:\\\\
\textsc{Randomized-Partition(\textit{A},\,\textit{p},\,\textit{r})}\\
1\firsttab$i \leftarrow $ \textsc{Random(\textit{p},\,\textit{r})}\\
2\firsttab Scambia \textit{A}[\textit{r}] con \textit{A}[\textit{i}]\\
3\firsttab\textbf{return} \textsc{Partition(\textit{A},\,\textit{p},\,\textit{r})}\\\\
Il nuovo \textsc{Randomized-Quicksort} chiama \textsc{Randomized-Partition}, anziché \textsc{Partition}:\\\\
\textsc{Randomized-Quicksort(\textit{A},\,\textit{p},\,\textit{r})}\\
1\firsttab\textbf{if} $p < r$\\
2\secondtab\textit{q} $\leftarrow$ \textsc{Randomized-Partition(\textit{A},\,\textit{p},\,\textit{r})}\\
3\secondtab\textsc{Randomized-Quicksort(\textit{A},\,\textit{p},\,$q-1$)}\\
4\secondtab\textsc{Randomized-Quicksort(\textit{A},\,$q+1$,\,\textit{r})}\\\\
La randomizzazione impedisce a specifici input di causare sempre il caso peggiore. Per esempio: l'array ordinato è il caso peggiore per \textsc{Quicksort}, non per \textsc{Randomized-Quicksort}.
\section{Analisi del caso peggiore di Quicksort}
Come già visto, il caso peggiore di \textsc{Quicksort}, che si verifica quando ,ad ogni livello di ricorsione, si ha il peggior taglio, ha un tempo di esecuzione $\Theta(n^2)$.

Utilizzando il metodo di sostituzione applicato alla ricorrenza per il caso peggiore è possibile dimostrare che il tempo di esecuzione di \textsc{Quicksort} è $O(n^2)$ ed è anche $\Omega(n^2)$, quindi $\Theta(n^2)$. Sia $T(n)$ il tempo nel caso peggiore per la procedura \textsc{Quicksort} con un input di dimensione \textit{n}. Si ottiene la ricorrenza
\begin{equation*}
T(n) = \max_{0 \leq \,q\, \leq n-1} (T(q) + T(n - q - 1)) + \Theta(n)
\end{equation*}
La ricorrenza dipende da dove si trova il pivot rispetto ai dati. $T(q)$ è l'array sinistro, mentre $T(n - q -1)$ è l'array destro ($-1$ indica il pivot). Supponendo $T(n) \leq cn^2$ per qualche costante \textit{c} e sostituendo, si ottiene:
\begin{align*}
T(n) &\leq \max_{0 \leq \,q\, \leq n-1} (cq^2 + c(n - q - 1)^2) + \Theta(n) \\
&= c \cdot \max_{0 \leq \,q\, \leq n-1} (q^2 + (n - q - 1)^2) + \Theta(n)
\end{align*}
L'espressione $q^2 + (n - q - 1)^2$ è una parabola  con la concavità verso l'alto che raggiunge il suo massimo nei due estremi dell'intervallo $0 \leq \,q\, \leq n-1$ del parametro \textit{q}; ovvero con $q = 0$ o $q = n - 1$ (si sceglie $q  = 0$ che sbilancia del tutto). Questa osservazione fornisce il limite:
\begin{equation*}
\max_{0 \leq \,q\, \leq n-1} (q^2 + (n - q - 1)^2) \leq (n - 1)^2 = n^2 - 2n + 1
\end{equation*}
Riprendendo l'espressione di $T(n)$ , si ottiene:
\begin{align*}
T(n) &\leq cn^2 - c(2n - 1) + \Theta(n) \\
&\leq cn^2
\end{align*}
perché si può assegnare alla costante \textit{c} un valore sufficientemente grande affinché il termine $O(2n - 1)$ prevalga sul termine $\Theta(n)$; quindi $T(n) = O(n^2)$ è il caso peggiore. Ma il caso peggiore è anche $\Omega(n^2)$, quindi si ottiene $\Theta(n^2)$. Si è così dimostrato che $\Theta(n^2)$ è il caso peggiore di \textsc{Quicksort}.
\section{Tempo di esecuzione atteso e confronti}
Il tempo di esecuzione di \textsc{Quicksort} è dominato dal tempo impiegato dalla procedura \textsc{Partition} (cioè da quanti confronti vengono eseguiti in \textsc{Partition}; idealmente meno confronti si fanno, più è veloce, ma questo dipende dalla posizione e dal pivot cioè dalla disposizione). Ogni volta che viene chiamata la procedura \textsc{Partition}, viene selezionato un elemento pivot; questo elemento non sarà mai incluso nelle successive chiamate ricorsive di \textsc{Quicksort} e \textsc{Partition}. Quindi, ci possono essere al massimo \textit{n} chiamate di \textsc{Partition} durante l'intera esecuzione dell'algoritmo \textsc{Quicksort}. Una chiamata di \textsc{Partition} impiega il tempo $O(1)$ più una quantità di tempo che è proporzionale al numero di iterazioni del ciclo \textbf{for} nelle righe 3 - 6. Ogni iterazione di questo ciclo \textbf{for} effettua un confronto fra l'elemento pivot e un altro elemento dell'array A (riga 4). Pertanto, se si conta il numero totale di volte che la riga 4 viene eseguita, è possibile limitare il tempo totale impiegato nel ciclo \textbf{for} durante l'intera esecuzione di \textsc{Quicksort}.

Se $X$ è il numero \textbf{totale} di confronti svolti nella riga 4 di \textsc{Partition} nell'intera esecuzione di \textsc{Quicksort} su un array di \textit{n} elementi, allora il tempo di esecuzione di \textsc{Quicksort} (cioè il suo costo totale) è $O(n + X)$.

L'obiettivo è quindi quello di calcolare un limite al numero totale di confronti $X$ svolti in tutte le chiamate di \textsc{Partition}. Per semplificare l'analisi si rinominano $z_1,\,z_2,\,z_3,\,...\,,z_n$ gli elementi dell'array \textit{A}, dove $z_i \leq z_j$ se $i < j$ (ciò significa che ci si interessa all'ordine e non al valore). Si definisce anche $Z_{ij} = \{z_i,\,z_{i+1},...\,,z_j\}$ l'insieme degli elementi compresi tra $z_i$ e $z_j$, estremi inclusi. Gli elementi $z_i$ e $z_j$ sono confrontati al massimo una volta, in particolare, sono confrontati solo col pivot (quindi uno dei due in un momento è il pivot che verrà posizionato) e, dopo che una particolare chiamata di \textsc{Partition} finisce, il pivot utilizzato in questa chiamata non viene più confrontato con nessun altro elemento, cioè non è presente in chiamate successive. Alla fine di \textsc{Partition}, il pivot è nel posto giusto e lì rimane. 

Si definisce ora la variabile casuale indicatrice
\begin{equation*}
X_{ij} = I\{ z_i \text{ è confrontato con } z_j\}
\end{equation*}
Si stanno considerando i confronti che vengono eseguiti in un istante qualsiasi durante l'esecuzione dell'algoritmo, non soltanto durante un'iterazione o una chiamata di \textsc{Partition}. Poiché ogni coppia viene confrontata al massimo una volta, è possibile rappresentare facilmente il numero totale di confronti svolti dall'algoritmo in questo modo:
\begin{equation*}
X = \sum_{i=1}^{n-1}\sum_{j=i+1}^{n}X_{ij}
\end{equation*}
Prendendo i valori attesi da entrambi i lati e poi applicando la linearità del valore atteso, si ottiene:
\begin{align*}
E[X] &= E\Biggl[\sum_{i=1}^{n-1}\sum_{j=i+1}^{n}X_{ij}\Biggr] \\
&= \sum_{i=1}^{n-1}\sum_{j=i+1}^{n}E[X_{ij}] \\
&= \sum_{i=1}^{n-1}\sum_{j=i+1}^{n} Pr\{z_i \text{ è confrontato con } z_j\}
\end{align*}
Resta da calcolare \textit{Pr}$\{z_i \text{ è confrontato con } z_j\}$.\\Poiché si suppone che i valori degli elementi siano distinti, una volta che viene scelto un pivot \textit{x} con $z_i < x < z_j$, si sa che $z_i$ e $z_j$ non potranno essere confrontati in un istante successivo. Se, d'altra parte, viene scelto $z_i$ come pivot prima di qualsiasi altro elemento di $Z_{ij}$, allora $z_i$ sarà confrontato con ogni elemento di $Z_{ij}$, tranne sé stesso. Analogamente, se viene scelto $z_j$ come pivot prima di qualsiasi altro elemento di $Z_{ij}$, allora $z_j$ sarà confrontato con ogni elemento di $Z_{ij}$, tranne sé stesso. Quindi $z_i$ e $z_j$ vengono confrontati se e soltanto se il primo elemento che verrà scelto come pivot in $Z_{ij}$ è $z_i$ o $z_j$. Schematizzando
\begin{itemize}
\item Numeri in partizioni diverse mai confrontati
\begin{itemize}
\item[]Se $z_i < pivot < z_j \Rightarrow z_i$ e $z_j$ mai confrontati perché il pivot li separa e andranno in chiamate diverse
\end{itemize}
\item Se $z_i$ o $z_j$ scelto per primo in $Z_{ij}$ allora $z_i$ o $z_j$ confrontato con tutti gli altri elementi di $Z_{ij}$
\begin{itemize}
\item[]$\Rightarrow z_i$ e $z_j$ confrontati $\Leftrightarrow$ il \textbf{primo} pivot in $Z_{ij}$ è $z_i$ o $z_j$
\end{itemize}
\item Pivot scelti casualmente e indipendentemente $|Z_{ij}| = j - i + 1$
\begin{itemize}
\item[]$\Rightarrow$ probabilità $z_i$ o $z_j$ scelto per primo in $Z_{ij}$ è $\frac{1}{j-i+1}$
\end{itemize}
\end{itemize}
Quindi si ha
\begin{align*}
Pr\{z_i \text{ è confrontato con } z_j\} &= Pr\{z_i \text{\,o\,} z_j \text{ primo pivot scelto da } Z_{ij}\} \\
&= Pr\{z_i \text{ primo pivot scelto da } Z_{ij}\} \\
&= Pr\{z_j \text{ primo pivot scelto da } Z_{ij}\} \\
&= \frac{1}{j-i+1} + \frac{1}{j-i+1} \\
&= \frac{2}{j-i+1}
\end{align*}
Sostituendo in E[\textit{X}] si ottiene
\begin{equation*}
E[X] = \sum_{i=1}^{n-1}\sum_{j=i+1}^{n} Pr\{z_i \text{ è confrontato con } z_j\} = \sum_{i=1}^{n-1}\sum_{j=i+1}^{n}\frac{2}{j-i+1}
\end{equation*}
Si effettua un cambio di variabile $ k = j - i$
\begin{align*}
E[X] &= \sum_{i=1}^{n-1}\sum_{k=1}^{n-i}\frac{2}{k+1} \\
&< \sum_{i=1}^{n-1}\sum_{k=1}^{n}\frac{2}{k} \\
&=  \sum_{i=1}^{n-1}O(lg\,n) \\
&= O(n\,lg\,n)
\end{align*}
Quindi il \textbf{tempo di esecuzione atteso} di \textsc{Randomized-Quicksort} è $O(n\,lg\,n)$.
\chapter{Ordinamento in tempo lineare}
Come visto, alcuni algoritmi possono ordinare \textit{n} numeri nel tempo $O(n\,lg\,n)$. \textsc{Merge-Sort} raggiunge questo limite superiore nel caso peggiore; \textsc{Quicksort} lo raggiunge nel caso medio. Inoltre, per ciascuno di questi algoritmi, è possibile produrre una sequenza di \textit{n} numeri di input tale che l'algoritmo venga eseguito nel tempo $\Omega(n\,lg\,n)$.

Questi algoritmi sono detti \textbf{ordinamenti per confronti} perché l'ordinamento che effettuano è basato soltanto su confronti fra gli elementi di input. Qualsiasi ordinamento per confronti deve effettuare $\Omega(n\,lg\,n)$ confronti nel caso peggiore per ordinare \textit{n} elementi. Quindi \textsc{Merge-Sort} è asintoticamente ottimale e non esiste un ordinamento per confronti che sia più veloce per più di un fattore costante.

Esistono però degli algoritmi che vengono eseguiti in \textbf{tempo lineare}. Ovviamente questi algoritmi usano operazioni diverse dai confronti per effettuare l'ordinamento. Di conseguenza, il limite inferiore $\Omega(n\,lg\,n)$ non vale per questi algoritmi. Tra di essi compaiono \textsc{Counting-Sort} e \textsc{Radix-Sort}.
\section{Il modello dell'albero di decisione}
Gli ordinamenti per confronti possono essere visti astrattamente in termini di \textbf{alberi di decisione}. Un albero di decisione è un albero binario pieno che rappresenta i confronti fra elementi che vengono effettuati da un particolare algoritmo di ordinamento che opera su un input di una data dimensione. Il controllo, lo spostamento dei dati e tutti gli altri aspetti dell'algoritmo vengono ignorati.

In un albero di decisione, ogni nodo interno è annotato con $i:j$ per qualche \textit{i} e \textit{j} nell'intervallo $1 \leq i$, $j \leq n$, dove \textit{n} è il numero di elementi nella sequenza di input. Ogni foglia è annotata con una permutazione dei dati in input. L'esecuzione dell'algoritmo di ordinamento corrisponde a tracciare un cammino semplice dalla radice dell'albero di decisione fino a una foglia. Ogni nodo interno rappresenta un confronto $a_i \leq a_j$. Il sottoalbero sinistro detta i successivi confronti per $a_i \leq a_j$; il sottoalbero destro detta i successivi confronti per $a_i > a_j$. Quando raggiunge una foglia, l'algoritmo ha stabilito l'ordinamento corretto dell'input. 

Poiché qualsiasi algoritmo di ordinamento corretto deve essere in grado di produrre ogni permutazione del suo input, una condizione necessaria affinché un ordinamento per confronti sia corretto è che ciascuna delle $n!$ permutazioni di \textit{n} elementi appaia come una delle foglie dell'albero di decisione e che ciascuna di queste foglie sia raggiungibile dalla radice attraverso un percorso che corrisponde ad una effettiva esecuzione dell'ordinamento per confronti (queste foglie sono chiamata raggiungibili).
\subsection{Limite inferiore per il caso peggiore}
La lunghezza del cammino semplice più lungo dalla radice di un albero di decisione a una delle sue foglie raggiungibili rappresenta il numero di confronti che svolge il corrispondente algoritmo di ordinamento nel caso peggiore. Di conseguenza, il numero di confronti nel caso peggiore per un dato algoritmo di ordinamento per confronti è uguale all'altezza del suo albero di decisione. Un limite inferiore sulle altezze di tutti gli alberi di decisione , dove ogni permutazione compare in una foglia raggiungibile, è pertanto un limite inferiore sul tempo di esecuzione di qualsiasi algoritmo di ordinamento per confronti.
\begin{theorem}
Ogni albero binario di altezza \textit{h} ha al massimo $2^h$ foglie. Indicato con \textit{h} la sua altezza e con $l_h$ il numero di foglie, allora $l_h \leq 2^h$.
\end{theorem}
\begin{proof}
Si procede per induzione su \textit{h}:
\begin{itemize}
\item\textbf{Base:} Per $h = 0$, l'albero ha un solo nodo $\rightarrow 2^h = 1$
\item\textbf{Passo induttivo:} Si suppone \textbf{vero} per $h - 1$. Ogni foglia dell'albero di altezza $h - 1$ ha al massimo due nuove foglie, per cui
\begin{equation*}
l_h \leq 2\cdot l_{h-1} = 2\cdot 2^{h-1} = 2^h
\end{equation*}
\end{itemize}
\end{proof}
\begin{theorem}
Qualsiasi algoritmo di ordinamento per confronti richiede $\Omega(n\,lg\,n)$ confronti nel caso peggiore (cioè ogni albero di decisione che ordina \textit{n} elementi ha altezza $\Omega(n\,lg\,n)$).
\end{theorem}
\begin{proof}
È sufficiente determinare l'altezza di un albero di decisione dove ogni permutazione appare come una foglia raggiungibile. Si considera un albero di decisione di altezza \textit{h} con \textit{l} foglie raggiungibili che corrisponde ad un algoritmo per confronti di \textit{n} elementi. Poiché ciascuna delle $n!$ permutazioni dell'input compare in una foglia, si ha $n! \leq l$. Dal momento che un albero binario di altezza \textit{h} non ha più di $2^h$ foglie, si ha $n! \leq l \leq 2^h$. Prendendo i logaritmi, questa relazione implica che
\begin{align*}
h &\geq lg(n!) \text{\firsttab (perché la funzione logaritmo è monotona crescente)} \\
&\geq lg\Bigl(\frac{n}{e}\Bigr)^n \\
&= n\,lg\Bigl(\frac{n}{e}\Bigr) = n\,lg\,n - n\,lg\,e = \Omega(n\,lg\,n) 
\end{align*}
\end{proof}
Si usa $\Omega$ perché c'è $\geq$. Quindi \textsc{Merge-Sort} è un \textbf{ordinamento per confronto asintoticamente ottimo}, questo perché il limite superiore $O(n\,lg\,n)$ sul tempo di esecuzione di \textsc{Merge-Sort} corrisponde al limite inferiore $\Omega(n\,lg\,n)$.
\section{Counting sort}
L'algoritmo \textsc{Counting-Sort} suppone che ciascuno degli \textit{n} elementi di input sia un numero naturale compreso nell'intervallo 0 a \textit{k}, per qualche intero \textit{k}. Quando $k = O(n)$, l'ordinamento viene effettuato nel tempo $\Theta(n)$.

\textsc{Counting-Sort} determina, per ogni elemento di input \textit{x}, il numero di elementi minori di \textit{x}. Esso usa questa informazione per inserire l'elemento \textit{x} direttamente nella sua posizione nell'array di output. Questo schema deve essere leggermente modificato per gestire il caso in cui più elementi hanno lo stesso valore, per evitare che siano inseriti nella stessa posizione.

Nel codice di \textsc{Counting-Sort} si suppone che l'input sia un array \textit{A}[\textit{1\,...\,n}], quindi che \textit{length}[\textit{A}] = \textit{n}. Occorrono altri due array: \textit{B}[$1\,...\,n$], che contiene l'output ordinato, e l'array \textit{C}[$0\,...\,k$] che fornisce la memoria temporanea di lavoro (conta quante volte c'è ciascun valore). Quindi occupa il doppio dello spazio, al quale si aggiunge l'array \textit{C}.\\\\
\textsc{Counting-Sort(\textit{A},\,\textit{B},\,\textit{k})}\\
1\firsttab sia \textit{C}[$0\,..\,k$] un nuovo array \\
2\firsttab\textbf{for} $i \leftarrow 0$ \textbf{to} \textit{k} \\
3\secondtab \textit{C}[\textit{i}] $\leftarrow 0$ \\
4\firsttab\textbf{for} $j \leftarrow 1$ \textbf{to} A.\textit{length} \\
5\secondtab \textit{C}[\textit{A}[\textit{j}]] $\leftarrow$ \textit{C}[\textit{A}[\textit{j}]] + 1 \\
6\firsttab // \textit{C}[\textit{i}] ora contiene il numero di elementi uguali a \textit{i} \\
7\firsttab\textbf{for} $i \leftarrow 1$ \textbf{to} \textit{k} \\
8\secondtab \textit{C}[\textit{i}] $\leftarrow$ \textit{C}[\textit{i}] + \textit{C}[\textit{i - 1}] \\
9\firsttab // \textit{C}[\textit{i}] ora contiene il numero di elementi minori o uguali a \textit{i} \\
10\firsttab\textbf{for} $j \leftarrow$ \textit{A.length} \textbf{downto} 1 \\
11\secondtab \textit{B}[\textit{C}[\textit{A}[\textit{j}]]] $\leftarrow$ \textit{A}[\textit{j}] \\
12\secondtab \textit{C}[\textit{A}[\textit{j}]] $\leftarrow$ \textit{C}[\textit{A}[\textit{j}]] - 1\\\\
Commenti:
\begin{enumerate}
\item[0]\textit{k} è il valore massimo da ordinare
\item[2-3]Azzera il vettore contatore
\item[4-5]Scorre e conta quante volte c'è \textit{A}[\textit{j}]
\item[7-8]Scorre \textit{C} dal primo all'ultimo elemento senza toccare \textit{C}[0] che indica il numero di elementi uguali a 0 nell'array
\item[10]Parte dal fondo (per avere stabilità) e lo posiziona
\item[12]Più elementi potrebbero avere lo stesso valore
\end{enumerate}
Dopo che il ciclo \textbf{for} (righe 2 - 3) inizializza a zero tutti gli elementi dell'array \textit{C}, ogni elemento di input viene esaminato nelle righe 4 - 5 del ciclo \textbf{for}. Se il valore di un elemento di input è \textit{i}, si incrementa \textit{C}[\textit{i}]. Quindi, dopo la riga 5, \textit{C}[\textit{i}] contiene il numero degli elementi di input uguali a \textit{i} per ogni intero $i = 0,\,1,\,...\,,\,k$. Le righe 7 - 8 determinano, per ogni $i = 0,\,1,\,...\,,\,k$, quanti elementi di input sono minori o uguali a \textit{i}, mantenendo la somma corrente dell'array \textit{C}. Infine, le righe 10 - 12 del ciclo \textbf{for} inseriscono l'elemento \textit{A}[\textit{j}] nella corretta posizione ordinata dell'array di output \textit{B}.

Se tutti gli \textit{n} elementi sono distinti, quando viene eseguita per la prima volta la riga 10, per ogni \textit{A}[\textit{j}], il valore \textit{C}[\textit{A}[\textit{j}]] rappresenta la posizione finale corretta di \textit{A}[\textit{j}] nell'array di output, in quanto ci sono \textit{C}[\textit{A}[\textit{j}]] elementi minori o uguali ad \textit{A}[\textit{j}]. Poiché gli elementi potrebbero non essere distinti, \textit{C}[\textit{A}[\textit{j}]] viene ridotto ogni volta che viene inserito un valore \textit{A}[\textit{j}] nell'array \textit{B}. La riduzione di \textit{C}[\textit{A}[\textit{j}]] fa sì che il successivo elemento di input con un valore uguale ad \textit{A}[\textit{j}], se esiste, venga inserito nella posizione immediatamente prima di \textit{A}[\textit{j}] nell'array di output.

Il ciclo \textbf{for} alle righe 2 - 3 impiega un tempo $\Theta(k)$, il ciclo \textbf{for} alle righe 4 - 5 impiega un tempo $\Theta(n)$, il ciclo \textbf{for} alle righe 7 - 8 impiega un tempo $\Theta(k)$ e il ciclo \textbf{for} alle righe 10 - 12 impiega un tempo $\Theta(n)$. Quindi il tempo totale è $\Theta(k + n)$. Di solito \textsc{Counting-Sort} viene utilizzato quando $k = O(n)$, nel qual caso il tempo di esecuzione è $\Theta(n)$, quindi un ordinamento in \textbf{tempo lineare}. \textsc{Counting-Sort} batte il limite inferiore di $\Omega(n\,lg\,n)$ perché non è un algoritmo di ordinamento per confronti. Infatti, il codice non effettua alcun confronto fra gli elementi di input. Piuttosto, \textsc{Counting-Sort} usa i valori effettivi degli elementi come indici di un array.\\

Un'importante proprietà di \textsc{Counting-Sort} è la \textbf{stabilità}: le chiavi con lo stesso valore si presentano nell'array di output nello stesso ordine in cui si trovano nell'array in input. Ovvero, l'uguaglianza di due numeri viene risolta applicando la seguente regola: il numero che si presenta per primo nell'array di input sarà inserito per primo nell'array di output. Normalmente, la proprietà di stabilità è importante soltanto quando i dati satellite vengono spostati insieme con le chiavi da ordinare. Per verificare che \textsc{Counting-Sort} è un algoritmo stabile è sufficiente guardare come funziona l'ultimo ciclo \textbf{for}. La correttezza di \textsc{Counting-Sort} può essere verificata tramite invariante di ciclo.
\section{Radix sort}
L'algoritmo \textsc{Radix-Sort} risolve il problema dell'ordinamento in una maniera contraria all'intuizione, ordinando le cifre \textbf{meno significative} per prime. Indicato con \textit{d} il numero di cifre che costituiscono i valori da ordinare, occorreranno soltanto \textit{d} passaggi per completare l'ordinamento. È essenziale che gli ordinamenti delle cifre in questo algoritmo siano \textbf{stabili}.\\\\
\textsc{Radix-Sort(\textit{A},\,\textit{d})}\\
1\firsttab\textbf{for} $i \leftarrow 1$ \textbf{to} \textit{d} \\
2\secondtab Usa un ordinamento \textbf{stabile} per ordinare l'array \textit{A} sulla cifra \textit{i}\\\\
Sono algoritmi \textbf{stabili} \textsc{Counting-Sort}, \textsc{Insertion-Sort}, \textsc{Merge-Sort} se in \textsc{Merge} c'è il $\leq$ e non $<$, \textsc{Quicksort} non è detto che lo sia.
\subsection{Correttezza di Radix sort}
La correttezza di \textsc{Radix-Sort} si dimostra per induzione sulla colonna \textit{i} da ordinare:
\begin{enumerate}
\item Si suppone che le cifre $1,\,2,\,...\,,\,i - 1$ siano ordinate
\begin{itemize}
\item Se due cifre in posizione \textit{i} sono \textbf{diverse}
\begin{itemize}
\item[]$\Rightarrow$ ordinamento su posizione \textit{i} è corretto
\end{itemize}
\item[]Le posizioni $1,\,...\,,\,i - 1$ sono irrilevanti
\item Se 2 cifre in posizione \textit{i} sono \textbf{uguali} (es. 23 e 25)
\begin{itemize}
\item[]$\Rightarrow$ i numeri sono già nell'ordine giusto (ipotesi induttiva)
\end{itemize}
\item[]Ordinamento \textbf{stabile} sulla cifra \textit{i} li lascia nell'ordine giusto
\end{itemize}
\item$\Rightarrow$ ordinamento \textbf{stabile} sulla cifra \textit{i} lascia le cifre $1,\,...\,,\,i$ ordinate
\end{enumerate}
\subsection{Analisi di Radix sort}
Dati \textit{n} numeri di \textit{d} cifre, dove ogni cifra può avere fino a \textit{k} valori possibili, la procedura \textsc{Radix-Sort} ordina correttamente i numeri nel tempo $\Theta(d(n + k))$, se l'ordinamento stabile utilizzato nella procedura impiega un tempo $\Theta(n + k)$. Se \textit{d} è costante e $k = O(n)$ allora \textsc{Radix-Sort} viene eseguito in tempo lineare, cioè $\Theta(d\,n)$.

L'analisi del tempo di esecuzione dipende dall'ordinamento stabile che viene utilizzato come algoritmo di ordinamento intermedio. Se ogni cifra si trova nell'intervallo da 0 a $k - 1$ e $k$ non è troppo grande, \textsc{Counting-Sort} è la scelta ovvia da fare.

Date \textit{n} parole di \textit{b} bit diverse e un intero positivo $r \leq b$. È possibile suddividere tali parole in pezzi di \textit{r} bit; ciascuna parola ha $d = \lceil b/r \rceil$ cifre di \textit{r} bit. È possibile applicare \textsc{Counting-Sort} con $k = 2^r - 1$. Per esempio, per parole di 32 bit e cifre da 8 bit, si ha $b = 32$, $r = 8$, $d = \lceil b/r \rceil = \lceil 32/8 \rceil = 4$ e $k = 2^r -1 = 2^8 - 1 = 255$. Per \textit{n parole} di \textit{b} bit e un intero positivo $r \leq b$, \textsc{Radix-Sort} ordina correttamente questi numeri nel tempo $\Theta(\frac{b}{r}(n + 2^r))$ se l'algoritmo di ordinamento stabile usato richiede tempo $\Theta(n + k)$ per input nell'intervallo da 0 a \textit{k}.\\Si sceglie \textit{r} in modo da bilanciare $b/r$ e $n +2^r$:
\begin{itemize}
\item Scegliendo $r \approx lg\,n$ si ha una situazione ottimale:
\begin{itemize}
\item[]$\Theta(\frac{b}{r}(n + 2^r)) = \Theta(\frac{b}{lg\,n}(n + n)) = \Theta(\frac{bn}{lg\,n})$
\end{itemize}
\item[]Meglio di $\Theta(n)$
\item Se fosse $r < lg\,n \Rightarrow \frac{b}{r} > \frac{b}{lg\,n} \Rightarrow n + 2^r$ non migliora e resta a $\Theta(n)$
\item Se fosse $r > lg\,n \Rightarrow n + 2^r$ diventa più grande di \textit{n} per un fattore moltiplicativo
\end{itemize}
Per esempio, per ordinare $2^{16}$ numeri a 32 bit, si usa $r = lg\,2^{16} = 16$ bit, per un totale di $\lceil b/r \rceil = 2$ passi.
\subsection{Esempio di Radix sort}
L'algoritmo \textsc{Radix-Sort} risolve il problema dell'ordinamento in una maniera contraria all'intuizione, ordinando le cifre \textbf{meno significative} per prime. Indicato con \textit{d} il numero di cifre che costituiscono i valori da ordinare, occorreranno soltanto \textit{d} passaggi per completare l'ordinamento.\\\\
\begin{tabular}{ccrcccl}
& &S & &S & &S \\
326 & &69\textbf{0} & &7\textbf{0}4 & &\textbf{3}26\\
453 & &75\textbf{1}  & &6\textbf{0}8 & &\textbf{4}35\\
608 & &45\textbf{3} & &3\textbf{2}6 & &\textbf{4}53\\
835 & &70\textbf{4} & &8\textbf{3}5 & &\textbf{6}08\\
751 &$\rightarrow$ &83\textbf{5} &$\rightarrow$ &4\textbf{3}5 &$\rightarrow$ &\textbf{6}90\\
435 & &43\textbf{5} & &7\textbf{5}1 & &\textbf{7}04\\
704 & &36\textbf{6} & &4\textbf{5}3 & &\textbf{7}51\\
690 & &60\textbf{8} & &6\textbf{9}0 & &\textbf{8}35
\end{tabular}
\chapter{Hashing}
Una \textbf{tabella hash} è una struttura dati efficace per implementare i dizionari. Sebbene la ricerca di un elemento in una tabella hash richieda, nel caso peggiore, lo stesso tempo $\Theta(n)$ richiesto per ricercare un elemento in una lista concatenata, l'hashing, sotto opportune ipotesi, garantisce un tempo medio per ricercare un elemento in una tabella hash di $O(1)$.

Una tabella hash è una generalizzazione dell'indirizzamento diretto che, in un array ordinario, sfrutta la possibilità di esaminare una posizione arbitraria in un array nel tempo $O(1)$. Si può utilizzare vantaggiosamente l'indirizzamento diretto quando è possibile allocare un array che ha una posizione per ogni chiave possibile. Così facendo, dato un universo di chiavi \textit{U} che va da 0 a $k - 1$, dove \textit{k} è la lunghezza di un array, l'elemento con chiave \textit{k} si troverà nella posizione \textit{k}. Quando il numero di chiavi effettivamente memorizzate è piccolo rispetto al numero totale di chiavi possibili, le tabelle hash diventano una valida alternativa all'indirizzamento diretto di un array, in quanto una tabella hash tipicamente usa un array di dimensione proporzionale al numero di chiavi effettivamente memorizzate. Anziché utilizzare una chiave direttamente come un indice dell'array, la chiave viene usata per calcolare l'indice.
\section{Tabelle a indirizzamento diretto}
L'indirizzamento diretto è una tecnica che funziona bene quando l'universo delle chiavi $U = \{0,\,1,\,2,\,3,\,...\,,\,m - 1\}$ è ragionevolmente piccolo.

Si considera un'applicazione che ha bisogno di un insieme dinamico in cui ogni elemento ha una chiave estratta dall'universo $U = \{0,\,1,\,2,\,3,\,...\,,\,m - 1\}$, dove \textit{m} non è troppo grande, e si suppone inoltre che due elementi non possano avere la stessa chiave.

Per rappresentare l'insieme dinamico, si utilizza un array o \textbf{tabella a indirizzamento diretto}, che verrà indicata con $T = [0,\,...\,,\,m - 1]$, dove ogni posizione o \textbf{cella} corrisponde a una chiave nell'universo \textit{U}. In generale, la cella \textit{k} punterà a un elemento dell'insieme con chiave \textit{k}. Se l'insieme non contiene l'elemento con chiave \textit{k}, allora \textit{T}[\textit{k}] = \textsc{nil}. Nel caso di chiavi duplicate si utilizza una lista collegata.

Le operazioni di dizionario sono semplici da implementare:\\\\
\textsc{Direct-Address-Search(\textit{T},\,\textit{k})}\\
1\firsttab\textbf{return} \textit{T}[\textit{k}]\\\\
\textsc{Direct-Address-Insert(\textit{T},\,\textit{x})}\\
1\firsttab \textit{T}[\textit{x.key}] $\leftarrow x$\\\\
\textsc{Direct-Address-Delete(\textit{T},\,\textit{x})}\\
1\firsttab \textit{T}[\textit{x.key}] $\leftarrow$ \textsc{nil}\\\\
Ciascuna di queste operazioni richiede un tempo $O(1)$.

Se l'universo delle chiavi \textit{U} è troppo grande, memorizzare una tabella \textit{T} di dimensione $|U|$ può essere impraticabile, se non impossibile, considerando la memoria disponibile in un normale calcolatore. Inoltre, l'insieme \textit{K} delle chiavi effettivamente memorizzate può essere così piccolo rispetto a \textit{U} che la maggior parte dello spazio allocato per la tabella \textit{T} sarebbe sprecato.
\section{Tabelle hash}
Quando l'insieme \textit{K} delle chiavi memorizzate in un dizionario è molto più piccolo dell'universo \textit{U} di tutte le chiavi possibili, una tabella hash richiede molto meno spazio di una tabella a indirizzamento diretto. Lo spazio richiesto può essere ridotto a $\Theta(|K|)$, senza perdere il vantaggio di ricercare un elemento nella tabella hash nel tempo $O(1)$.

Con l'indirizzamento diretto, un elemento con chiave \textit{k} è memorizzato nella cella \textit{k}. Con l'hashing, questo elemento è memorizzato nella cella $h(k)$ (ovvero memorizza \textit{k} in \textit{T}[\textit{h}(\textit{k})]); cioè si utilizza una \textbf{funzione hash} \textit{h} per calcolare la cella dalla chiave \textit{k}. Quindi \textit{h} associa l'universo \textit{U} delle chiavi alle celle di una \textbf{tabella hash} $T = [0,\,...\,,\,m - 1]$:
\begin{equation*}
h \,:\, U \rightarrow \{0,\,1,\,2,\,3,\,...\,,\,m - 1\}
\end{equation*}
Dove la dimensione \textit{m} della tabella hash è generalmente molto più piccola di $|U|$. Si dirà che un elemento con chiave \textit{k} viene mappato nella cella $h(k)$ o anche che $h(k)$ è il \textbf{valore hash} della chiave \textit{k}.
\section{Funzioni hash}
La funzione hash, che ha il compito di ridurre l'intervallo degli indici e di conseguenza la dimensione dell'array, è una funzione \textbf{non iniettiva}. La funzione $h(k)$ dovrebbe realizzare un \textbf{hash uniforme semplice} per cui ogni chiave ha la stessa probabilità di essere mandata in una qualsiasi delle \textit{m} celle, indipendentemente dalla cella cui viene mandata una qualsiasi altra cella. In pratica questo non è possibile perché non si conosce la distribuzione di probabilità secondo la quale sono estratte le chiavi che, a loro volta, potrebbero non essere prese indipendentemente l'una dall'altra. Per poter creare una buona funzione hash si andranno ad utilizzare delle informazioni qualitative relative al dominio delle chiavi.

Un buon approccio consiste nel derivare il valore hash in modo che sia indipendente da qualsiasi regolarità che possa esistere nei dati. Per esempio, il metodo della divisione calcola il valore hash come il resto della divisione fra la chiave e un determinato numero primo. Questo metodo spesso fornisce buoni risultati, purché il numero primo sia scelto in modo da non essere correlato a nessuna regolarità nella distribuzione della chiavi.

La maggior parte delle funzioni hash suppone che l'universo delle chiavi sia l'insieme dei numeri naturali $\mathbb{N} = \{0,\,1,\,2,\,3,\,...\,\}$. Quindi, se le chiavi non sono numeri naturali, occorre un metodo per interpretarle come tali. Per esempio, una stringa di caratteri può essere interpretata come un numero intero espresso in una notazione posizionale di base opportuna (vedi codifica ASCII).
\subsection{Il metodo della divisione}
Quando si applica il \textbf{metodo della divisione} per creare una funzione hash, una chiave \textit{k} viene associata a una delle \textit{m} celle prendendo il resto della divisione fra \textit{k} e \textit{m}; cioè la funzione hash è:
\begin{equation*}
h(k) = k \text{ mod } m = k - \Bigl\lfloor \frac{k}{m} \Bigr\rfloor \cdot m
\end{equation*}
Il vantaggio di questo metodo è che è veloce, mentre, lo svantaggio, è che quando si utilizza il metodo della divisione, di solito, si devono evitare determinati valori di \textit{m}. Per esempio, \textit{m} non dovrebbe essere una potenza di 2, perché se $m = 2^p$, allora $h(k)$ rappresenta proprio i \textit{p} bit meno significativi di \textit{k} (critico per rappresentare le stringhe). A meno che non sia noto che tutte le configurazioni dei \textit{p} bit di ordine inferiore abbiano la stessa probabilità, è meglio rendere la funzione hash dipendente da tutti i bit della chiave. Scegliere $m = 2^p - 1$, quando \textit{k} è una stringa di caratteri interpretata nella base $2^p$, potrebbe essere una cattiva soluzione, perché la permutazione dei caratteri di \textit{k} non cambia il suo valore hash. Un \textbf{numero primo} non troppo vicino a una potenza esatta di 2 è spesso una buona scelta per \textit{m}.
\subsection{Il metodo della moltiplicazione}
Il \textbf{metodo della moltiplicazione} per creare funzioni hash si svolge in due passi. Prima si moltiplica la chiave \textit{k} per una costante \textit{A} appartenente all'intervallo $0 < A < 1$ e si estrae la parte frazionaria di \textit{kA}. Poi si moltiplica tale valore per \textit{m} e si prende la parte intera inferiore del risultato. In sintesi, la funzione hash è:
\begin{equation*}
h(k) = \lfloor m \cdot (k \cdot A \text{ mod } 1) \rfloor
\end{equation*}
Dove $(k \cdot A \text{ mod } 1)$ rappresenta la parte frazionaria di $kA$, cioè $kA - \lfloor kA \rfloor$.

Lo svantaggio del metodo della moltiplicazione è che è più lento del metodo della divisione. Al contrario, un suo vantaggio è che il valore di \textit{m} non è critico. Tipicamente, lo si sceglie come una potenza del 2 ($m = 2^p$ per qualche intero \textit{p}), il che rende semplice implementare la funzione hash nella maggior parte dei calcolatori.

Si suppone che la dimensione della parola della macchina sia \textit{w} bit e che \textit{k} entri in una sola parola (\textit{k} richiede \textit{w} bit). Come \textit{A} si prende una funzione della forma $\frac{s}{2^w}$, dove \textit{s} è un intero nell'intervallo $0 < s < 2^w$ (\textit{s} richiede \textit{w} bit). Inizialmente, si moltiplica \textit{k} per l'intero di \textit{w} bit, $s = A \cdot 2^w$. Il risultato è un valore di $2w$ bit definito come $r_1 2^w + r_0$, dove $r_1$ è la parte intera, cioè la più significativa, di $kA$ ($r_1 = \lfloor kA \rfloor$) e $r_0$ è la parte frazionaria, cioè la meno significativa, del prodotto $kA$ ($r_0 = kA \text{ mod } 1 = kA -  \lfloor kA \rfloor$). Il valore hash desiderato di \textit{p} bit è formato dai \textit{p} bit più significativi di $r_0$.

$\lfloor m \cdot (k \cdot A \text{ mod } 1) \rfloor \Rightarrow$ shift a sinistra $r_0$ di $p = lg\,m$ bit, si prendono i \textit{p} bit a sinistra del punto binario. Non serve shiftare, si prendono i \textit{p} bit più significativi di $r_0$.

Sebbene questo metodo funzioni con qualsiasi valore della costante $A$, tuttavia con qualche valore funziona meglio che con altri sulla base della chiave su cui fare l'hash. La scelta ottimale dipende dalle caratteristiche dei dati da sottoporre all'hashing. Knuth propone $A \approx \frac{\sqrt{5} - 1}{2} = 0,618033..$ come valore che funziona ragionevolmente bene. Quindi dato \textit{w} si sceglie \textit{s} intero tale che $\frac{s}{2^w} \approx \frac{\sqrt{5} - 1}{2}$.
\section{Collisioni e tecniche per risolverle}
Può verificarsi che due chiavi possano essere mappate nella stessa cella, ovvero si può verificare che $h(k) = h(k')$ con $k \not= k'$. Questo evento si chiama \textbf{collisione}. Può capitare se $|K| \leq m$ e capita sicuramente si $|K| > m$. Esistono però delle tecniche efficaci per risolvere i conflitti creati dalle collisioni. Tra queste: il concatenamento e l'indirizzamento aperto. 
\subsection{Concatenamento}
Nel \textbf{concatenamento} si pongono tutti gli elementi che sono associati alla stessa cella (cioè che hanno lo stesso hash) in una \textbf{lista collegata}. Si potrà quindi verificare che una generica cella \textit{j}  contenga un puntatore alla testa di una lista di tutti gli elementi memorizzati che vengono mappati in \textit{j}; se non ce ne sono, la cella \textit{j} contiene la costante \textsc{nil}. Non è una struttura dati molto dinamica.\\\\
\textsc{Chained-Hash-Insert(\textit{T},\,\textit{x})}\\
\firsttab inserisce \textit{x} in testa alla lista $T[h(x.key)]$\\\\
Il tempo di esecuzione nel caso peggiore per l'inserimento è $O(1)$. La procedura di inserimento è veloce, anche perché si suppone che l'elemento \textit{x} da inserire non sia presente nella tabella; se necessario, questa ipotesi può essere verificata (con un costo aggiuntivo) ricercando un elemento la cui chiava sia $x.key$, prima di effettuare l'inserimento.\\\\
\textsc{Chained-Hash-Search(\textit{T},\,\textit{k})}\\
\firsttab ricerca un elemento con chiave \textit{k} nella lista $T[h(k)]$\\\\
Per la ricerca, il tempo di esecuzione nel caso peggiore è proporzionale alla lunghezza della lista.\\\\
\textsc{Chained-Hash-Delete(\textit{T},\,\textit{x})}\\
\firsttab cancella \textit{x} dalla lista $T[h(x.key)]$\\\\
La cancellazione di un elemento \textit{x} può essere realizzata nel tempo $O(1)$ se le liste sono doppiamente concatenate (non considera il tempo per trovare l'elemento da cancellare). Con liste semplicemente collegate, costa quanto la ricerca.
\subsubsection{Analisi di hash con concatenamento}
Data una tabella hash \textit{T} con \textit{m} celle dove sono memorizzati \textit{n} elementi, si definisce \textbf{fattore di carico} $\alpha$ della tabella \textit{T} il rapporto $n/m$, ossia il numero medio di elementi memorizzati in una lista (\textit{n} = numero di elementi memorizzati nella tabella, \textit{m} = numero di slot nella tabella). Tale fattore $\alpha$ può essere minore, uguale o maggiore di 1.

Il comportamento nel caso peggiore dell'hashing con concatenamento è pessimo: tutte le \textit{n} chiavi sono associate alla stessa cella, creando una singola lista di lunghezza \textit{n}. Il tempo di esecuzione della ricerca è quindi $\Theta(1) + \Theta(n) = \Theta(n)$, dove $\Theta(1)$ è il tempo per calcolare la funzione hash. Le tavole hash non sono utilizzate per le loro prestazioni nel caso peggiore.

Le prestazioni nel caso medio dipendono dal modo in cui la funzione hash \textit{h} distribuisce mediamente l'insieme delle chiavi da memorizzare tra le \textit{m} celle. Si suppone che qualsiasi elemento abbia la stessa probabilità di essere mandato in una qualsiasi delle \textit{m} celle, indipendentemente dalle celle in cui sono mandati gli altri elementi. Questa ipotesi è detta \textbf{hashing uniforme semplice}.

Per $j = 0,\,1,\,2,\,3,\,...\,,\,m - 1$, indicando con $n_j$ la lunghezza della lista $T[j]$, si avrà:
\begin{equation*}
n = n_0 + n_1 + n_2 + ... + n_{m-1}
\end{equation*}
e il valore atteso di $n_j$ sarà:
\begin{equation*}
E[n_j] = \alpha = \frac{n}{m}
\end{equation*}
Si suppone che basti un tempo $O(1)$ per calcolare il valore hash $h(k)$, in modo che il tempo richiesto per cercare un elemento con chiave \textit{k} dipenda linearmente dalla lunghezza $n_{h(k)}$ della lista $T[h(k)]$. Mettendo assieme in un tempo $O(1)$ il tempo richiesto per calcolare la funzione hash e accedere alla cella $h(k)$, si considera il numero atteso di elementi esaminati dall'algoritmo di ricerca, ovvero il numero di elementi nella lista $T[h(k)]$ che vengono controllati per vedere se le loro chiavi sono uguali a \textit{k}. Si considerano due casi. Nel primo caso, la ricerca \textbf{non ha successo}: nessun elemento nella tabella ha la chiave \textit{k}. Nel secondo caso, la ricerca \textbf{ha successo} e viene trovato un elemento con chiave \textit{k}.
\begin{theorem}
In una tabella hash le cui collisioni sono risolte con il concatenamento, una ricerca senza successo richiede un tempo $\Theta(1 + \alpha)$ nel caso medio, nell'ipotesi di hashing uniforme semplice.
\end{theorem}
\begin{proof}
Nell'ipotesi di hashing uniforme semplice, qualsiasi chiave \textit{k} non ancora memorizzata nella tabella ha la stessa probabilità di essere associata ad una qualsiasi delle \textit{m} celle. Il tempo atteso per ricercare senza successo una chiave \textit{k} è il tempo atteso per svolgere le ricerche fino alla fine della lista $T[h(k)]$, che ha una lunghezza attesa pari a $E[n_{h(k)}] = \alpha$. Quindi, il numero atteso di elementi esaminati in una ricerca senza successo è $\alpha$ e il tempo totale richiesto (incluso quello per calcolare $h(k)$) è $\Theta(1 + \alpha)$.
\end{proof}
Il caso di una ricerca con successo è un po' differente, perché ogni lista non ha la stessa probabilità di essere oggetto delle ricerche. La probabilità che una lista sia oggetto delle ricerche è proporzionale al numeri di elementi che contiene. Nonostante questo, il tempo atteso è ancora $\Theta(1 + \alpha)$.
\begin{theorem}
In una tabella hash le cui collisioni sono risolte con il concatenamento, una ricerca con successo richiede un tempo $\Theta(1 + \alpha)$ nel caso medio, nell'ipotesi di hashing uniforme semplice.
\end{theorem}
\begin{proof}
Si suppone che l'elemento da ricercare abbia la stessa probabilità di essere uno qualsiasi degli \textit{n} elementi memorizzati nella tabella. Il numero di elementi esaminati durante una ricerca con successo di un elemento \textit{x} è uno in più del numero di elementi che si trovano prima di \textit{x} nella lista di \textit{x}. Gli elementi che precedono \textit{x} nella lista, sono stati inseriti tutti dopo di \textit{x}, perché i nuovi elementi vengono posti all'inizio della lista. Per trovare il numero atteso di elementi esaminati, si prende la media, sugli \textit{n} elementi \textit{x} nella tabella, di 1 più il numero atteso di elementi aggiunti alla lista di \textit{x} dopo che \textit{x} è stato aggiunto alla lista. Si indica con $x_i$ l'\textit{i}-esimo elemento inserito nella tabella, per $i = 1,\,2,\,3,\,...\,,\,n$, e si definisce $k_i = x_i.key$. Per le chiavi $k_i$ e $k_j$, si definisce la variabile casuale indicatrice
\begin{equation*}
X_{ij} = I\{h(k_i) = h(k_j)\}
\end{equation*}
Nell'ipotesi di hashing uniforme semplice, si ha
\begin{equation*}
Pr\{h(k_i) = h(k_j)\} = \frac{1}{m}
\end{equation*}
E quindi
\begin{equation*}
E[X_{ij}] = \frac{1}{m}
\end{equation*}
Dunque il numero atteso di elementi esaminati in una ricerca con successo è
\begin{align*}
E\Biggl[\frac{1}{n}\sum_{i=1}^{n}\Biggl(1 + \sum_{j=i+1}^{n}X_{ij}\Biggr)\Biggr] &= \frac{1}{n}\sum_{i=1}^{n}\Biggl(1 + \sum_{j=i+1}^{n}E[X_{ij}]\Biggr) \\
&= \frac{1}{n}\sum_{i=1}^{n}\Biggl(1 + \sum_{j=i+1}^{n}\frac{1}{m}\Biggr) \\
&= 1 + \frac{1}{n\,m}\sum_{i=1}^{n}(n - i) \\
&= 1 + \frac{1}{n\,m}\Biggl(\sum_{i=1}^{n}n - \sum_{i=1}^{n}i\Biggr) \\
&= 1 + \frac{1}{n\,m}\Biggl(n^2 - \frac{n(n+1)}{2}\Biggr) \\
&= 1 + \frac{n - 1}{2m} \\
&= 1 + \frac{\alpha}{2} - \frac{\alpha}{2n}
\end{align*}
In conclusione, il tempo totale richiesto per una ricerca con successo (incluso il tempo per calcolare la funzione hash) è $\Theta(2 + \alpha/2 - \alpha/2n) = \Theta(1 + \alpha)$.
\end{proof}
\subsection{Indirizzamento aperto}
Nell'\textbf{indirizzamento aperto}, tutti gli elementi sono memorizzati nella tabella hash stessa; ovvero ogni cella della tabella contiene un elemento dell'insieme dinamico (una chiave) o la costante \textsc{nil}. Quando si cerca un elemento, si esamina sistematicamente le celle della tabella finché non si trova l'elemento desiderato o finché non ci si rende conto che l'elemento non si trova nella tabella.

Diversamente dal concatenamento, non ci sono liste né elementi memorizzati all'esterno della tabella. Quindi, nell'indirizzamento aperto, la tabella hash può riempirsi al punto tale che non possono essere effettuati altri incrementi: una conseguenza è che il fattore di carico $\alpha$ non supera mai 1.

Per effettuare un inserimento mediante l'indirizzamento aperto, si esaminano in successione le posizioni della tabella hash (\textbf{ispezione}), finché non si trova una cella vuota in cui inserire la chiave. Anziché eseguire sempre lo stesso ordine $0,\,1,\,...\,,\,m - 1$ (che richiede un tempo di ricerca $\Theta(n)$), la sequenza delle posizioni esaminate durante un'ispezione dipende dalla chiave da inserire. Per determinare quali celle esaminare, si estende la funzione hash in modo da includere l'ordine di ispezione (a partire da 0) come secondo input. Quindi, la funzione hash diventa
\begin{equation*}
h : U \times \{0,\,1,\,...\,,\,m - 1\} \rightarrow \{0,\,1,\,...\,,\,m - 1\}
\end{equation*}
Con l'indirizzamento aperto si richiede che, per ogni chiave \textit{k}, la \textbf{sequenza di ispezione}
\begin{equation*}
\langle h(k,0),\, h(k,1),\,...\,,\, h(k,m-1)\rangle
\end{equation*}
sia una permutazione di $\langle 0,\,1,\,...\,,\,m - 1  \rangle$, in modo che ogni posizione della tabella hash possa essere considerata come possibile cella in cui inserire una nuova chiave mentre la tabella si riempie. Se necessario, si esaminano tutti gli slot, inoltre, nessuno slot verrà esaminato più di una volta.

La procedura \textsc{Hash-Insert} riceve in ingresso una tabella hash \textit{T} e una chiave \textit{k}. Essa ritorna il numero della cella in cui ha memorizzato la chiave \textit{k} oppure segnala un errore se la tabella era già piena.\\\\
\textsc{Hash-Insert(\textit{T},\,\textit{k})}\\
1\firsttab$i \leftarrow 0$\\
2\firsttab\textbf{repeat}\\
3\secondtab$j \leftarrow h(k,i)$\\
4\secondtab\textbf{if} \textit{T}[\textit{j}] = \textsc{nil}\\
5\thirdtab \textit{T}[\textit{j}] $\leftarrow k$\\
6\thirdtab\textbf{return} \textit{j}\\
7\secondtab\textbf{else} $i \leftarrow i + 1$\\
8\firsttab\textbf{until} $i = m$\\
9\firsttab\textbf{error} "overflow della tabella hash"
\\\\Commenti:
\begin{itemize}
\item[0]Inserisce il valore nel primo \textsc{nil} trovato
\item[3]Un esempio di funzione hash è:\\$h(k,\,i) = (h'(k) + i) \text{ mod } m = (k \text{ mod } m + i) \text{ mod } m$
\end{itemize}

L'algoritmo che ricerca la chiave \textit{k} esamina la stessa sequenza di celle che ha esaminato l'algoritmo di inserimento quando ha inserito la chiave \textit{k}. Quindi, la ricerca può terminare (senza successo) quando trova una cella vuota, perché la chiave \textit{k} sarebbe stata inserita lì e non dopo nella sua sequenza di ispezione. La procedura \textsc{Hash-Search} prende come input una tabella hash \textit{T} e una chiave \textit{k}; restituisce \textit{j} se la cella \textit{j} contiene la chiave \textit{k} oppure \textsc{nil} se la chiave \textit{k} non si trova nella tabella \textit{T}.\\\\
\textsc{Hash-Search(\textit{T},\,\textit{k})}\\
1\firsttab$i \leftarrow 0$\\
2\firsttab\textbf{repeat}\\
3\secondtab$j \leftarrow h(k,i)$\\
4\secondtab\textbf{if} \textit{T}[\textit{j}] = \textit{k}\\
5\thirdtab\textbf{return} \textit{j}\\
6\secondtab$i \leftarrow i + 1$\\
7\firsttab\textbf{until} \textit{T}[\textit{j}] = \textsc{nil} or $i = m$\\
8\firsttab\textbf{return} \textsc{nil} 
\\\\Commenti:
\begin{itemize}
\item[3]Calcolare la posizione della cella da esaminare attraverso la funzione hash
\item[5]L'elemento è stato trovato e si trova nella cella di indice \textit{j}
\item[7]Si ripete fintantoché non si trova una posizione vuota o finché non si sono visitate tutte le celle
\item[8]Restituisce \textsc{nil} se non è stato trovato
\end{itemize}

La cancellazione da una tabella hash a indirizzamento aperto è un'operazione difficile. Quando si cancella una chiave dalla cella \textit{i}, non si può semplicemente marcare questa cella come vuota inserendovi la costante \textsc{nil}. Così facendo, potrebbe essere impossibile ritrovare qualsiasi chiave \textit{k} nel cui inserimento si abbia esaminato la cella \textit{i} e la si abbia trovata occupata. Una soluzione consiste nel marcare la cella registrandovi il valore speciale \textsc{deleted}, anziché \textsc{nil}. Si dovrà quindi modificare la procedura \textsc{Hash-Insert} per trattare tale cella come se fosse vuota, in modo da potere inserire una nuova chiave. Nessuna modifica è richiesta per \textsc{Hash-Search}, perché questa procedura ignora i valori \textsc{deleted} durante la ricerca.\\

Nell'analisi si fa l'ipotesi di \textbf{hashing uniforme}: si suppone che ogni chiave abbia la stessa probabilità di avere come sequenza di ispezione una delle $m!$ permutazioni di $\langle 0,\,1,\,...\,,\,m - 1  \rangle$. L'hashing uniforme estende il concetto di hashing uniforme semplice, definito precedentemente, al caso in cui la funzione hash produca, non un singolo numero, ma un'intera sequenza di ispezione. Poiché è difficile implementare il vero hashing uniforme, in pratica si usano delle approssimazioni accettabili. Tre tecniche comunemente utilizzate per calcolare la sequenza di ispezione richieste dall'indirizzamento aperto sono: \textbf{ispezione lineare}, \textbf{ispezione quadratica} e \textbf{doppio hashing}. Tutte e tre le tecniche garantiscono che $\langle h(k,0),\, h(k,1),\,...\,,\, h(k,m-1)\rangle$ sia una permutazione di $\langle 0,\,1,\,...\,,\,m - 1  \rangle$ per ogni chiave \textit{k}. Tuttavia, nessuna di queste tecniche soddisfa l'ipotesi di hashing uniforme, in quanto nessuna di esse è in grado di generare più di $m^2$ sequenze di ispezione differenti (anziché $m!$ come richiesto dall'hashing uniforme).
\subsubsection{Ispezione lineare}
Data una funzione hash ordinaria $h' \,:\, U \rightarrow \{0,\,1,\,2,\,3,\,...\,,\,m - 1\}$, che prende il nome di \textbf{funzione hash ausiliaria},il metodo dell'\textbf{ispezione lineare} usa la funzione hash
\begin{equation*}
h(k,\,i) = (h'(k) + i) \text{ mod } m
\end{equation*}
per $i = 0,\,1,\,...\,,\,m - 1$. Data la chiave \textit{k}, la prima cella esaminata è $T[h'(k)]$, che è la cella data dalla funzione hash ausiliaria; la seconda cella esaminata è $T[h'(k) + 1]$ e così via fino alla cella $T[m - 1]$. Poi, l'ispezione riprende dalle celle $T[0],\,T[1],\,...\,,\,T[h'(k) - 1]$. Poiché la prima cella ispezionata determina l'intera sequenza di ispezioni, ci sono soltanto \textit{m} sequenze di ispezione distinte.

L'ispezione lienare è facile da implementare ma presenta un problema noto come \textbf{addensamento primario}: si formano lunghe file di celle occupate, che aumentano il tempo medio di ricerca. Gli addensamenti si formano perché una cella vuota preceduta da \textit{i} celle piene ha la probabilità $(i + 1)/m$ di essere la prossima a essere occupata. Le lunghe file di celle occupate tendono a diventare sempre più lunghe e il tempo di ricerca medio aumenta.
\subsubsection{Ispezione quadratica}
L'\textbf{ispezione quadratica} usa una funzione hash della forma
\begin{equation*}
h(k,\,i) = (h'(k) + c_1i + c_2i^2) \text{ mod } m
\end{equation*}
dove $h'$ è una funzione hash ausiliaria, $c_1 \text{ e } c_2 \not= 0$ sono costanti ausiliarie e $i = 0,\,1,\,...\,,\,m - 1$. La posizione iniziale esaminata è $T[h'(k)]$; le posizioni successivamente esaminate sono distanziate da quantità che dipendono in modo quadratico dal numero d'ordine di ispezione \textit{i}. Questa tecnica funziona molto meglio dell'ispezione lineare, ma per fare pieno uso della tabella hash, i valori $c_1,\,c_2$ ed \textit{m} non si possono scegliere arbitrariamente e devono essere vincolati per assicurare che si abbia una permutazione completa di $\langle 0,\,1,\,...\,,\,m - 1  \rangle$. Inoltre, se due chiavi hanno la stessa posizione iniziale di ispezione, allora le loro sequenze di ispezione sono identiche, perché $h(k_1,0) = h(k_2,0)$ implica $h(k_1,i) = h(k_2,i)$. Questa proprietà porta a una forma più lieve di addensamento, che prende il nome di \textbf{addensamento secondario}. Come per l'ispezione lineare, la prima posizione determina l'intera sequenza, quindi vengono utilizzate soltanto \textit{m} sequenze di ispezione distinte.
\subsubsection{Doppio hashing}
È uno dei metodi migliori disponibili per l'indirizzamento aperto perché le permutazioni prodotte hanno molte delle caratteristiche delle permutazioni scelte a caso. Il \textbf{doppio hashing} usa due funzioni hash ausiliarie $h_1$ per la prima esplorazione e $h_2$ per le esplorazioni restanti
\begin{equation*}
h(k,\,i) = (h_1(k) + i\cdot h_2(k)) \text{ mod } m
\end{equation*}
L'ispezione inizia dalla posizione $T[h_1(k)]$; le successive posizioni sono distanziate dalle precedenti posizioni di una quantità $h_2(k)$ modulo \textit{m}. Quindi, diversamente dal caso dell'ispezione lineare o quadratica, la sequenza di ispezione qui dipende in due modi dalla chiave \textit{k}, perché possono variare sia la posizione iniziale di ispezione sia la distanza fra due posizioni successive di ispezione.

Il valore $h_2(k)$ deve essere primo relativo con la dimensione \textit{m} della tabella hash perché venga ispezionata l'intera tabella hash. Un modo pratico per garantire questa condizione è scegliere \textit{m} potenza del 2 e definire $h_2$ in modo che produca sempre un numero dispari. Un altro modo è scegliere \textit{m} primo e definire $h_2$ in modo che generi sempre un numero intero positivo minore di \textit{m}. Per esempio, si potrebbe scegliere \textit{m} primo e porre
\begin{align*}
&h_1(k) = k \text{ mod } m \\
&h_2(k) = 1 + (k \text{ mod } m')
\end{align*}
dove $m'$ deve essere scelto un po' più piccolo di \textit{m} (come $m - 1$).

Quando \textit{m} è primo oppure una potenza di 2, il doppio hashing è migliore delle ispezioni lineari e quadratiche in quanto usa $\Theta(m^2)$ sequenze di ispezione, anziché $\Theta(m)$, perché ogni possibile coppia $(h_1(k),h_2(k))$ produce una distinta sequenza di ispezione. Di conseguenza, per questi valori di \textit{m}, le prestazioni del doppio hashing risultano molto prossime a quelle dello schema ideale dell'hashing uniforme.

Nel doppio hashing, per la ricerca senza successo e l'inserimento, il numero atteso di esplorazioni è al più $\frac{1}{1-\alpha}$. Per la ricerca con successo, il numero atteso di esplorazione è al più $\frac{1}{\alpha}ln\frac{1}{1-\alpha}$.
\chapter{Alberi binari di ricerca}
Gli alberi di ricerca sono strutture dati che supportano molte operazioni sugli insiemi dinamici, fra le quali \textsc{Search, Minimum, Maximum, Predecessor, Successor, Insert} e \textsc{Delete}. Quindi, un albero di ricerca può essere utilizzato sia come dizionario sia come una coda di priorità. Le operazioni di base su un albero binario di ricerca richiedono un tempo proporzionale all'altezza dell'albero. Per un albero binario completo con \textit{n} nodi, tali operazioni sono eseguite nel tempo $\Theta(lg\,n)$ nel caso peggiore. Se invece, l'albero è una catena lineare di \textit{n} nodi, le stesse operazioni richiedono un tempo $\Theta(n)$ nel caso peggiore.
\section{Cos'è un albero binario di ricerca}
Un albero binario di ricerca è organizzato in un albero binario, che può essere rappresentato da una struttura dati concatenata in cui ogni nodo è un oggetto. Oltre a una chiave \textit{key} e ai dati satellite, ogni nodo dell'albero contiene gli attributi \textit{left, right} e \textit{p} che puntano ai nodi che corrispondono, rispettivamente, al figlio sinistro, al figlio destro e al padre del nodo. Se manca un figlio o il padre, i corrispondenti attributi contengono il valore \textsc{nil}. Il nodo radice (\textit{root}) è l'unico nodo nell'albero il cui attributo padre è \textsc{nil}.

Le chiavi in un albero binario di ricerca sono sempre memorizzate in modo da soddisfare la \textbf{proprietà degli alberi binari di ricerca}:
\begin{quote}
Sia \textit{x} un nodo in un albero binario di ricerca. Se \textit{y} è un nodo nel sottoalbero sinistro di \textit{x}, allora $y.key \leq x.key$. Se \textit{y} è un nodo nel sottoalbero destro di \textit{x}, allora $y.key \geq x.key$. 
\end{quote}
La proprietà degli alberi binari di ricerca consente di elencare ordinatamente tutte le chiavi di un albero binario di ricerca con un semplice algoritmo ricorsivo di \textbf{attraversamento simmetrico di un albero} (inorder). Questo algoritmo è così chiamato perché la chiave della radice di un sottoalbero viene stampata nel mezzo tra la stampa dei valori nel sottoalbero sinistro e la stampa dei valori nel sottoalbero destro. Analogamente, un algoritmo di \textbf{attraversamento anticipato di un albero} (preorder) stampa la radice prima dei valori dei suoi sottoalberi e un algoritmo di \textbf{attraversamento posticipato di un albero} (postorder) stampa la radice dopo i valori dei suoi sottoalberi. L'attraversamento \textbf{preorder} può essere utile per memorizzare in modo univoco un albero andando a memorizzare ogni nodo come \textit{n(-,-)} dove $n$ indica il nodo e tra parentesi si indicano prima il figlio sinistro, poi quello destro. Con la chiamata \textsc{Inorder-Tree-Walk(\textit{T.root})} la procedura stampa tutti gli elementi di un albero binario di ricerca \textit{T}.\\\\
\textsc{Inorder-Tree-Walk(\textit{x})}\\
1\firsttab\textbf{if} $x \not= \textsc{nil}$\\
2\secondtab\textsc{Inorder-Tree-Walk(\textit{x.left})}\\
3\secondtab stampa $x.key$\\
4\secondtab\textsc{Inorder-Tree-Walk(\textit{x.right})}\\\\
La correttezza dell'algoritmo si ricava direttamente per induzione dalla proprietà degli alberi binari di ricerca.

Occorre un tempo $\Theta(n)$ per attraversare un albero binario di ricerca di \textit{n} nodi perché, dopo la chiamata iniziale, la procedura viene chiamata ricorsivamente esattamente due volte per ogni nodi dell'albero - una volta per il figlio sinistro e una per il figlio destro.
\begin{theorem}
Se \textit{x} è la radice di un sottoalbero di \textit{n} nodi, la chiamata \textsc{Inorder-Tree-Walk(\textit{x})} richiede il tempo $\Theta(n)$.
\end{theorem}
\begin{proof}
Sia $T(n)$ il tempo richiesto dalla procedura \textsc{Inorder-Tree-Walk} quando viene chiamata per la radice di un sottoalbero di \textit{n} nodi. Poiché \textsc{Inorder-Tree-Walk} visita tutti gli \textit{n} nodi del sottoalbero, si ha $T(n) = \Omega(n)$. Si dimostra ora che $T(n) = O(n)$.

\textsc{Inorder-Tree-Walk} richiede una piccola quantità costante di tempo con un sottoalbero vuoto (per il resto $x \not= \textsc{nil}$), quindi $T(0) = c$ per qualche costante positiva \textit{c}.

Per $n > 0$, si suppone che \textsc{Inorder-Tree-Walk} sia chiamata per un nodo \textit{x} il cui sottoalbero sinistro ha \textit{k} nodi e il cui sottoalbero destro ha $n - k - 1$ nodi. Il tempo per eseguire \textsc{Inorder-Tree-Walk} è
\begin{equation*}
T(n) \leq T(k) + T(n - k - 1) + d 
\end{equation*}
per qualche costante positiva \textit{d} che rappresenta un limite superiore per il tempo per eseguire \textsc{Inorder-Tree-Walk}, escludendo il tempo impiegato nelle chiamate ricorsive.

Si applica ora il metodo di sostituzione per trovare che $T(n) = \Theta(n)$ dimostrando che $T(n) \leq (c + d)n + c$. Per $n = 0$, si ha $(c + d)\cdot 0 + c = c = T(0)$. Per $n > 0$ si ha
\begin{align*}
T(n) &\leq T(k) + T(n - k - 1) + d \\
&= ((c+ d)k + c) + ((c + d)(n - k - 1) + c) + d \\
&= (c + d)n + c - (c + d) + c + d \\
&=(c+ d)n + c
\end{align*}
che completa la dimostrazione.
\end{proof}
\section{Interrogazione di un albero binario di ricerca}
Una tipica operazione eseguita su un albero binario di ricerca è quella di cercare una chiave memorizzata nell'albero. Oltre all'operazione \textsc{Search}, gli alberi binari di ricerca supportano interrogazioni (query) quali \textsc{Minimum, Maximum, Predecessor} e \textsc{Successor}.
\subsection{Ricerca}
Per cercare un nodo con una data chiave in un albero binario di ricerca si utilizza la procedura \textsc{Tree-Search}. Dato un puntatore alla radice dell'albero e una chiave \textit{k}, \textsc{Tree-Search} restituisce un puntatore a un nodo con chiave \textit{k}, se esiste, altrimenti restituisce il valore \textsc{nil}.\\\\
\textsc{Tree-Search(\textit{x},\,\textit{k})}\\
1\firsttab\textbf{if} \textit{x} = \textsc{nil} or \textit{k} = \textit{x.key}\\
2\secondtab\textbf{return} \textit{x}\\
3\firsttab\textbf{if} $k < $ \textit{x.key}\\
4\secondtab\textbf{return} \textsc{Tree-Search(\textit{x.left},\,\textit{k})}\\
5\firsttab\textbf{else return} \textsc{Tree-Search(\textit{x.right},\,\textit{k})}\\\\
La procedura inizia la sua ricerca dalla radice e segue un cammino semplice verso il basso lungo l'albero. Per ogni nodo \textit{x} che incontra, confronta la chiave \textit{k} con $x.key$. Se le due chiavi sono uguali, la ricerca termina.

Se $k < x.key$, la ricerca continua nel sottoalbero sinistro di \textit{x}, in quanto la proprietà degli alberi binari di ricerca implica che \textit{k} non può essere memorizzato nel sottoalbero destro. Simmetricamente, se $k > x.key$, la ricerca continua nel sottoalbero destro.

I nodi incontrati durante la ricorsione formano un cammino semplice verso il basso dalla radice dell'albero, quindi il tempo di esecuzione di \textsc{Tree-Search} è $O(h)$, dove \textit{h} è l'altezza dell'albero.

La procedura è  ricorsiva in coda e può essere riscritta in forma iterativa (al massimo ci mette il tempo necessario per andare dalla radice alla foglia) che è più efficiente nella maggior parte dei calcolatori.\\\\
\textsc{Iterative-Tree-Search(\textit{x},\,\textit{k})}\\
1\firsttab\textbf{while} \textit{x} = \textsc{nil} or \textit{k} = \textit{x.key}\\
2\secondtab\textbf{if} $k < $ \textit{x.key}\\
3\thirdtab\textit{x} $\leftarrow$ \textit{x.left}\\
4\secondtab\textbf{else} \textit{x} $\leftarrow$ \textit{x.right}\\
5\firsttab\textbf{return} \textit{x}\\\\
La correttezza di questa procedura è garantita dalla definizione di albero binario di ricerca. L'invariante di ciclo relativa alla forma iterativa di  \textsc{Tree-Search} è la seguente:
\begin{quote}
\textit{All'inizio di una generica iterazione, se la chiave è presente, si troverà nel sottoalbero avente radice \textit{x}; se non è presente allora non si trova nel sottoalbero di radice \textit{x}.}
\end{quote}
\subsection{Massimo e minimo}
Un elemento con chiave minima in un albero binario di ricerca può sempre essere trovato seguendo, a partire dalla radice, i puntatori \textit{left} dei figli a sinistra, fino a quando non viene incontrato un valore \textsc{nil}. La procedura \textsc{Tree-Minimum} restituisce un puntatore all'elemento minimo nel sottoalbero con radice in un nodo \textit{x}, che si suppone diverso da \textsc{nil}.

La proprietà degli alberi binari di ricerca garantisce la correttezza di questa procedura. Se un nodo \textit{x} non ha un sottoalbero sinistro, allora poiché ogni chiave nel sottoalbero destro di \textit{x} è almeno grande quanto \textit{x.key}, la chiave minima nel sottoalbero con radice in \textit{x} è \textit{x.key}. Se il nodo \textit{x} ha un sottoalbero sinistro, allora, poiché nessuna chiave nel sottoalbero destro è minore di \textit{x.key} e ogni chiave nel sottoalbero sinistro non è maggiore di \textit{x.key}, la chiave minima nel sottoalbero con radice in \textit{x} può essere trovata nel sottoalbero con radice in \textit{x.left}.\\\\
\textsc{Tree-Minimum(\textit{x})}\\
1\firsttab\textbf{while} \textit{x.left} $\not=$ \textsc{nil}\\
2\secondtab \textit{x} $\leftarrow$ \textit{x.key}\\
3\firsttab\textbf{return} \textit{x}\\\\
\textsc{Tree-Maximum(\textit{x})}\\
1\firsttab\textbf{while} \textit{x.right} $\not=$ \textsc{nil}\\
2\secondtab \textit{x} $\leftarrow$ \textit{x.key}\\
3\firsttab\textbf{return} \textit{x}\\\\
Entrambe queste procedure vengono eseguite nel tempo $O(h)$ in un albero binario di ricerca di altezza \textit{h} perché, come in \textsc{Tree-Search}, la sequenza dei nodi incontrati forma un cammino semplice che scende dalla radice.
\subsection{Successore e predecessore}
Se tutte le chiavi appartenenti ad un albero binario di ricerca sono distinte, il successore di un nodo \textit{x} è il nodo con la più piccola chiave che è maggiore di \textit{x.key}. La struttura di un albero binario di ricerca consente di determinare il successore di un nodo senza mai confrontare le chiavi. La procedura \textsc{Tree-Successor} restituisce il successore di un nodo \textit{x} in un albero binario di ricerca, se esiste, oppure \textsc{nil} se \textit{x} ha la chiave massima nell'albero.\\\\
\textsc{Tree-Successor(\textit{x})}\\
1\firsttab\textbf{if} \textit{x.right} $\not=$ \textsc{nil}\\
2\secondtab\textbf{return} \textsc{Tree-Minimum(\textit{x.right})}\\
3\firsttab\textit{y} $\leftarrow$ \textit{x.p}\\
4\firsttab\textbf{while} \textit{y} $\not=$ \textsc{nil} and \textit{x} = \textit{y.right}\\
5\secondtab\textit{x} $\leftarrow$ \textit{y}\\
6\secondtab\textit{y} $\leftarrow$ \textit{y.p}\\
7\firsttab\textbf{return} \textit{y}\\\\
Se il sottoalbero destro del nodo \textit{x} non è vuoto, allora il successore di \textit{x} è il minimo nel sottoalbero destro di \textit{x}. Al contrario, se il sottoalbero destro del nodo \textit{x} è vuoto e \textit{x} ha un successore \textit{y}, allora \textit{y} è l'antenato più prossimo di \textit{x} il cui figlio sinistro è anche antenato di \textit{x}. In alcuni casi, per trovare \textit{y} si deve risalire l'albero partendo da \textit{x}, finché non si incontra un nodo che è figlio sinistro di suo padre; questa operazione è svolta dalle righe 3 - 7 di \textsc{Tree-Successor}.

Il tempo di esecuzione di \textsc{Tree-Successor} in un albero di aletzza \textit{h} è $O(h)$, perché si segue un cammino semplice che sale o uno che scende. Anche la procedura \textsc{Tree-Predecessor}, che è simmetrica a \textsc{Tree-Successor}, viene eseguita nel tempo $O(h)$.
\section{Inserimento}
Le operazioni di inserimento e cancellazione modificano l'insieme dinamico rappresentato da un albero binario di ricerca. La struttura dati deve essere modificata per riflettere questa modifica, ma in modo tale che la proprietà degli alberi binari di ricerca resti valida.

Per inserire un nuovo valore \textit{v} in un albero binario di ricerca \textit{T}, si utilizza la procedura \textsc{Tree-Insert}. La procedura riceve un nodo \textit{z} per cui \textit{z.key} = \textit{v}, \textit{z.left} = \textsc{nil}, \textit{z.right} = \textsc{nil}; essa modifica \textit{T} e qualche attributo di \textit{z} in modo che \textit{z} sia inserito in una posizione appropriata nell'albero.

\textsc{Tree-Insert} inizia dalla radice dell'albero e il puntatore \textit{x} traccia il cammino semplice in discesa cercando un \textsc{nil} da sostituire con l'elemento di input \textit{z}. La procedura mantiene anche un puntatore inseguitore \textit{y} che punta al padre di \textit{x}.\\\\
\textsc{Tree-Insert(\textit{T},\,\textit{z})}\\
1\firsttab\textit{y} $\leftarrow$ \textsc{nil}\\
2\firsttab\textit{x} $\leftarrow$ \textit{T.root}\\
3\firsttab\textbf{while} \textit{x} $\not=$ \textsc{nil}\\ 
4\secondtab\textit{y} $\leftarrow$ \textit{x}\\
5\secondtab\textbf{if} \textit{z.key} $<$ \textit{x.key}\\
6\thirdtab\textit{x} $\leftarrow$ \textit{x.left}\\
7\secondtab\textbf{else} \textit{x} $\leftarrow$ \textit{x.right}\\
8\firsttab\textit{z.p} $\leftarrow$ \textit{y}\\
9\firsttab\textbf{if} \textit{y} = \textsc{nil}\\
10\secondtab\textit{T.root} $\leftarrow$ \textit{z}\\
11\firsttab\textbf{elseif} \textit{z.key} $<$ \textit{y.key}\\
12\secondtab\textit{y.left} $\leftarrow$ \textit{z}\\
13\firsttab\textbf{else} \textit{y.right} $\leftarrow$ \textit{z}\\\\
Commenti:
\begin{enumerate}
\item[3]Finché non arriva ad un punto in cui non ci sono figli
\item[3-7]Ricerca il nodo che non ha figli
\item[10]L'albero \textit{T} era vuoto
\item[11-13]Aggiorna il padre
\item[11]\textit{y} è l'ultimo nodo con chiave diversa da \textsc{nil}
\item[12]Se si viene da destra
\item[13]Se si viene da sinistra
\end{enumerate}
Dopo l'inizializzazione, la righe 3 - 7 del ciclo \textbf{while} spostano i puntatori \textit{x} e \textit{y} verso il basso, andando a sinistra o a destra a seconda dell'esito del confronto fra \textit{z.key} e \textit{x.key}, finché a \textit{x} non viene assegnato il valore \textsc{nil}. Serve un puntatore inseguitore \textit{y} perché, quando si trova il \textsc{nil} dove mettere \textit{z}, la ricerca è andata un passo oltre il nodo che deve essere modificato. Le righe 8 - 13 impostano i puntatori che servono a inserire \textit{z}.

La procedura \textsc{Tree-Insert} viene eseguita nel tempo $O(h)$ in un albero di altezza \textit{h}. Nel caso migliore, ovvero quando l'albero è bilanciato, $h = lg\,n$, nel caso peggiore, ovvero quando l'albero è completamente sbilanciato, $h = n$. Nel caso medio, $h = n\,lg\,n$. In generale, il valore \textit{h} dipende dall'\textbf{ordine} di inserimento.\\

È possibile utilizzare \textsc{Tree-Insert} e \textsc{Inorder-Tree-Walk} per ordinare un insieme di numeri: si costruisce un albero binario di ricerca con i numeri dati in input e poi li si stampa con un attraversamento simmetrico. Per fare in modo che tale ordinamento sia stabile bisogna gestire i duplicati; si suppone per esempio che il duplicato venga messo a destra, così facendo però si sbilancia l'albero. Un'altra possibilità è quella di aggiungere una lista concatenata contenente le chiavi duplicate che verranno aggiunte in coda per essere più stabili. In questo caso si modifica la procedura \textsc{Tree-Insert} per verificare se \textit{z.key} = \textit{x.key} nel primo \textbf{if}, e \textit{z.key} = \textit{y.key} all'interno di \textbf{elseif}. Oppure, si può utilizzare un flag booleano, che si aggiorna ad ogni iterazione, per distribuire i duplicati a sinistra o a destra del nodo.
\section{Cancellazione}
La procedura per cancellare un nodo \textit{z} da un albero binario di ricerca considera tre casi base a seconda del numeri di figli
\begin{enumerate}
\item \textbf{\textit{z} non ha figli}: si cancella \textit{z} andando a modificare il puntatore del padre. Si modifica suo padre \textit{p}[\textit{z}] per sostituire \textit{z} con \textsc{nil} come suo figlio.
\item \textbf{\textit{z} ha un figlio}: si cancella \textit{z} e si aggiorna il padre \textit{z.p} in modo che punti al figlio di \textit{z} invece che a \textit{z}. Ciò significa che si eleva il figlio di \textit{z} in modo da occupare la posizione di \textit{z} nell'albero, modificando il padre di \textit{z} per sostituire \textit{z} con il figlio di \textit{z}.
\item \textbf{\textit{z} ha due figli}: si trova il successore \textit{y} di \textit{z}, cioè il minimo del sottoalbero destro. Tale nodo \textit{y} può non avere figli o può averne al massimo uno (altrimenti non sarebbe il successore) e in tal caso è solo il figlio destro, infatti, se avesse il figlio sinistro, non sarebbe il minimo. Si cerca \textit{y} = min(\textit{z.right}), si cancella \textit{y} (considerando il caso 1 o 2) e si sostituisce la chiave di \textit{z} e dati satellite con quelli di \textit{y}. Questo significa che, dopo aver trovato il successore \textit{y} del nodo \textit{z}, si dovrà fare in modo che \textit{y} assuma la posizione di \textit{z} nell'albero. La parte restante del sottoalbero sinistro di \textit{z} diventa il nuovo sottoalbero sinistro di \textit{y}. Nel momento in cui si cancella \textit{y} si devono considerare due sottocasi:
\begin{itemize}
\item \textit{y} è il figlio di \textit{z}
\item \textit{y} non è figlio di \textit{z}
\end{itemize}
\end{enumerate}
La procedura per cancellare un dato nodo \textit{z} da un albero binario di ricerca \textit{T} richiede come argomenti i puntatori a \textit{T} e \textit{z}. La procedura organizza la cancellazione in tre casi:
\begin{enumerate}
\item Se \textit{z} non ha un figlio sinistro, si sostituisce \textit{z} con il suo figlio destro, che può essere \textsc{nil} oppure no. Se il figlio destro di \textit{z} è \textsc{nil}, si ha il caso in cui \textit{z} non ha figli. Se il figlio destro di \textit{z} non è \textsc{nil}, si ha il caso in cui \textit{z} ha un solo figlio, che è il suo figlio destro.
\item Se \textit{z} ha un solo figlio, che è il suo figlio sinistro, si sostituisce \textit{z} con il suo figlio sinistro.
\item Altrimenti, \textit{z} ha un figlio sinistro e un figlio destro. Si trova il successore \textit{y} di \textit{z}, che si trova nel sottoalbero destro di \textit{z} e non ha figlio sinistro. Si vuole staccare \textit{y} dalla sua posizione corrente per metterlo al posto di \textit{z} nell'albero:
\begin{itemize}
\item Se \textit{y} è il figlio destro di \textit{z}, si sostituisce \textit{z} con \textit{y}, lasciando a \textit{y} soltanto il figlio destro.
\item Altrimenti, \textit{y} si trova nel sottoalbero destro di \textit{z}, ma non è il figlio destro di \textit{z}. In questo caso, si sostituisce prima \textit{y} con il suo figlio destro; poi si sostituisce \textit{z} con \textit{y}.
\end{itemize}
\end{enumerate}
Per poter spostare i sottoalberi all'interno dell'albero binario di ricerca, si definisce la procedura \textsc{Transplant}, che sostituisce un sottoalbero, come figlio di suo padre, con un altro sottoalbero. Quando \textsc{Transplant} sostituisce il sottoalbero con radice nel nodo \textit{u} con il sottoalbero con radice nel nodo \textit{v}, il padre del nodo \textit{u} diventa il padre del nodo \textit{v}, e il padre di \textit{u} alla fine ha \textit{v} come figlio.\\\\\
\textsc{Transplant(\textit{T},\,\textit{u},\,\textit{v})}\\
1\firsttab\textbf{if} \textit{u.p} = \textsc{nil}\\
2\secondtab\textit{T.root} $\leftarrow$ \textit{v}\\
3\firsttab\textbf{elseif} \textit{u} = \textit{u.p.left}\\
4\secondtab\textit{u.p.left} $\leftarrow$ \textit{v}\\
5\firsttab\textbf{else} \textit{u.p.right} $\leftarrow$ \textit{v}\\
6\firsttab\textbf{if} \textit{v} $\not=$ \textsc{nil}\\
7\secondtab\textit{v.p} $\leftarrow$ \textit{u.p}\\\\
Le righe 1 - 2 gestiscono il caso in cui \textit{u} è la radice di \textit{T}. Altrimenti, \textit{u} è un figlio sinistro o un figlio destro di suo padre. Le righe 3 - 4 aggiornano \textit{u.p.left} se \textit{u} è un figlio sinistro; la riga 5 aggiorna \textit{u.p.right} se \textit{u} è un figlio destro. Poiché \textit{v} può essere \textsc{nil}, le righe 6 - 7 aggiornano \textit{v.p} se \textit{v} non è \textsc{nil}. \textsc{Transplant} non aggiorna \textit{v.left} e \textit{v.right}; fare ciò, o non farlo, è compito della procedura che chiama \textsc{Transplant}.

Dopo aver definito \textsc{Transplant} è possibile definire la procedura \textsc{Tree-Delete} che cancella un nodo \textit{z} dall'albero binario di ricerca \textit{T}.

Ogni riga di \textsc{Tree-Delete}, incluse le chiamate di \textsc{Transplant}, richiede un tempo costante, tranne la chiamata di \textsc{Tree-Minimum} nella riga 5. Quindi, la procedura \textsc{Tree-Delete} viene eseguita nel tempo $O(h)$ in un albero binario di ricerca di altezza \textit{h}.

Lo pseudocodice di \textsc{Tree-Delete} è il seguente:\\\\
\textsc{Tree-Delete(\textit{T},\,\textit{z})}\\
1\firsttab\textbf{if} \textit{z.left} = \textsc{nil}\\
2\secondtab\textsc{Transplant(\textit{T},\,\textit{z},\,\textit{z.right})}\\
3\firsttab\textbf{elseif} \textit{z.right} = \textsc{nil}\\
4\secondtab\textsc{Transplant(\textit{T},\,\textit{z},\,\textit{z.left})}\\
5\firsttab\textbf{else} \textit{y} $\leftarrow$ \textsc{Tree-Minimum(\textit{z.right})}\\
6\secondtab\textbf{if} \textit{y.p} $\not=$ \textit{z}\\
7\thirdtab\textsc{Transplant(\textit{T},\,\textit{y},\,\textit{y.right})}\\
8\thirdtab\textit{y.right} $\leftarrow$ \textit{z.right}\\
9\thirdtab\textit{y.right.p} $\leftarrow$ \textit{y}\\
10\secondtab\textsc{Transplant(\textit{T},\,\textit{z},\,\textit{y})}\\
11\secondtab\textit{y.left} $\leftarrow$ \textit{z.left}\\
12\secondtab\textit{y.left.p} $\leftarrow$ \textit{y}\\\\
Le righe 1 - 2 gestiscono il caso in cui il nodo \textit{z} non ha un figlio sinistro; le righe 3 - 4 gestiscono il caso in cui il nodo \textit{z} ha un figlio sinistro, ma non ha un figlio destro. Le righe 5 - 12 trattano gli altri due casi in cui \textit{z} ha due figli. La riga 5 trova il nodo \textit{y}, che è successore di \textit{z}. Poiché \textit{z} ha un sottoalbero destro non vuoto, il suo successore deve essere il nodo di quel sottoalbero con la chiave più piccola; da qui la chiamata alla procedura \textsc{Tree-Minimum}. \textit{y}, come detto, non ha un figlio sinistro. Si stacca \textit{y} dalla sua posizione corrente e lo si mette al posto di \textit{z}. Se \textit{y} è il figlio destro di \textit{z}, le righe 10 - 12 sostituiscono \textit{z}, come figlio di suo madre, con \textit{y}; poi, sostituiscono il figlio sinistro di \textit{y} con il figlio sinistro di \textit{z}. Se \textit{y} non è figlio sinistro di \textit{z}, le righe 7 - 9 sostituiscono \textit{y}, come figlio di suo padre, con il figlio destro di \textit{y} e cambiano il figlio destro di \textit{z} nel figlio destro di \textit{y}; le righe 10 - 12 sostituiscono \textit{z}, come figlio di suo padre, con \textit{y} e infine, rimpiazzano il figlio sinistro di \textit{y} con il figlio sinistro di \textit{z}.
\chapter{Alberi rosso-neri}
Gli alberi rosso-neri rappresentano uno dei tanti modi in cui gli alberi di ricerca vengono bilanciati per garantire che le operazioni elementari sugli insiemi dinamici richiedano un tempo $O(lg\,n)$ nel caso peggiore.
\section{Proprietà degli alberi rosso-neri}
Un \textbf{albero rosso-nero} è un albero binario di ricerca in cui ogni nodo \textit{x} ha l'attributo booleano aggiuntivo \textit{x.color}, ovvero il \textbf{colore} del nodo che può essere \textsc{red} o \textsc{black}.

Assegnando dei vincoli al modo in cui i nodi possono essere colorati lungo qualsiasi cammino semplice che va dalla radice a una foglia qualsiasi, gli alberi rosso-neri garantiscono che nessuno di tali cammini sia lungo più del doppio di qualsiasi altro, quindi l'albero è approssimativamente \textbf{bilanciato}.

Ogni nodo dell'albero contiene quindi gli attributi \textit{color}, \textit{key}, \textit{left}, \textit{right} e \textit{p}. Se manca un figlio o il padre di un nodo, il corrispondente attributo puntatore del nodo contiene il valore \textsc{nil}. In particolare, tutti i puntatori a \textsc{nil} sono sostituiti con puntatori alla sentinella \textit{T.\textsc{nil}}. Si utilizza la sentinella \textsc{T.nil} per tutte le foglie dell'albero rosso-nero \textit{T} e come padre della radice dell'albero. Per \textit{T.\textsc{nil}} il suo attributo \textit{color} è  \textsc{black} e gli attributi \textit{key}, \textit{left}, \textit{right} e \textit{p} possono assumere valori arbitrari perché sono irrilevanti.

Un albero rosso-nero è un albero binario di ricerca che gode di cinque proprietà fondamentali:
\begin{enumerate}
\item Ogni nodo è \textbf{rosso} o \textbf{nero}
\item La \textbf{radice} è \textbf{nera}
\item Ogni \textbf{foglia} (\textit{T.\textsc{nil}}) è \textbf{nera}
\item Se un nodo è \textbf{rosso}, allora entrambi i suoi figli sono \textbf{neri}. Ovvero, non possono essere presenti due nodi rossi consecutivi in un cammino semplice dalla radice a una foglia.
\item \textbf{Tutti} i cammini da ogni nodo alle foglie contengono lo \textbf{stesso numero} di nodi \textbf{neri} (si hanno tanti cammini quanto il numero di foglie)
\end{enumerate}
Dato un generico nodo \textit{x} appartenente ad un albero rosso-nero si definiscono due tipologie di altezza: l'\textbf{altezza}, indicata con \textit{h(x)}, e l'\textbf{altezza nera}, indicata con \textit{bh(x)}.
\begin{description}
\item[Altezza \textit{h}(\textit{x}):]Numero di archi nel cammino più lungo fino ad una foglia
\item[Altezza nera \textit{bh}(\textit{x}):]Numero di nodi \textbf{neri} (incluso \textit{T.\textsc{nil}}) nel cammino da \textit{x} alla foglia (escluso \textit{x})
\end{description}
Grazie alla quinta proprietà degli alberi rosso-neri, l'altezza nera di un generico nodo \textit{x} è ben definita.
\begin{theorem}
Ogni nodo con altezza \textit{h} ha altezza nera $\geq h/2$.
\end{theorem}
\begin{proof}
La quarta proprietà degli alberi rosso-neri garantisce che se un nodo è rosso entrambi i suoi figli sono neri. Questa proprietà implica che al massimo $h/2$ nodi nel cammino dal nodo alla foglia sono rossi. Dunque, almeno $h/2$ nodi sono neri.
\end{proof}
\begin{theorem}
Il sottoalbero con radice in un nodo \textit{x} qualsiasi contiene almeno $2^{bh(x)} - 1$ nodi interni.
\end{theorem}
\begin{proof}
Si procede per induzione sull'altezza di \textit{x}. Si pone $h = h(x)$ e $bh = bh(x)$.
\begin{description}
\item[Passo base]Se l'altezza di \textit{x} è 0, cioè $h = h(x) = 0$, allora \textit{x} deve essere una foglia ($bh(x) = 0$) e il sottoalbero con radice in \textit{x} contiene almeno $2^{bh(x)} - 1 = 2^0 -1 = 0$ nodi interni.
\item[Passo induttivo]Si considera un nodo \textit{x} che ha un'altezza positiva ed è quindi un nodo interno con due figli. Ogni figlio di \textit{x} ha altezza $h' = h - 1$ e altezza nera $bh'$ pari a $bh(x)$, se il suo colore è rosso, o pari a $bh(x) - 1$ se il suo colore è nero (per \textit{bh} si valuta il figlio perché nel conteggio di $bh(x)$ si esclude il nodo \textit{x}). Poiché l'altezza di un figlio di \textit{x} è minore dell'altezza di \textit{x}, si può applicare l'ipotesi induttiva per concludere che ogni figlio ha almeno $2^{bh(x) - 1} - 1$ nodi interni. Quindi, il sottoalbero con radice in \textit{x} contiene almeno ($2^{bh(x) - 1} - 1$) + ($2^{bh(x) - 1} - 1$) + 1 = $2^{bh(x)} - 1$ nodi interni ($2^{bh(x) - 1} - 1$ compare due volte perché rappresenta sia il sottoalbero destro sia quello sinistro); questo dimostra l'asserzione.
\end{description}
\end{proof}
\begin{lemma}
L'altezza massima di un albero rosso-nero con \textit{n} nodi interni è $2\,lg(n + 1)$.
\end{lemma}
\begin{proof}
\begin{equation*}
n \geq 2^{bh} - 1 \geq 2^{h/2} - 1 \Rightarrow n + 1 \geq 2^{h/2} \Rightarrow lg(n + 1) \geq h/2 \Rightarrow h \leq 2\,lg(n + 1)
\end{equation*}
\end{proof}
Un'immediata conseguenza di questo lemma è che le operazioni sugli insiemi dinamici \textsc{Search}, \textsc{Minimum}, \textsc{Maximum}, \textsc{Successor} e \textsc{Predecessor} possono essere implementate nel tempo $O(lg\,n)$ negli alberi rosso-neri, perché possono essere eseguite nel tempo $O(h)$ in un albero binario di ricerca di altezza \textit{h} e qualsiasi albero rosso-nero di \textit{n} nodi è un albero binario di ricerca di altezza $O(lg\,n)$.
\section{Rotazioni}
Poiché le operazioni \textsc{Tree-Insert} e \textsc{Tree-Delete} modificano l'albero su cui si sta operando, il risultato potrebbe violare le proprietà degli alberi rosso-neri. Per ripristinare queste proprietà, si dovrà modificare i colori di qualche nodo dell'albero e anche la struttura dei puntatori. La rotazione consente dunque una \textbf{ristrutturazione} dell'albero e viene usata per mantenere gli alberi rosso-neri \textbf{bilanciati}.

La struttura dei puntatori viene modificata tramite una \textbf{rotazione}: un'operazione locale in un albero di ricerca che mantiene l'ordine delle chiavi e preserva la proprietà degli alberi binari di ricerca. I due tipi di rotazione sono: rotazione sinistra e rotazione destra. Quando si esegue una rotazione sinistra in un nodo \textit{x}, supponendo che il suo figlio destro \textit{y} non sia \textit{T.}\textsc{nil}; \textit{x} può essere qualsiasi nodo il cui figlio destro non è \textit{T.}\textsc{nil}. La rotazione sinistra fa perno sul collegamento tra \textit{x} e \textit{y}; il nodo \textit{y} diventa la nuova radice del sottoalbero, con \textit{x} come figlio sinistro di \textit{y} e il figlio sinistro di \textit{y} come figlio destro di \textit{x}.

Lo pseudocodice per \textsc{Left-Rotate} suppone che $x.right \not= T.\textsc{nil}$ e che il padre della radice sia \textit{T.}\textsc{nil}.\\\\
\textsc{Left-Rotate(\textit{T},\,\textit{x})}\\
1\firsttab\textit{y} $\leftarrow$ \textit{x.right}\\
2\firsttab\textit{x.right} $\leftarrow$ \textit{y.left}\\
3\firsttab\textbf{if} \textit{y.left} $\not=$ \textit{T.}\textsc{nil}\\
4\secondtab\textit{y.left.p} $\leftarrow$ \textit{x}\\
5\firsttab\textit{y.p} $\leftarrow$ \textit{x.p}\\
6\firsttab\textbf{if} \textit{x.p} = \textit{T.}\textsc{nil}\\
7\secondtab\textit{T.root} $\leftarrow$ \textit{y}\\
8\firsttab\textbf{elseif} \textit{x} = \textit{x.p.left}\\
9\secondtab\textit{x.p.left} $\leftarrow$ \textit{y}\\
10\firsttab\textbf{else} \textit{x.p.right} $\leftarrow$ \textit{y}\\
11\firsttab\textit{y.left} $\leftarrow$ \textit{x}\\
12\firsttab\textit{x.p} $\leftarrow$ \textit{y}\\\\
Commenti:
\begin{enumerate}
\item[1]Imposta \textit{y}
\item[2]Sposta il sottoalbero sinistro di \textit{y} nel sottoalbero destro di \textit{x}
\item[3]Controlla che il figlio sinistro di \textit{y} non sia vuoto
\item[5]Collega il padre di \textit{x} a \textit{y}
\item[6-8]Se \textit{x} era la sua radice.. altrimenti aggiusta alla riga 8
\item[11]Pone \textit{x} a sinistra di \textit{y}
\end{enumerate}
Il codice per \textsc{Right-Rotate} è simmetrico. Sia la procedura \textsc{Left-Rotate} che \textsc{Right-Rotate} vengono eseguite nel tempo $O(1)$. Soltanto i puntatori vengono modificati da una rotazione; tutti gli altri attributi di un nodo non cambiano. Dopo la rotazione l'albero è più bilanciato.
\section{Inserimento}
L'inserimento di un nodo in un albero rosso-nero di \textit{n} nodi può essere effettuato nel tempo $O(lg\,n)$. Si utilizza una versione modificata della procedura \textsc{Tree-Insert} per inserire un nodo \textit{z} nell'albero \textit{T} come se fosse un normale albero binario di ricerca e poi si colora \textit{z} di rosso. Per garantire che le proprietà degli alberi rosso-neri siano preservate, si chiama una procedura ausiliaria \textsc{RB-Insert-Fixup} che ricolora i nodi ed effettua delle rotazioni.\\\\
\textsc{RB-Insert(\textit{T},\,\textit{z})}\\
1\firsttab\textit{y} $\leftarrow$ \textit{T.}\textsc{nil}\\
2\firsttab\textit{x} $\leftarrow$ \textit{T.root}\\
3\firsttab\textbf{while} \textit{x} $\not=$ \textit{T.}\textsc{nil}\\ 
4\secondtab\textit{y} $\leftarrow$ \textit{x}\\
5\secondtab\textbf{if} \textit{z.key} $<$ \textit{x.key}\\
6\thirdtab\textit{x} $\leftarrow$ \textit{x.left}\\
7\secondtab\textbf{else} \textit{x} $\leftarrow$ \textit{x.right}\\
8\firsttab\textit{z.p} $\leftarrow$ \textit{y}\\
9\firsttab\textbf{if} \textit{y} = \textit{T.}\textsc{nil}\\
10\secondtab\textit{T.root} $\leftarrow$ \textit{z}\\
11\firsttab\textbf{elseif} \textit{z.key} $<$ \textit{y.key}\\
12\secondtab\textit{y.left} $\leftarrow$ \textit{z}\\
13\firsttab\textbf{else} \textit{y.right} $\leftarrow$ \textit{z}\\
14\firsttab\textit{z.left} $\leftarrow$ \textit{T.}\textsc{nil}\\
14\firsttab\textit{z.right} $\leftarrow$ \textit{T.}\textsc{nil}\\
16\firsttab\textit{z.color} $\leftarrow$ \textsc{red}\\
17\firsttab\textsc{RB-Insert-Fixup(\textit{T},\,\textit{z})}\\\\
Commenti:
\begin{enumerate}
\item[1-15]Normale inserimento in un albero binario di ricerca
\item[17]Dopo aver colorato il nuovo nodo in rosso si potrebbero violare le proprietà degli alberi rosso-neri il che comporta che l'albero si sta sbilanciando; si chiama dunque la procedura \textsc{RB-Insert-Fixup} per aggiustare l'albero
\end{enumerate}
Tutte le istanze di \textsc{nil} in \textsc{Tree-Insert} sono sostituite con \textit{T.}\textsc{nil}. Si assegna \textit{T.}\textsc{nil} a \textit{z.left} e \textit{z.right} nelle righe 14 - 15 per mantenere la struttura appropriata dell'albero.

Dopo aver inserito il nuovo nodo \textit{z} e averlo colorato in rosso si potrebbe violare una proprietà degli alberi rosso-neri:
\begin{description}
\item[P1] OK
\item[P3] OK
\item[P5] OK
\item[P2]Violata se \textit{z} è la nuova radice dell'albero rosso-nero
\item[P4]Violata se \textit{z.p} è rosso. In tal caso si avrebbero due rossi di fila
\end{description}
Per arrivare a definire completamente la procedura \textsc{RB-Insert-Fixup} si parte dal ciclo \textbf{while} più esterno\\\\
\textsc{RB-Insert-Fixup(\textit{T},\,\textit{z})}\\
1\firsttab\textbf{while} \textit{z.p.color} = \textsc{red}\\
$\vdots$\\
16\firsttab\textit{T.root.color} $\leftarrow$ \textsc{black}\\\\
A questo ciclo \textbf{while} è associata la seguente invariante di ciclo composta da tre parti:
\begin{quote}
\textit{All'inizio di ogni iterazione del ciclo:
\begin{itemize}
\item Il nodo z è rosso
\item Se z.p è la radice, allora z.p è nero
\item Se ci sono violazioni delle proprietà degli alberi rosso-neri, al massimo ce n'è una su tutto l'albero e riguarda la proprietà 2 o la proprietà 4. Se c'è una violazione della seconda proprietà, questa si verifica perché il nodo z è la radice ed è rossa. Se c'è una violazione della quarta proprietà, essa si verifica perché z e z.p sono entrambi rossi
\end{itemize}}
\end{quote}
Si dimostra ora la sua validità:
\begin{description}
\item[Inizializzazione]Prima della prima iterazione del ciclo, si parte da un albero rosso-nero senza violazioni a cui si è aggiunto un nodo rosso \textit{z}:
\begin{itemize}
\item\textit{z} è settato rosso
\item Se \textit{z.p} è la radice, allora se era rosso viene violata la quarta proprietà, altrimenti tutte le proprietà sono rispettate
\item Il resto dell'albero rimane immutato, è stato aggiunto un nodo che viene colorato in rosso ma questo non varia le altezze nere che sono dunque corrette
\end{itemize}
Se c'è una violazione della seconda proprietà, allora la radice rossa deve essere il nodo \textit{z} appena inserito, che in tal caso è l'unico nodo interno nell'albero. Poiché il padre ed entrambi i figli di \textit{z} sono la sentinella, che è nera, non c'è violazione della quarta proprietà. Quindi, questa violazione della seconda proprietà è l'unica violazione delle proprietà degli alberi rosso-neri nell'intero albero. Se c'è una violazione della quarta proprietà, allora, poiché i figli del nodo \textit{z} sono sentinelle nere e l'albero non aveva altre violazioni prima dell'inserimento di \textit{z}, la violazione deve essere attribuita al fatto che \textit{z} e \textit{z.p} sono entrambi rossi. Non ci sono altre violazioni delle proprietà degli alberi rosso-neri
\item[Conclusione]Il ciclo termina perché \textit{z.p} è nero. Quindi, non c'è violazione della quarta proprietà alla conclusione del ciclo. Per l'invariante di ciclo, l'unica proprietà che potrebbe essere violata è la seconda. La riga 16 ripristina anche questa proprietà, cosicché quando \textsc{RB-Insert-Fixup} termina, tutte le proprietà degli alberi rosso-neri sono valide
\item[Conservazione]Ci sarebbero sei casi da considerare nel ciclo \textbf{while} ma tre di essi sono simmetrici agli altri tre, a seconda che il padre \textit{z.p} di \textit{z} sia un figlio sinistro o un figlio destro del nonno \textit{z.p.p} di \textit{z}; ciò è determinato nella riga 2. Si considera solo il caso in cui \textit{z.p} è un figlio sinistro. Il nonno \textit{z.p.p} esiste, in quanto per il secondo punto dell'invariante di ciclo, se \textit{z.p} è la radice, allora \textit{z.p} è nero. Poiché si entra in una iterazione del ciclo soltanto se \textit{z.p} è rosso, si sa che \textit{z.p} non può essere la radice. Quindi \textit{z.p.p} esiste.  Il caso 1 si distingue dai casi 2 e 3 per il colore del fratello del padre di \textit{z} (lo zio di \textit{z}). La riga 3 fa sì che \textit{y} punti allo zio \textit{z.p.p.right} di \textit{z} e la riga 4 effettua un test. Se \textit{y} è rosso, allora viene applicato il caso 1, altrimenti il controllo passa ai casi 2 e 3. In tutti e tre i casi, il nonno \textit{z.p.p} di \textit{z} è nero, in quanto il padre \textit{z.p} è rosso, quindi la quarta proprietà è violata solo fra \textit{z} e \textit{z.p}.
\begin{description}
\item[Caso 1 : lo zio \textit{y} di \textit{z} è rosso]Questo caso viene eseguito quando \textit{z.p} e \textit{y} sono entrambi rossi. Poiché il nonno \textit{z.p.p} è nero (sicuro perché prima dell'inserimento era un albero rosso-nero), si può colorare di nero \textit{z.p} e \textit{y}, risolvendo così il problema che \textit{z} e \textit{z.p} sono entrambi rossi e rispettando così la quarta proprietà; si colora di rosso \textit{z.p.p} per conservare la quinta proprietà. A questo punto si ripete il ciclo \textbf{while} con \textit{z.p.p} come il nuovo nodo \textit{z}. Il puntatore \textit{z} si sposta di due livelli in alto nell'albero.\\\\
\textsc{RB-Insert-Fixup(\textit{T},\,\textit{z})}\\
1\firsttab\textbf{while} \textit{z.p.color} = \textsc{red}\\
2\secondtab\textbf{if} \textit{z.p} = \textit{z.p.p.left}\\
3\thirdtab\textit{y} $\leftarrow$ \textit{z.p.p.right}\\
4\thirdtab\textbf{if} \textit{y.color} = \textsc{red}\\
5\fourthtab\textit{z.p.color} $\leftarrow$ \textsc{black}\\
6\fourthtab\textit{y.color} $\leftarrow$ \textsc{black}\\
7\fourthtab\textit{z.p.p.color} $\leftarrow$ \textsc{red}\\
8\fourthtab\textit{z} $\leftarrow$ \textit{z.p.p}\\
9\thirdtab\textbf{else}\\
$\vdots$\\\\
Commenti:
\begin{enumerate}
\item[2]Figlio sinistro
\item[4]Caso 1 : lo zio è rosso
\item[5-7]Cambia i colori come visto
\item[8]Va al nonno
\item[9]Else... lo zio è nero
\end{enumerate}
\item[Caso 2 : lo zio \textit{y} di \textit{z} è nero e \textit{z} è un figlio destro]Questo caso e il successivo si distinguono a seconda che \textit{z} sia un figlio destro o sinistro di \textit{z.p}. Le righe 10 - 11 costituiscono il caso 2. In questo caso, il nodo \textit{z} è un figlio destro di suo padre, \textit{z.p.p} è ancora nero. Si effettua una rotazione sinistra intorno a \textit{z.p} per trasformare la situazione nel caso 3 in cui il nodo \textit{z} è un figlio sinistro. Poiché \textit{z} e \textit{z.p} sono entrambi rossi, la rotazione non influisce né sull'altezza nera dei nodi né sulla quinta proprietà. Non vengono cambiati i colori.\\\\
\textsc{RB-Insert-Fixup(\textit{T},\,\textit{z})}\\
$\vdots$\\
9\thirdtab\textbf{else if} \textit{z} = \textit{z.p.right}\\
10\fifthtab\textit{z} $\leftarrow$ \textit{z.p}\\
11\fifthtab\textsc{Left-Rotate(\textit{T},\,\textit{z})}\\
$\vdots$
\item[Caso 3 : lo zio \textit{y} di \textit{z} è nero e \textit{z} è un figlio sinistro]Sia che si entri nel caso 3 direttamente o tramite il caso 2, lo zio \textit{y} di \textit{z} è nero, perché altrimenti si avrebbe eseguito il caso 1. In aggiunta, il nodo \textit{z.p.p} esiste e, dopo aver spostato \textit{z} di un livello in alto nella riga 10 e poi di un livello in basso nella 11, l'identità di \textit{z.p.p} resta invariata. In questo caso, si colora \textit{z.p} di nero, \textit{z.p.p} di rosso e si effettua una rotazione destra su \textit{z.p.p} per preservare tutte le proprietà. Il corpo del \textbf{while} non viene eseguito un'altra volta, in quanto \textit{z.p} ora è nero.\\\\
\textsc{RB-Insert-Fixup(\textit{T},\,\textit{z})}\\
$\vdots$\\
12\fourthtab\textit{z.p.color} $\leftarrow$ \textsc{black}\\
13\fourthtab\textit{z.p.p.color} $\leftarrow$ \textsc{red}\\
14\fourthtab\textsc{Right-Rotate(\textit{T},\,\textit{z.p.p})}\\
$\vdots$
\end{description}
\end{description}
Si arriva quindi alla versione completa della procedura \textsc{RB-Insert-Fixup}:\\\\
\textsc{RB-Insert-Fixup(\textit{T},\,\textit{z})}\\
1\firsttab\textbf{while} \textit{z.p.color} = \textsc{red}\\
2\secondtab\textbf{if} \textit{z.p} = \textit{z.p.p.left}\\
3\thirdtab\textit{y} $\leftarrow$ \textit{z.p.p.right}\\
4\thirdtab\textbf{if} \textit{y.color} = \textsc{red}\\
5\fourthtab\textit{z.p.color} $\leftarrow$ \textsc{black}\\
6\fourthtab\textit{y.color} $\leftarrow$ \textsc{black}\\
7\fourthtab\textit{z.p.p.color} $\leftarrow$ \textsc{red}\\
8\fourthtab\textit{z} $\leftarrow$ \textit{z.p.p}\\
9\thirdtab\textbf{else if} \textit{z} = \textit{z.p.right}\\
10\fifthtab\textit{z} $\leftarrow$ \textit{z.p}\\
11\fifthtab\textsc{Left-Rotate(\textit{T},\,\textit{z})}\\
12\fourthtab\textit{z.p.color} $\leftarrow$ \textsc{black}\\
13\fourthtab\textit{z.p.p.color} $\leftarrow$ \textsc{red}\\
14\fourthtab\textsc{Right-Rotate(\textit{T},\,\textit{z.p.p})}\\
15\secondtab\textbf{else} (come righe 3 - 14 scambiando \textit{right} e \textit{left})\\
16\firsttab\textit{T.root.color} $\leftarrow$ \textsc{black}\\\\
Commenti:
\begin{enumerate}
\item[5-8]Risolve il caso 1
\item[10-11]Risolve il caso 2
\item[11]Trasforma il caso 2 nel caso 3
\item[12-14]Risolve il caso 3
\end{enumerate}
Per un albero rosso-nero di \textit{n} nodi le righe 1 - 16 di \textsc{RB-Insert} richiedono il tempo $O(lg\,n)$. Nella procedura \textsc{RB-Insert-Fixup} il ciclo \textbf{while} viene ripetuto soltanto se viene eseguito il caso 1 e in tal caso il puntatore \textit{z} si sposta di due livelli in alto nell'albero. Il numero totale di volte che può essere eseguito il ciclo \textbf{while} è quindi $O(lg\,n)$. Di conseguenza, \textsc{RB-Insert} richiede un tempo totale pari a $O(lg\,n)$. Il ciclo \textbf{while} non effettua mai più di due rotazioni, perché termina se viene eseguito il caso 2 o il caso 3. 
\section{Cancellazione}
Quando si cancella un nodo bisogna stare attenti a che colore aveva il nodo rimosso:
\begin{description}
\item[Rosso]In questo caso non ci sono problemi perché, dopo aver rimosso il nodo, l'altezza nera $bh$ non è variata, non si hanno due nodi rossi a fila e non viene violata la seconda proprietà perché se il nodo eliminato è rosso tale nodo non è sicuramente la radice.
\item[Nero]Si potrebbe violare la seconda proprietà se il nodo rimosso era la radice e suo figlio (la nuova radice) era rosso, oppure la quarta proprietà (due rossi a fila), oppure ancora la quinta proprietà (cammino nero).
\end{description}
Ci sarebbero nove casi da considerare e risolvere.
\chapter{Strutture dati aumentate}
Raramente si andrà a progettare una struttura dati da zero. Più frequentemente, sarà sufficiente prendere una struttura dati nota e aggiungere nuove informazioni; ovvero sarà sufficiente aumentare una struttura dati elementare memorizzando in essa delle informazioni aggiuntive. Oltre l'aggiunta di nuove informazioni sarà anche possibile andare a definire delle nuove operazioni per la struttura dati considerata. Aumentare una struttura dati non è sempre semplice, in quanto le informazioni aggiuntive devono essere aggiornate e gestite dalle ordinarie operazioni sulla struttura dati e devono essere gestite correttamente senza perdita di efficienza.
\section{Statistiche d'ordine dinamiche}
L'\textit{i}-esima \textbf{statistica d'ordine} di un insieme di \textit{n} elementi, con $i \in \{1,\,2,\,...\,,\,n\}$, è l'elemento dell'insieme con l'\textit{i}-esima chiave più piccola. Qualsiasi statistica d'ordine su di un insieme dinamico può essere ottenuta nel tempo $O(n)$ da un insieme non ordinato. Si definisce invece \textbf{rango} di un elemento, la posizione che occupa nella sequenza ordinata degli elementi dell'insieme. A differenza della statistica d'ordine, il rango può essere determinato nel tempo $O(lg\,n)$.

Un \textbf{albero per statistiche d'ordine} \textbf{T} è un albero rosso-nero con un'informazione aggiuntiva memorizzata in ogni nodo. In un nodo \textit{x} di un albero rosso-nero, oltre agli attributi usuali \textit{x.key}, \textit{x.left}, \textit{x.right}, \textit{x.p} e \textit{x.color} compare il nuovo attributo \textit{x.size}. Questo attributo contiene il numero di nodi interni nel sottoalbero con radice in \textit{x} (incluso lo stesso \textit{x} ed escluse le foglie - sentinelle), cioè la dimensione del sottoalbero. Se si definisce che la dimensione della sentinella \textit{T.}\textsc{nil} è 0, ovvero si imposta \textit{T.\textsc{nil}.size} a 0, allora si ha l'identità:
\begin{equation*}
x.size = x.left.size + x.right.size + 1
\end{equation*}
Il +1 indica il nodo \textit{x} stesso.

In un albero per statistiche d'ordine non è richiesto che le chiavi siano distinte. In presenza di chiavi uguali, la precedente notazione di rango non è ben definita. Si elimina questa ambiguità definendo il rango di un elemento come la posizione in cui l'elemento sarebbe elencato in un attraversamento simmetrico dell'albero (inorder).
\subsection{Ricerca di un elemento con un dato rango}
La procedura \textsc{OS-Select} consente di trovare un elemento con un dato rango. Ritorna il puntatore al nodo che contiene l'\textit{i}-esima chiave più piccola nel sottoalbero con radice in \textit{x}. Per trovare il nodo con l'\textit{i}-esima chiave più piccola in un albero per statistiche d'ordine \textit{T}, la chiamata iniziale è \textsc{OS-Select(\textit{T.root},\,\textit{i})}.\\\\
\textsc{OS-Select(\textit{x},\,\textit{i})}\\
1\firsttab\textit{r} $\leftarrow$ \textit{x.left.size} + 1\\
2\firsttab\textbf{if} \textit{i} = \textit{r}\\
3\secondtab\textbf{return} \textit{x}\\
4\firsttab\textbf{elseif} \textit{i} $<$ \textit{r}\\
5\secondtab\textbf{return} \textsc{OS-Select(\textit{x.left},\,\textit{i})}\\
6\firsttab\textbf{else return} \textsc{OS-Select(\textit{x.right},\,\textit{i - r})}\\\\
Commenti:
\begin{enumerate}
\item[0]Parte dalla radice e via via scende
\item[1]\textit{r} è il rango del nodo \textit{x}
\item[5]Va nel sottoalbero sinistro se minore
\item[6]Va nel sottoalbero destro se maggiore
\item[6]\textit{i - r} sono i valori che seguono \textit{r} che hanno rango successivo
\end{enumerate}
Nella riga 1  di \textsc{OS-Select} si calcola \textit{r}, il rango del nodo \textit{x} nel sottoalbero di radice \textit{x}. Il valore di \textit{x.left.size} è il numero di nodi che precedono \textit{x} in un attraversamento simmetrico del sottoalbero con radice in \textit{x}. Quindi, il valore \textit{x.left.size} + 1 è il rango di \textit{x} all'interno del sottoalbero con radice in \textit{x}. Se $i = r$, allora il nodo \textit{x} è l'\textit{i}-esimo elemento più piccolo, quindi la riga 3 restituisce \textit{x}. Se $i < r$, allora l'\textit{i}-esimo elemento più piccolo è nel sottoalbero sinistro di \textit{x}, quindi la riga 5 effettua una ricorsione su \textit{x.left}. Se $i > r$, allora l'\textit{i}-esimo elemento più piccolo è nel sottoalbero destro di \textit{x}. Poiché ci sono \textit{r} elementi nel sottoalbero con radice in \textit{x} che precedono il sottoalbero destro di \textit{x} in un attraversamento simmetrico, l'\textit{i}-esimo elemento più piccolo nel sottoalbero con radice in \textit{x} è l'($i - r$)-esimo elemento più piccolo nel sottoalbero con radice in \textit{x.right}. Questo elemento è determinato in modo ricorsivo nella riga 6.

La procedura \textsc{OS-Select} è ricorsiva in coda e può dunque essere vista come una procedura iterativa a cui è associata l'invariante di ciclo:
\begin{quote}
\textit{Prima di ogni iterazione l'i-esimo valore si trova nel sottoalbero con radice in x}
\end{quote}
Indicato con \textit{r} il rango di \textit{x} nel sottoalbero con radice in \textit{x}:
\begin{itemize}
\item Se $i = r$, l'invariante è verificata perché ritorna \textit{x}
\item Se $i < r$, allora l'\textit{i}-esimo elemento più piccolo è nel sottoalbero sinistro
\item Se $i > r$, allora l'\textit{i}-esimo elemento più piccolo si trova nel sottoalbero destro. Si tolgono gli \textit{r} elementi nel sottoalbero di \textit{x} che precedono quelli nel sottoalbero destro di \textit{x}
\end{itemize}
Poiché per ogni chiamata ricorsiva si scende di un livello nell'albero per statistiche d'ordine, il tempo totale di \textsc{OS-Select}, nel caso peggiore, è proporzionale all'altezza dell'albero. Poiché l'albero è un albero rosso-nero, la sua altezza è $O(lg\,n)$, dove \textit{n} è il numero di nodi. Quindi, il tempo di esecuzione di \textsc{OS-Select} è $O(lg\,n)$ per un insieme dinamico di \textit{n} elementi.
\subsection{Determinare il rango di un elemento}
Dato un puntatore a un nodo \textit{x} in un albero per statistiche d'ordine \textit{T}, la procedura \textsc{OS-Rank} restituisce la posizione di \textit{x} nell'ordinamento lineare determinato da un attraversamento simmetrico dell'albero \textit{T}.\\\\
\textsc{OS-Rank(\textit{T},\,\textit{x})}\\
1\firsttab\textit{r} $\leftarrow$ \textit{x.left.size} + 1\\
2\firsttab\textit{y} $\leftarrow$ \textit{x}\\
3\firsttab\textbf{while} \textit{y} $\not=$ \textit{T.root}\\
4\secondtab\textbf{if} \textit{y} = \textit{y.p.right}\\
5\thirdtab\textit{r} $\leftarrow$ \textit{r} + \textit{y.p.left.size} + 1\\
6\secondtab\textit{y} $\leftarrow$ \textit{y.p}\\
7\firsttab\textbf{return} \textit{r}\\\\
Commenti:
\begin{enumerate}
\item[0]Parte da un nodo e risale verso la radice
\item[3]Finché non arriva alla radice
\item[4-5]Si deve capire se il nodo è un figlio destro o un figlio sinistro del padre. Se è un figlio destro, cambia posizione
\item[6]Se figlio sinistro la posizione non cambia
\end{enumerate}
Il rango di \textit{x} può essere considerato come il numero di nodi che precedono \textit{x} in un attraversamento simmetrico dell'albero, più 1 per \textit{x} stesso. \textsc{OS-Rank} conserva la seguente invariante di ciclo:
\begin{quote}
\textit{All'inizio di ogni iterazione del ciclo \textbf{while} (righe 3 - 6), r è il rango di x.key nel sottoalbero con radice nel nodo y. Ovvero  si verifica che r = rank(x.key,\,y)}
\end{quote}
Si dimostra ora la sua validità:
\begin{description}
\item[Inizializzazione]Prima della prima iterazione, la riga 1 assegna a \textit{r} il rango di \textit{x.key} all'interno del sottoalbero con radice in \textit{x}. L'assegnazione di \textit{x} ad \textit{y} nella riga 2 rende l'invariante vera la prima volta che viene eseguito il test nella riga 3
\item[Conservazione]Se, all'inizio del ciclo, \textit{r} è il rango di x.key nel sottoalbero con radice nel nodo y, allora, alla fine del ciclo, \textit{r} è il rango di \textit{x.key} nel sottoalbero con radice nel nodo \textit{y.p}. Se \textit{y} è un figlio sinistro, il sottoalbero del fratello ha nodi che seguono \textit{x}, dunque \textit{r} non cambia. Se, invece, \textit{y} è un figlio destro, tutti i nodi nel sottoalbero del fratello precedono tutti i nodi nel sottoalbero di \textit{y}, dunque \textit{r} $\leftarrow$ \textit{r} + \textit{y.p.left.size} + 1
\item[Conclusione]Il ciclo termina quando \textit{y} = \textit{T.root}, quindi il sottoalbero con radice in \textit{y} è l'intero albero. Dunque, il valore di \textit{r} è il rango di \textit{x.key} nell'intero albero
\end{description}
Poiché ogni iterazione del ciclo \textbf{while} impiega il tempo $O(1)$ e \textit{y} risale di un livello nell'albero a ogni iterazione, il tempo di esecuzione di \textsc{OS-Rank}, nel caso peggiore, è proporzionale all'altezza dell'albero: $O(lg\,n)$ in un albero per statistiche d'ordine di \textit{n} nodi.
\subsection{Gestione delle dimensioni dei sottoalberi}
Dato l'attributo \textit{size} in ogni nodo, \textsc{OS-Select} e \textsc{OS-Rank} possono calcolare rapidamente le informazioni sulle statistiche d'ordine. Tuttavia, questo lavoro risulterebbe inutile se questi attributi non potessero essere gestiti con efficienza dalle operazioni di base che modificano gli alberi rosso-neri. Si dovranno quindi gestire le dimensioni dei sottoalberi durante le operazioni di inserimento e cancellazione senza influire sul tempo di esecuzione asintotico di ciascuna operazione.

L'inserimento in un albero rosso-nero si svolge in due fasi. Nella prima fase, si discende dalla radice dell'albero, inserendo il nuovo nodo come figlio di un nodo esistente. Nella seconda fase si risale verso la radice, cambiando i colori ed effettuando qualche rotazione per conservare le proprietà degli alberi rosso-neri. 

Per gestire le dimensioni dei sottoalberi nella prima fase, si incrementa semplicemente \textit{x.size} per ogni nodo \textit{x} nel cammino semplice dalla radice fino alle foglie. Il nuovo nodo che viene aggiunto ha l'attributo \textit{size} pari a 1. Poiché ci sono $O(lg\,n)$ nodi lungo il cammino percorso, il costo addizionale per gestire gli attributi \textit{size} è $O(lg\,n)$. 

Nella seconda fase, le uniche modifiche strutturali dell'albero rosso-nero di base sono provocate dalle rotazioni, che sono al massimo due. Inoltre, una rotazione è un'operazione locale: soltanto due nodi hanno gli attributi \textit{size} invalidati, i due nodi uniti dal collegamento attorno ai quali viene effettuata la rotazione. Facendo riferimento al codice della procedura \textsc{Left-Rotate(\textit{T},\,\textit{x})} si aggiornano le seguenti righe:\\\\
13\firsttab\textit{y.size} $\leftarrow$ \textit{x.size}\\
14\firsttab\textit{x.size} $\leftarrow$ \textit{x.left.size} + \textit{x.right.size} + 1\\\\
La modifica di \textsc{Right-Rotate} è simmetrica.

Poiché vengono effettuate al massimo due rotazioni durante l'inserimento in un albero rosso-nero, occorre soltanto un tempo addizionale $O(1)$ per aggiornare gli attributi \textit{size} nella seconda fase. Quindi, il tempo totale per completare l'inserimento in un albero per statistiche d'ordine di \textit{n} nodi è $O(lg\,n)$, che è asintoticamente uguale a quello di un normale albero rosso-nero.

Anche la cancellazione da un albero rosso-nero è formata da due fasi: la prima opera sull'albero di ricerca sottostante; la seconda provoca al massimo tre rotazioni, senza altre modifiche strutturali. La prima fase o rimuove un nodo \textit{y} oppure lo sposta più in alto nell'albero. Per aggiornare le dimensioni dei sottoalberi, si segue un cammino semplice dal nodo \textit{y} (partendo dalla sua posizione originale nell'albero) fino alla radice, riducendo il valore dell'attributo \textit{size} per ogni nodo che si incontra. Poiché questo cammino semplice ha una lunghezza $O(lg\,n)$ in un albero rosso-nero di \textit{n} nodi, il tempo aggiuntivo che viene impiegato per gestire gli attributi \textit{size} nella prima fase è $O(lg\,n)$. Le $O(1)$ rotazioni nella seconda fase della cancellazione possono essere gestite come è stato fatto nell'inserimento. Quindi, le operazioni di inserimento e cancellazione, inclusa la gestione degli attributi \textit{size}, richiedono un tempo $O(lg\,n)$ su di un albero per statistiche d'ordine di \textit{n} nodi.
\section{Aumentare una struttura dati}
Il procedimento per aumentare una struttura dati può essere suddiviso in quattro passi:
\begin{enumerate}
\item Scegliere una struttura dati di base
\item Determinare le informazioni aggiuntive da gestire nella struttura dati di base
\item Verificare che le informazioni aggiuntive possono essere gestite dalle operazioni elementari sulla struttura dati di base che la modificano
\item Sviluppare nuove operazioni
\end{enumerate}
Non occorre seguire i passi nell'ordine in cui sono elencati. Spesso la progettazione include una fase in cui si procede per tentativi e il progresso nei vari passi, di solito, avviene in parallelo.

Per poter progettare gli alberi per statistiche d'ordine:
\begin{enumerate}
\item Si scelgono gli alberi rosso-neri come struttura dati di base. Un segnale sull'idoneità degli alberi rosso-neri proviene dal loro efficiente supporto ad altre operazioni sugli insiemi dinamici con ordinamento totale, come \textsc{Minimum}, \textsc{Maximum}, \textsc{Successor} e \textsc{Predecessor}
\item Si aggiunge l'attributo \textit{size}. Ogni nodo memorizza la dimensione del sottoalbero con radice in \textit{x}. In generale, le informazioni aggiuntive rendono le operazioni più efficienti
\item Si verifica che si possono gestire le informazioni aggiuntive per le operazioni esistenti sulla struttura dati. In particolare si è garantito che le operazioni di inserimento e cancellazione possono gestire correttamente gli attributi \textit{size}, continuando ad essere eseguite nel tempo $O(lg\,n)$
\item Si sviluppano le nuove operazioni \textsc{OS-Select} e \textsc{OS-Rank}
\end{enumerate}
\subsection{Aumentare gli alberi rosso-neri}
Quando una struttura dati aumentata si basa sugli alberi rosso-neri, si può provare che certi tipi di informazioni aggiuntive possono essere gestiti in maniera efficiente nelle operazioni di inserimento e cancellazione.
\begin{theorem}
Sia \textit{f} un attributo che aumenta un albero rosso-nero \textit{T} di \textit{n} nodi; si suppone che il valore di \textit{f} per un nodo \textit{x} possa essere calcolato utilizzando soltanto le informazioni nei nodi \textit{x}, \textit{x.left} e \textit{x.right}, inclusi \textit{x.left.f} e \textit{x.right.f} (solo dal nodo stesso, dal figlio destro e sinistro e non da tutto l'albero). Allora, è possibile gestire i valori di \textit{f} in tutti i nodi di \textit{T} durante l'inserimento e la cancellazione, senza influire asintoticamente sulla prestazione $O(lg\,n)$ di queste operazioni.
\end{theorem}
\begin{proof}
Il concetto che sta alla base della dimostrazione è che la modifica di un attributo \textit{f} in un nodo \textit{x} si propaga soltanto agli antenati di \textit{x} nell'albero. Ovvero, la modifica di \textit{x.f} potrebbe richiedere l'aggiornamento di \textit{x.p.f}, ma nient'altro; l'aggiornamento di \textit{x.p.f} potrebbe richiedere l'aggiornamento di \textit{x.p.p.f}, ma nient'altro; e così via risalendo l'albero. Quando viene aggiornato \textit{T.root.f}, nessun altro nodo dipende da questo nuovo valore, quindi il processo termina. Poiché l'altezza di un albero rosso-nero è $O(lg\,n)$, la modifica di un attributo \textit{f} in un nodo richiede un tempo $O(lg\,n)$ per aggiornare i nodi che dipendono da tale modifica.

L'inserimento di un nodo \textit{x} nell'albero \textit{T} si compone di due fasi. Durante la prima fase, \textit{x} viene inserito come figlio di un nodo esistente \textit{x.p}. Il valore di \textit{x.f} può essere calcolato nel tempo $O(1)$ perché, per ipotesi, dipende soltanto dalle informazioni negli altri attributi dello stesso \textit{x} e dalle informazioni dei figli di \textit{x}, ma i figli di \textit{x} sono entrambi la sentinella \textit{T.\textsc{nil}}. Una volta calcolato \textit{x.f}, la modifica si propaga verso l'alto nell'albero. Quindi, il tempo totale per la prima fase dell'inserimento è $O(lg\,n)$. Durante la seconda fase, le uniche modifiche strutturali dell'albero derivano dalle rotazioni. Poiché in una rotazione cambiano soltanto due nodi, il tempo totale per aggiornare gli attributi \textit{f} è $O(lg\,n)$ per rotazione. Dal momento che in un inserimento ci sono al massimo due rotazioni, il tempo totale per l'inserimento è $O(lg\,n)$.

Come l'inserimento, anche la cancellazione si svolge in due fasi. Nella prima fase, la modifiche dell'albero si verificano quando il nodo cancellato viene effettivamente rimosso dall'albero. Se il nodo cancellato aveva due figli il suo successore viene messo al suo posto e quindi il nodo effettivamente rimosso è il successore. La propagazione degli aggiornamenti di \textit{f} indotti da queste modifiche costa al massimo $O(lg\,n)$, in quanto le modifiche cambiano localmente l'albero. La sistemazione dell'albero rosso-nero durante la seconda fase richiede al massimo tre rotazioni, ciascuna delle quali impiega al massimo il tempo $O(lg\,n)$ per propagare gli aggiornamenti di \textit{f}. Quindi, come per l'inserimento, il tempo totale per la cancellazione è $O(lg\,n)$.
\end{proof}
In molti casi, come la gestione degli attributi \textit{size} negli alberi per statistiche d'ordine, il costo di aggiornamento dopo una rotazione è $O(1)$, anziché $O(lg\,n)$ come appena dimostrato. 
\section{Alberi di Intervalli}
Tramite gli alberi di intervalli è possibile gestire un insieme di intervalli, per esempio gli intervalli temporali. È possibile rappresentare un intervallo [$t_1$,\,$t_2$], con $t_1 \leq t_2$, come un oggetto \textit{i}, con gli attributi \textit{i.low} = $t_1$ (\textbf{estremo inferiore}) e \textit{i.high} = $t_2$ (\textbf{estremo superiore}). Si dirà che gli intervalli \textit{i} e \textit{j} \textbf{si sovrappongono} se e solo se $i \,\cap\, j \neq \emptyset$, ovvero se $i.low \leq j.high$ e $j.low \leq i.high$. Alternativamente, \textit{i} e \textit{j} \textbf{non si sovrappongono} se e solo se $i.low > j.high$ o $j.low > i.high$. Due intervalli qualsiasi \textit{i} e \textit{j} soddisfano la \textbf{tricotomia degli intervalli}; ovvero una sola delle seguenti proprietà può essere vera
\begin{itemize}
\item\textit{i} e \textit{j} si sovrappongono
\item\textit{i} è a sinistra di \textit{j} (cioè $i.high < j.low$)
\item\textit{i} è a destra di \textit{j} (cioè $j.high < i.low$)
\end{itemize}
Un \textbf{albero di intervalli} è un albero rosso-nero che gestisce un insieme dinamico di elementi, in cui ogni elemento \textit{x} contiene un intervallo \textit{x.int}. Gli alberi di intervalli supportano le seguenti operazioni:
\begin{description}
\item\textsc{Interval-Insert(\textit{T,\,\textit{x}})} aggiunge l'elemento \textit{x}, il cui attributo \textit{int} si suppone contenga un intervallo, all'albero di intervalli \textit{T}
\item\textsc{Interval-Delete(\textit{T,\,\textit{x}})} rimuove l'elemento \textit{x} dall'albero di intervalli \textit{T}
\item\textsc{Interval-Search(\textit{T,\,\textit{i}})} restituisce un puntatore a un elemento \textit{x} nell'albero di intervalli \textit{T} tale che \textit{x.int} si sovrappone all'intervallo \textit{i} o  restituisce un puntatore alla sentinella \textit{T.\textsc{nil}} se non esiste tale elemento nell'insieme
\end{description}
\subsection{Progetto di un albero di intervalli}
Come visto precedentemente, per poter aumentare una struttura dati, si segue un approccio diviso in quattro passi:
\begin{enumerate}
\item Scegliere una struttura dati sottostante
\item Determinare le informazioni aggiuntive da gestire
\item Verificare che si possono gestire le informazioni aggiuntive per le operazioni esistenti sulla struttura dati
\item Sviluppare nuove operazioni
\end{enumerate}
Nel caso degli alberi di intervalli:
\begin{description}
\item[Passo 1 : Struttura dati di base]Si sceglie un albero rosso-nero in cui ogni nodo \textit{x} contiene un intervallo \textit{x.int} e la chiave di \textit{x} è l'estremo inferiore, \textit{x.int.low}, dell'intervallo. Quindi, un attraversamento simmetrico (attraversamento inorder) della struttura dati elenca ordinatamente gli intervalli in funzione dell'estremo inferiore
\item[Passo 2 : Informazioni aggiuntive]Oltre agli intervalli, ogni nodo \textit{x} contiene un valore \textit{x.max}, che è il massimo tra tutti gli estremi destri degli intervalli memorizzati nel sottoalbero con radice in \textit{x}.
\begin{equation*}
x.max = max \left\{
\begin{array}{l}
x.int.high\\
x.left.max\\
x.right.max
\end{array}\right.
\end{equation*}
Si può verificare che \textit{x.left.max} $>$ \textit{x.right.max} perché si ordina rispetto a \textit{x.int.low}, cioè la posizione nell'albero è determinata solo dall'estremo inferiore non da quello superiore.
\item[Passo 3 : Gestione delle informazioni]Si deve verificare che le operazioni di inserimento e cancellazione possono essere svolte nel tempo $O(lg\,n)$ in un albero di intervalli di \textit{n} nodi. Se si conosce l'intervallo \textit{x.int}, quindi \textit{x.int.high}, e i valori \textit{max} dei figli \textit{x.left} e \textit{x.right} del nodo \textit{x}, è facile determinare \textit{x.max} come visto nel punto precedente. Per il teorema $(12.1)$, precedentemente dimostrato, le operazioni di inserimento e cancellazione vengono eseguite nel tempo $O(lg\,n)$. In realtà, l'aggiornamento degli attributi \textit{max} può essere eseguito nel tempo $O(1)$ per ogni rotazione.
\item[Passo 4 : Sviluppare le nuove operazioni]L'unica operazione da implementare è \textsc{Interval-Search(\textit{T,\,\textit{i}})} che trova un nodo nell'albero \textit{T} il cui intervallo si sovrappone all'intervallo \textit{i}. Se non c'è un intervallo che si sovrappone a \textit{i} nell'albero, viene restituito un puntatore alla sentinella \textit{T.\textsc{nil}}.\\\\
\textsc{Interval-Search(\textit{T,\,\textit{i}})}\\
1\firsttab\textit{x} $\leftarrow$ \textit{T.root}\\
2\firsttab\textbf{while} \textit{x} $\neq$ \textit{T.\textsc{nil}} e \textit{i} non si sovrappone a \textit{x.int}\\
3\secondtab\textbf{if} \textit{x.left} $\neq$ \textit{T.\textsc{nil}} e \textit{x.left.max} $\geq$ \textit{i.low}\\
4\thirdtab\textit{x} $\leftarrow$ \textit{x.left}\\
5\secondtab\textbf{else} \textit{x} $\leftarrow$ \textit{x.right}\\
6\firsttab\textbf{return} \textit{x}\\\\
La ricerca di un intervallo che si sovrappone a \textit{i} inizia con \textit{x} nella radice dell'albero e prosegue verso il basso. Termina quando viene trovato un intervallo che si sovrappone a \textit{i} o quando \textit{x} punta alla sentinella \textit{T.\textsc{nil}}. Poiché ogni iterazione del ciclo di base impiega il tempo $O(1)$ e poiché l'altezza di un albero rosso-nero di \textit{n} nodi è $O(lg\,n)$, la procedura \textsc{Interval-Search} impiega il tempo $O(lg\,n)$.
\end{description}
\subsection{Correttezza di Interval search}
Per spiegare perché \textsc{Interval-Search} è corretta, si parte dall'idea che sarà sufficiente controllare solo uno dei due figli del nodo.
\begin{theorem}
La procedura \textsc{Interval-Search(\textit{T,\,\textit{i}})} restituisce un nodo il cui intervallo si sovrappone a \textit{i} oppure restituisce \textit{T.\textsc{nil}} se l'albero \textit{T} non contiene alcun nodo il cui intervallo si sovrappone a \textit{i}.
In altri termini:
\begin{itemize}
\item Se la ricerca va a destra, allora:
\begin{itemize}
\item C'è una sovrapposizione nel sottoalbero destro
\item[]Oppure
\item Non c'è sovrapposizione in nessuno dei due sottoalberi
\end{itemize}
\item Se la ricerca va a sinistra, allora:
\begin{itemize}
\item C'è una sovrapposizione nel sottoalbero sinistro
\item[]Oppure
\item Non c'è sovrapposizione in nessuno dei due sottoalberi
\end{itemize}
\end{itemize}
Se non c'è sovrapposizione in uno dei due, allora non c'è in nessuno dei due.
\end{theorem}
\begin{proof}
Se viene eseguita la riga 5, allora per la condizione di diramazione nella riga 3, la ricerca va a destra e si ha \textit{x.left} = \textit{T.\textsc{nil}} oppure \textit{x.left.max} $<$ \textit{i.low}; ciò comporta che il sottoalbero con radice in \textit{x.left} non contiene un intervallo che si sovrappone a \textit{i}. Quindi, non si ha sovrapposizione a sinistra. Se c'è una sovrapposizione nel sottoalbero destro non ci sono problemi, altrimenti si deve mostrare che non c'è sovrapposizione a sinistra. Se si suppone \textit{x.left} $\neq$ \textit{T.\textsc{nil}} e \textit{x.left.max} $<$ \textit{i.low}, per ogni intervallo \textit{j} nel sottoalbero sinistra di \textit{x} si ha:
\begin{align*}
j.high &\leq x.left.max \\
&< i.low
\end{align*}
Per la tricotomia degli intervalli, \textit{i} e \textit{j} non si sovrappongono. Allora il sottoalbero sinistro di \textit{x} non contiene intervalli che si sovrappongono a \textit{i}.

Se, invece, viene eseguita la riga 4, allora per la condizione di diramazione nella riga 3, la ricerca va a sinistra e si ha $i.low \leq x.left.max = j.high$ per qualche \textit{j} nel sottoalbero sinistro. Inoltre, per la definizione dell'attributo \textit{max}, ci deve essere un intervallo \textit{j} nel sottoalbero sinistro di \textit{x} tale che
\begin{align*}
j.high &= x.left.max \\
&\geq i.low
\end{align*}
Poiché \textit{i} e \textit{j} non si sovrappongono e poiché non è vero che $j.high < i.low$, allora per la tricotomia degli intervalli si ha $i.high < j.low$. Gli alberi di intervalli usano come chiavi gli estremi inferiori degli intervalli, quindi la proprietà dell'albero di ricerca implica che, per qualsiasi intervallo \textit{k} nel sottoalbero destro di \textit{x} si ha:
\begin{equation*}
\underbrace{j.low}_{sinistra} \leq \underbrace{k.low}_{destra}
\end{equation*}
E dunque:
\begin{align*}
i.high &< j.low \\
&\leq k.low
\end{align*}
Per la tricotomia degli intervalli, \textit{i} e \textit{k} non si sovrappongono.\\Dunque, si è dimostrato che la procedura \textsc{Interval-Search} funziona correttamente.  
\end{proof}
\chapter{Programmazione dinamica}
La programmazione dinamica, come il metodo divide et impera, risolve i problemi combinando le soluzioni dei sottoproblemi (con il termine programmazione si fa riferimento all'uso di una tecnica tabulare). Gli algoritmi divide et impera suddividono un problema in sottoproblemi indipendenti, risolvono in modo ricorsivo i sottoproblemi e in seguito combinano le loro soluzioni per risolvere il problema originale. La programmazione dinamica, invece, può essere applicata quando i sottoproblemi non sono indipendenti, ovvero quando i sottoproblemi hanno in comune dei sottosottoproblemi. In questo contesto, un algoritmo divide et impera svolge molto più lavoro del necessario, risolvendo ripetutamente i sottoproblemi comuni. Un algoritmo di programmazione dinamica risolve ciascun sottoproblema una sola volta e salva la sua soluzione in una tabella, evitando così il lavoro di dover ricalcolare la soluzione ogni volta che si presenta lo stesso sottoproblema.

La programmazione dinamica si applica tipicamente ai \textbf{problemi di ottimizzazione}, quali problemi di massimizzazione o minimizzazione. Per questi problemi ci possono essere molte soluzioni possibili. Ogni soluzione ha un valore e si vuole trovare una soluzione con il valore ottimo. Si dice \textsl{una} soluzione ottima del problema e non \textsl{la} soluzione ottima, perché ci possono essere più soluzioni che raggiungono il valore ottimo.

Il processo di sviluppo di un algoritmo di programmazione dinamica può essere suddiviso in una sequenza di quattro fasi:
\begin{enumerate}
\item Caratterizzare la struttura di una soluzione ottima
\item Definire ricorsivamente il valore di una soluzione ottima del problema
\item Calcolare il valore di una soluzione ottima, di solito con uno schema bottom-up. Dal basso verso l'altro, ovvero, da sottoproblemi semplici a quelli più difficili, fino al problema originario.
\item Costruire una soluzione ottima dalle informazioni calcolate
\end{enumerate}
Le prime tre fasi formano la base per risolvere un problema applicando la programmazione dinamica. La fase 4 può essere omessa se è richiesto soltanto il valore di una soluzione ottima. Quando si deve eseguire tale fase, a volte si memorizzano delle informazioni aggiuntive durante il calcolo della fase 3 per semplificare la costruzione di una soluzione ottima. 
\section{Taglio delle aste}
Il \textbf{problema del taglio delle aste} è un esempio di programmazione dinamica. Data un'asta di lunghezza \textit{n} e una tabella dei prezzi $p_i$, per $i = 1,\,2,\,3,\,...\,,\,n$, si vuole determinare il ricavo massimo $r_n$ che si può ottenere tagliando l'asta e vendendone i pezzi. Si noti che, se il prezzo $p_n$ di un'asta di lunghezza \textit{n} è sufficientemente grande, la soluzione ottima potrebbe essere quella di non effettuare alcun taglio.
\begin{center}
\begin{tabular}{c | cccccccccc}
lunghezza \textit{i} &1 &2 &3 &4 &5 &6 &7 &8 &9 &10\\
\hline
prezzo $p_i$ &1 &5 &8 &9 &10 &17 &17 &20 &24 &30
\end{tabular}
\end{center}
Considerando il caso in cui la lunghezza dell'asta da tagliare è $n = 4$, si hanno otto possibili modi di taglio:
\begin{center}
\begin{tabular}{c | ccccccccc}
 &1 &2 &3 &4 &5 &6 &7 &8\\
\hline
modo di taglio &4 &1-3 &1-1-2 &1-1-1-1 &2-2 &1-2-1 &3-1 &2-1-1\\
ricavo &9 &9 &7 &4 &10 &7 &9 &7
\end{tabular}
\end{center}
Si nota che tagliare un'asta di lunghezza 4 in due pezzi di lunghezza 2 fornisce un ricavo di $p_2 + p_2 = 5 + 5 = 10$, che è la soluzione ottima.

Un'asta di lunghezza \textit{n} può essere tagliata in $2^{n-1}$ modi differenti, in quanto si ha un'opzione indipendente di tagliare, o non tagliare, alla distanza \textit{i} dall'estremità sinistra (ovvero si può scegliere se tagliare, o non tagliare al \textit{i}-esimo punto di taglio), per $i = 1,\,2,\,3,\,...\,,\,n - 1$. Si denota una decomposizione in pezzi utilizzando la normale notazione additiva, cosicché $7 = 2 + 3 + 3$ indica che un'asta di lunghezza 7 viene tagliata in tre pezzi - due di lunghezza 2 e uno di lunghezza 3. Se una soluzione ottima prevede il taglio dell'asta in \textit{k} pezzi, per $1 \leq k \leq n$, allora una decomposizione ottima
\begin{equation*}
n = i_1 + 1_2 + ... + i_k
\end{equation*}
dell'asta in pezzi di lunghezze $i_1,\,i_2,\,...\,,\,i_k$ fornisce il ricavo massimo corrispondente
\begin{equation*}
r_n = p_{i_1} + p_{i_2} + ... + p_{i_k}
\end{equation*}
Per il problema in esame, si può determinare per ispezione i ricavi ottimi $r_i$, per $i = 1,\,2,\,3,\,...\,,\,10$ e le corrispondenti decomposizioni ottime. Si avrà dunque che è il ricavo massimo $r_n$ è:
\begin{center}
$r_4 = 10$ dalla soluzione $4 = 2 + 2$ perché associato al taglio ottimo [2,2]
\end{center}
Più in generale, si possono esprimere i valori dei ricavi massimi $r_n$ per $r \geq 1$ in funzione dei ricavi ottimi $r_i$ (con $i < n$) delle aste più corte. Per ogni taglio \textit{i} si ha:
\begin{equation*}
r_n = r_i + r_{n-i}
\end{equation*}
Da cui
\begin{equation*}
r_n = max\,(p_n,\,r_1 + r_{n-1},\,r_2 + r_{n-2},\,...\,,\,r_{n-1} + r_1)
\end{equation*}
Il primo argomento $p_n$, corrisponde alla vendita dell'asta di lunghezza \textit{n} senza tagli. Gli altri $n - 1$ argomenti corrispondono al ricavo massimo ottenuto facendo un taglio iniziale dell'asta in due pezzi di dimensione \textit{i} e \textit{n - i}, per $i = 1,\,2,\,3,\,...\,,\,n - 1$, e poi tagliando in modo ottimale gli ulteriori pezzi, ottenendo i ricavi $r_i$ e $r_{n-i}$ da questi pezzi.

Poiché non si conosce a priori quale valore di \textit{i} ottimizza i ricavi, si devono considerare tutti i possibili valori di \textit{i} e selezionare quello che massimizza i ricavi. Si potrebbe anche non scegliere alcun valore di \textit{i}, se si può ottenere il massimo ricavo vendendo le aste senza tagliarle.

Per risolvere il problema originale di dimensione \textit{n}, si risolvono problemi più piccoli dello stesso tipo, ma di dimensioni inferiori. Una volta effettuato il primo taglio, si possono considerare i due pezzi come istanze indipendenti del problema del taglio delle aste. L'ottimo è la somma dei ricavi ottimi delle due semiaste.
\begin{theorem}
La soluzione ottima complessiva incorpora le soluzioni ottime dei due sottoproblemi correlati che massimizzano i ricavi di ciascuno dei due pezzi.
\end{theorem}
\begin{proof}
Si procede per assurdo: si suppone che $r_i$ (o $r_{n-i}$) non sia l'ottimo del sottoproblema, si sostituisce a $r_i$ la soluzione ottima $r'_i > r_i$ ottenendo $r'_n > r_n$ ma ciò comporta che $r_n$ non sarebbe un ottimo.
\end{proof}
Si dirà dunque, che il problema del taglio delle aste presenta una \textbf{sottostruttura ottima}: la soluzioni ottime di un problema incorporano le soluzioni ottime dei sottoproblemi correlati, che possono essere risolti in modo indipendente.

È possibile definire in modo più semplice una struttura ricorsiva per il problema del taglio delle aste, ovvero definire $r_n$ secondo una formulazione più semplice:  si considera la decomposizione formata da una primo pezzo di lunghezza \textit{i} tagliato dall'estremità sinistra e dal pezzo restante di destra di lunghezza $n - i$. Soltanto il pezzo restante di destra potrà essere ulteriormente tagliato.

È possibile vedere ciascuna decomposizione di un'asta di lunghezza \textit{n} in questo modo: un primo pezzo seguito da un'eventuale decomposizione del pezzo restante. Così facendo, si può esprimere la soluzione senza alcun taglio dicendo che il primo pezzo ha dimensione $i = n$ e ricavo $p_n$ e che al pezzo rimanente di dimensione $n - i$ è associato il taglio ottimo dell'asta rimanente $r_{n-i}$, per cui si ottiene:
\begin{equation*}
r_n = p_i + r_{n-i}
\end{equation*}
Nella formulazione precedente si richiamava ricorsivamente la funzione due volte calcolando $r_i$ e $r_{n-i}$, adesso sono una volta per trovare $r_{n-i}$. Vale anche nel caso in cui non si taglia l'asta:
\begin{equation*}
r_n = p_n + r_0
\end{equation*}
ovvero quando il pezzo restante ha dimensione 0, con ricavo $r_0 = 0$. Si ottiene quindi la versione semplificata della precedente equazione che definiva $r_n$:
\begin{equation*}
r_n = \max_{1 \leq i \leq n} (p_i + r_{n-i})
\end{equation*}
Secondo questa formulazione, una soluzione ottima incorpora la soluzione di un solo sottoproblema - il pezzo restante - anziché due come avveniva nella formulazione precedente.

Da questa nuova formulazione si ricava facilmente l'algoritmo ricorsivo top-down chiamato \textsc{Cut-Rod} che riceve in ingresso la tabella dei prezzi \textit{p} e la lunghezza dell'asta \textit{n}.\\\\
\textsc{Cut-Rod(\textit{p},\,\textit{n})}\\
1\firsttab\textbf{if} \textit{n} = 0\\
2\secondtab\textbf{return} 0\\
3\firsttab\textit{q} $\leftarrow -\infty$\\
4\firsttab\textbf{for} \textit{i} $\leftarrow$ 1 \textbf{to} \textit{n}\\
5\secondtab\textit{q} $\leftarrow$ max(\textit{q},\,\textit{p}[\textit{i}] + \textsc{Cut-Rod(\textit{p},\,\textit{n - i})})\\
6\firsttab\textbf{return} \textit{q}\\\\
Commenti:
\begin{enumerate}
\item[3]Sentinella per trovare il massimo
\item[5]Implementa la nuova formulazione $r_n = \max_{1 \leq i \leq n} (p_i + r_{n-i})$
\end{enumerate}
La procedura \textsc{Cut-Rod} riceve come input un array $p[1\,...\,n]$ di prezzi e un intero \textit{n}, e restituisce il massimo ricavo possibile per un'asta di lunghezza \textit{n}. Se $n = 0$, nessun ricavo è possibile; quindi \textsc{Cut-Rod} restituisce 0 nella riga 2. La riga 3 inizializza il ricavo massimo \textit{q} a $-\infty$, in modo che il ciclo \textbf{for}, righe 4 - 5, calcola correttamente $q = \max_{1 \leq i \leq n}$($p_i$ + \textsc{Cut-Rod(\textit{p},\,\textit{n - i})}); la riga 6 poi restituisce questo valore. Tale valore \textit{q} è uguale alla risposta desiderata $r_n$.

Ogni volta che si incrementa \textit{n} di 1, il tempo di esecuzione della procedura quasi raddoppia.

L'inefficienza di \textsc{Cut-Rod} è dovuta al fatto che chiama più e più volte sé stessa in modo ricorsivo con gli stessi valori dei parametri; risolve ripetutamente gli stessi problemi.

Per analizzare il tempo di esecuzione di \textsc{Cut-Rod}, si indica con $T(n)$ il numero totale di chiamate di \textsc{Cut-Rod} quando la chiamata viene effettuata con il secondo parametro uguale a \textit{n}. Questa espressione è uguale al numero di nodi in un sottoalbero la cui radice ha l'etichetta \textit{n} nell'albero di ricorsione. Il conteggio include la chiamata iniziale alla radice. Quindi, $T(0) = 1$ e
\begin{equation*}
T(n) = 1 + \sum_{j=0}^{n-1}T(j)
\end{equation*}
Il valore iniziale 1 riguarda la chiamata della radice, e il termine $T(j)$ conta il numero di chiamate (incluse le chiamate ricorsive) dovute alla chiamata di \textsc{Cut-Rod(\textit{p},\,\textit{n - i})}, dove $j = n - i$. Si può vedere che $T(n) = \Theta(2^n)$ e quindi il tempo di esecuzione di \textsc{Cut-Rod} è esponenziale a \textit{n}.

Questo tempo di esecuzione esponenziale è dovuto al fatto che la procedura \textsc{Cut-Rod} considera esplicitamente tutti i $2^{n-1}$ modi possibili di tagliare un'asta di lunghezza \textit{n}. L'albero delle chiamate ricorsive ha $2^{n-1}$ foglie, una per ogni modo possibile di tagliare l'asta. Le etichette nel cammino semplice dalla radice a una foglia forniscono le dimensioni di ciascun pezzo destro prima di effettuare un taglio; ovvero le etichette forniscono i corrispondenti punti di taglio, misurati dall'estremità destra dell'asta.
\subsection{Programmazione dinamica per il taglio delle aste}
Avendo visto che una semplice soluzione ricorsiva non è efficiente perché risolve ripetutamente gli stessi sottoproblemi, applicando la programmazione dinamica si farà in modo che ogni sottoproblema sia risolto una volta soltanto, salvando la sua soluzione. Se si avrà bisogno di nuovo della soluzione di questo sottoproblema, si potrà riaverla immediatamente, senza bisogno di ricalcolarla. La programmazione dinamica richiede una memoria aggiuntiva extra per ridurre il tempo di esecuzione; si tratta di un tipico esempio di \textbf{compromesso tempo-memoria}. Il risparmio di tempo ottenibile può essere notevole: una soluzione con tempo esponenziale può essere trasformata in una soluzione con tempo polinomiale. Un metodo di programmazione dinamica viene eseguito in tempo polinomiale quando il numero di sottoproblemi distinti richiesti è polinomiale nella dimensione dell'input e ciascun sottoproblema può essere risolto in un tempo polinomiale.

Ci sono due modi equivalenti per implementare la programmazione dinamica:
\begin{description}
\item[Metodo top-down con annotazione]In questo approccio, si scrive la procedura ricorsiva in modo naturale, modificandola per salvare il risultato di ciascun sottoproblema (di solito in un array o in una tabella). La procedura prima verifica se ha risolto precedentemente questo sottoproblema. In caso affermativo, restituisce il valore salvato, risparmiando gli ulteriori calcoli a quel livello; altrimenti la procedura calcola il valore nel modo usuale. Quindi, risolve il problema di dimensione \textit{n}, e ricorsivamente risolve i sottoproblemi più piccoli, ma prima di lanciare la ricorsione sul sottoproblema più piccolo, controlla nella tabella se non è già disponibile la soluzione.
\item[Metodo bottom-up]La risoluzione di un particolare sottoproblema dipende soltanto dalla risoluzione di sottoproblemi più piccoli. Si ordinano i problemi per dimensione e poi si risolvono ordinatamente a partire dal più piccolo. Quando si risolve un particolare sottoproblema, tutti i sottoproblemi più piccoli da cui dipende la sua soluzione sono già stati risolti, e le loro soluzioni sono state salvate. Ogni sottoproblema viene risolto una sola volta e, quando lo si incontra, sono già stati risolti tutti i suoi sottoproblemi.
\end{description}
Questi due approcci generano algoritmi con lo stesso tempo di esecuzione asintotico. L'approccio top-down a volte non esamina ricorsivamente tutti i possibili sottoproblemi. L'approccio bottom-up spesso ha fattori costanti molto migliori, in quanto ha meno costi per le chiamate di procedura.\\

La versione \textbf{top-down} di \textsc{Cut-Rod} si basa sull'annotazione (\textbf{memoization}) delle soluzioni dei sottoproblemi già risolti:\\\\
\textsc{Memoized-Cut-Rod(\textit{p},\,\textit{n})}\\
1\firsttab Sia \textit{r}[0\,...\,\textit{n}] un nuovo array\\
2\firsttab\textbf{for} \textit{i} $\leftarrow$ 0 \textbf{to} \textit{n}\\
3\secondtab\textit{r}[\textit{i}] $\leftarrow -\infty$\\
4\firsttab\textbf{return} \textsc{Memoized-Cut-Rod-Aux(\textit{p},\,\textit{n},\,\textit{r})}\\\\
La procedura principale \textsc{Memoized-Cut-Rod} inizializza un nuovo array ausiliario \textit{r}[0\,...\,\textit{n}] con il valore $-\infty$, una scelta comoda per indicare i valori incogniti (i valori dei ricavi noti sono sempre non negativi). Poi, alla riga 4, chiama la sua routine ausiliaria \textsc{Memoized-Cut-Rod-Aux}. Tale procedura ausiliaria non è altro che la versione dotata di tabella, nella quale memorizzare le soluzioni dei sottoproblemi, della precedente procedura \textsc{Cut-Rod}.\\\\
\textsc{Memoized-Cut-Rod-Aux(\textit{p},\,\textit{n},\,\textit{r})}\\
1\firsttab\textbf{if} \textit{r}[\textit{n}] $\geq$ 0\\
2\secondtab\textbf{return} \textit{r}[\textit{n}]\\
3\firsttab\textbf{if} \textit{n} = 0\\
4\secondtab\textit{q} $\leftarrow$ 0\\
5\firsttab\textbf{else} \textit{q} $\leftarrow -\infty$\\
6\secondtab\textbf{for} \textit{i} $\leftarrow$ 1 \textbf{to} \textit{n}\\
7\thirdtab\textit{q} $\leftarrow$ max(\textit{q},\,\textit{p}[\textit{i}] + \textsc{Memoized-Cut-Rod-Aux(\textit{p},\,\textit{n - i},\,\textit{r})})\\
8\firsttab\textit{r}[\textit{n}] $\leftarrow$ \textit{q}\\
9\firsttab\textbf{return} \textit{q}\\\\
Commenti:
\begin{enumerate}
\item[0]\textit{r} indica i ricavi massimi ottenuti fino ad un certo punto
\item[1-2]Se si sta considerando un sottoproblema di cui è già stata calcolata la soluzione, tale soluzione viene restituita direttamente nella riga 2
\end{enumerate}
La riga 1 controlla innanzitutto se il valore desiderato è già noto; in questo caso, la riga 2 restituisce tale valore. Altrimenti, le righe 3 - 7 calcolano il valore desiderato \textit{q} chiamando ricorsivamente \textsc{Memoized-Cut-Rod-Aux}, la riga 8 lo salva in \textit{r}[\textit{n}] e la riga 9 lo restituisce.\\

La versione \textbf{bottom-up} non è ricorsiva e per questo motivo non è più possibile ottenere l'albero di ricorsione che rappresenta il suo andamento. Ha il seguente pseudocodice:\\\\
\textsc{Bottom-Up-Cut-Rod(\textit{p},\,\textit{n})}\\
1\firsttab Sia \textit{r}[0\,...\,\textit{n}] un nuovo array\\
2\firsttab\textit{r}[0] $\leftarrow$ 0\\
3\firsttab\textbf{for} \textit{j} $\leftarrow$ 1 \textbf{to} \textit{n}\\
4\secondtab\textit{q} $\leftarrow - \infty$\\
5\secondtab\textbf{for} \textit{i} $\leftarrow$ 1 \textbf{to} \textit{j}\\
6\thirdtab\textit{q} $\leftarrow$ max(\textit{q},\,\textit{p}[\textit{i}] + \textit{r}[\textit{j - i}])\\
7\secondtab\textit{r}[\textit{j}] $\leftarrow$ \textit{q}\\
8\firsttab\textbf{return} \textit{r}[\textit{n}]\\\\
Commenti:
\begin{enumerate}
\item[6]\textit{p}[\textit{i}] e \textit{r}[\textit{j - i}] sono già stati calcolati precedentemente
\end{enumerate}
Per l'approccio bottom-up della programmazione dinamica, \textsc{Bottom-Up-Cut-Rod} segue l'ordine naturale dei sottoproblemi: un problema di dimensione \textit{i} è più piccolo di un sottoproblema di dimensione \textit{j}, se $i < j$. Quindi, la procedura risolve i sottoproblemi di dimensioni $j = 0,\,1,\,...\,,\,n$, in quest'ordine.

La riga 1 crea un nuovo array \textit{r}[0\,...\,\textit{n}] in cui salvare i risultati dei sottoproblemi; la riga 2 inizializza \textit{r}[0] a 0, in quanto un'asta di lunghezza 0 non genera alcun ricavo. Le righe 3 - 6 risolvono ciascun sottoproblema di dimensione \textit{j}, per $j = 1,\,...\,,\,n$, nell'ordine delle dimensioni crescenti. La riga 6 fa riferimento direttamente all'elemento \textit{r}[\textit{j - i}] dell'array, anziché fare una chiamata ricorsiva per risolvere il sottoproblema di dimensione $j - i$. La riga 7 salva in \textit{r}[\textit{j}] la soluzione del sottoproblema di dimensione \textit{j}. Infine, la riga 8 restituisce \textit{r}[\textit{n}] che è uguale al valore ottimo $r_n$.\\

Le versioni bottom-up e top-down hanno lo stesso tempo di esecuzione asintotico. Il tempo di esecuzione della procedura \textsc{Bottom-Up-Cut-Rod} è $\Theta(n^2)$, a causa della doppia struttura annidata del ciclo. Il numero di iterazioni del suo ciclo più interno \textbf{for}, nelle righe 5 - 6, forma una seria aritmetica. Anche il tempo di esecuzione della versione top-down, \textsc{Memoized-Cut-Rod}, è $\Theta(n^2)$. Poiché una chiamata ricorsiva per risolvere un sottoproblema precedentemente risolto termina immediatamente, \textsc{Momized-Cut-Rod} risolve ciascun sottoproblema una sola volta. La procedura risolve i sottoproblemi di dimensione $0,\,1,\,...\,,\,n$. Per risolvere un sottoproblema di dimensione \textit{n}, il ciclo \textbf{for}, righe 6 - 7, effettua \textit{n} iterazioni. Quindi, il numero totale di iterazioni di questo ciclo \textbf{for}, per tutte le chiamate ricorsive di \textsc{Memoized-Cut-Rod}, forma una serie aritmetica, per un totale di $\Theta(n^2)$ iterazioni, come il ciclo interno \textbf{for} di \textsc{Bottom-Up-Cut-Rod}.
\subsection{Ricostruire una soluzione}
La soluzione ottenuta con la programmazione dinamica del problema del taglio delle aste fornisce il valore di una soluzione ottima (massimo ricavo), non la soluzione effettiva (il modo di taglio per ottenere il massimo ricavo): una lista di dimensioni dei pezzi. È possibile estendere l'approccio della programmazione dinamica per memorizzare non soltanto il valore ottimo calcolato per ciascun sottoproblema, ma anche una scelta che determina il valore ottimo. Con questa informazione, si è in grado di stampare facilmente una soluzione ottima.

Si definisce una versione estesa di \textsc{Bottom-Up-Cut-Rod} che calcola, per ogni dimensione \textit{j} dell'asta, non soltanto il ricavo massimo $r_j$, ma anche $s_j$, la dimensione ottima del primo pezzo da tagliare.\\\\
\textsc{Extended-Bottom-Up-Cut-Rod(\textit{p},\,\textit{n})}\\
1\firsttab Siano $r[0\,...\,n]$ e $s[0\,...\,n]$ due nuovi array\\
2\firsttab\textit{r}[0] $\leftarrow$ 0\\
3\firsttab\textbf{for} \textit{j} $\leftarrow$ 1 \textbf{to} \textit{n}\\
4\secondtab\textit{q} $\leftarrow - \infty$\\
5\secondtab\textbf{for} \textit{i} $\leftarrow$ 1 \textbf{to} \textit{j}\\
6\thirdtab\textbf{if} \textit{q} $<$ \textit{p}[\textit{i}] + \textit{r}[\textit{j - i}]\\
7\fourthtab\textit{q} $\leftarrow$ \textit{p}[\textit{i}] + \textit{r}[\textit{j - i}]\\
8\fourthtab\textit{s}[\textit{j}] $\leftarrow$ \textit{i}\\
9\secondtab\textit{r}[\textit{j}] $\leftarrow$ \textit{q}\\
10\firsttab\textbf{return} (\textit{r},\,\textit{s})\\\\
Questa procedura è simile a \textsc{Bottom-Up-Cut-Rod}, con la differenza che crea l'array \textit{s} nella riga 1, e aggiorna \textit{s}[\textit{j}] nella riga 8 per conservare la dimensione ottima \textit{i} del primo pezzo da tagliare quando viene risolto un sottoproblema di dimensione \textit{j}.

La procedura \textsc{Print-Cut-Rod-Solution} riceve una tabella di prezzi \textit{p} e una dimensione \textit{n} dell'asta; poi chiama \textsc{Extended-Bottom-Up-Cut-Rod} per calcolare l'array $s[1\,...\,n]$ delle dimensioni ottime dei primi pezzi e stampa la lista completa delle dimensioni dei pezzi per una decomposizione ottima di un'asta di lunghezza \textit{n}.\\\\
\textsc{Print-Cut-Rod-Solution(\textit{p},\,\textit{n})}\\
1\firsttab(\textit{r},\,\textit{s}) $\leftarrow$ \textsc{Extended-Bottom-Up-Cut-Rod(\textit{p},\,\textit{n})}\\
2\firsttab\textbf{while} \textit{n} $>$ 0\\
3\secondtab print s[\textit{n}]\\
4\secondtab\textit{n} $\leftarrow$ \textit{n} - s[\textit{n}]\\\\
Commenti:
\begin{enumerate}
\item[4]Trova il massimo nel pezzo rimanente
\end{enumerate}
Riprendendo la tabella
\begin{center}
\begin{tabular}{c | cccccccccc}
lunghezza \textit{i} &1 &2 &3 &4 &5 &6 &7 &8 &9 &10\\
\hline
prezzo $p_i$ &1 &5 &8 &9 &10 &17 &17 &20 &24 &30
\end{tabular}
\end{center}
Un esempio di esecuzione dell'algoritmo \textsc{Extended-Bottom-Up-Cut-Rod} e  della procedura \textsc{Print-Cut-Rod} è il seguente:
\begin{center}
\begin{tabular}{c | ccccccccccc}
\textit{i} &0 &1 &2 &3 &4 &5 &6 &7 &8 &9 &10\\
$p_i$ &0 &1 &5 &8 &9 &10 &17 &17 &20 &24 &30\\
$r_i$ &0 &1 &5 &8 &10 &13 &17 &18 &22 &25 &30\\
$s_i$ &0 &1 &2 &3 &2 &2 &6 &1 &2 &3 &10
\end{tabular}
\end{center}
\section{Longest Common Subsequence}
Nel problema della \textbf{più lunga sottosequenza comune} sono date due sequenze $X = \langle x_1,\,...\,,\,x_m \rangle$ e $Y = \langle y_1,\,...\,,\,y_n\rangle$ e si vuole trovare una sottosequenza di lunghezza massima che è comune a \textit{X} e \textit{Y}. Non è detto che le sequenze siano delle stringhe.

Una sottosequenza di una data sequenza è la sequenza stessa alla quale sono stati tolti zero o più elementi. Formalmente, sia $X = \langle x_1,\,...\,,\,x_m \rangle$ una sequenza, un'altra sequenza $Z = \langle z_1,\,z_2,\,...\,,\,z_k\rangle$  è una \textbf{sottosequenza} di \textit{X} se esiste una sequenza strettamente crescente $I = \langle i_1,\,...\,,\,i_k\rangle$ di indici di \textit{X} tale che $i_j > i_h$ se $j > h$ per ogni $j,h = 1,\,2,\,...\,,\,k$ e $x_{i_{j}} = z_j$ per ogni $j = 1,\,2,\,...\,,\,k$. Per esempio, $Z = \langle B, C, D, B\rangle$ è una sottosequenza di $X = \langle A, B, C, B, D, A, B\rangle$ con la corrispondente sequenza di indici $I = \langle 2, 3, 5, 7\rangle$.

Date due sequenze \textit{X} e \textit{Y}, si dirà che una sequenza \textit{Z} è una \textbf{sottosequenza comune} di \textit{X} e \textit{Y} se \textit{Z} è una sottosequenza di entrambe le sequenze \textit{X} e \textit{Y}. Per esempio, se $X = \langle A, B, C, B, D, A, B\rangle$ e $Y = \langle B, D, C, A, B, A\rangle$, la sequenza $\langle B, C, A\rangle$ è una sottosequenza comune di \textit{X} e \textit{Y} e la sequenza $\langle B, C, B, A\rangle$ è una LCS di \textit{X} e \textit{Y}.

Un algoritmo a forza bruta per risolvere il problema della più lunga sottosequenza comune consiste nell'enumerare tutte le sottosequenze di \textit{X} e controllare le singole sottosequenze per vedere se sono anche sottosequenze di \textit{Y}, tenendo traccia della più lunga sottosequenza trovata. Ogni sottosequenza di \textit{X} corrisponde a un sottoinsieme degli indici $\{1,\,2,\,...\,,\,m\}$ di \textit{X}. Ci sono $2^m$ sottosequenze di \textit{X} da controllare, il tempo necessario per controllare ogni sottosequenza è $\Theta(m)$ quindi questo approccio richiede un tempo esponenziale $\Theta(n\cdot2^m)$, il che lo rende inutilizzabile per le sequenze lunghe.

Data una sequenza $X = \langle x_1,\,...\,,\,x_m \rangle$, si definisce $X_i = \langle x_1,\,...\,,\,x_i \rangle$ l'\textit{i}-esimo \textbf{prefisso} di \textit{X}, per $i = 0,\,1,\,...\,,\,m$. Per esempio, se $X = \langle A, B, C, D\rangle$ si ha $X_1 = \langle A\rangle$, $X_3 = \langle A, B, C\rangle$ mentre $X_0$ è la sequenza vuota.
\begin{theorem}
Siano $X = \langle x_1,\,...\,,\,x_m \rangle$ e $Y = \langle y_1,\,...\,,\,y_n\rangle$ due sequenze; sia $Z = \langle z_1,\,...\,,\,z_k\rangle$ una qualsiasi LCS di \textit{X} e \textit{Y}, allora:
\begin{enumerate}
\item Se $x_m = y_n$, allora $z_k = x_m = y_n$ e $Z_{k-1}$ è una LCS di $X_{m-1}$ e $Y_{n-1}$
\item Se $x_m \neq y_n$, allora $z_k \neq x_m$ implica che \textit{Z} è una LCS di  $X_{m-1}$ e \textit{Y}
\item Se $x_m \neq y_n$, allora $z_k \not= y_n$ implica che \textit{Z} é una LCS di \textit{X} e $Y_{n-1}$
\end{enumerate}
\end{theorem}
\begin{proof}
Si dimostrano i tre punti separatamente:
\begin{enumerate}
\item Se $x_m = y_n$, supponendo $z_k \neq x_m$, si costruisce una nuova sequenza $Z' = \langle z_1,\,z_2,\,...\,,\,z_k,\,x_m\rangle$ (ottenuta accodando $x_m = y_n$ a \textit{Z}) che risulta essere una sottosequenza comune di \textit{X} e \textit{Y} di lunghezza $k + 1$; ma \textit{Z'} è una sottosequenza comune più lunga di \textit{Z} quindi si contraddice l'ipotesi che \textit{Z} sia una LCS di \textit{X} e \textit{Y}. Quindi, deve essere $z_k = x_m = y_n$. Ora, il prefisso $Z_{k-1}$ è sicuramente una sottosequenza comune di $X_{m-1}$ e $Y_{n-1}$, di lunghezza $k - 1$. Si vuole dimostrare che questo prefisso è una LCS. Si suppone per assurdo che esista una sottosequenza comune \textit{W} di $X_{m-1}$ e $Y_{n-1}$ che sia più lunga di $Z_{k-1}$, cioè di lunghezza maggiore di $k - 1$. Allora, si costruisce una nuova sequenza $W'$ accodando $x_m = y_n$ a \textit{W}, e si ottiene una sottosequenza comune di \textit{X} e \textit{Y} la cui lunghezza è maggiore di \textit{k}; ma questo contraddice il fatto che \textit{Z} sia una LCS di \textit{X} e \textit{Y}. 
\item Se $z_k \neq x_m$ allora \textit{Z} è una sottosequenza comune di $X_{m-1}$ e \textit{Y}. Se esistesse una sottosequenza comune \textit{W} di $X_{m-1}$ e \textit{Y} di lunghezza maggiore di \textit{k}, allora \textit{W} sarebbe anche una sottosequenza comune di $X_m$ e \textit{Y}, contraddicendo l'ipotesi che \textit{Z} sia una LCS di \textit{X} e \textit{Y}.
\item La dimostrazione è simmetrica a quella del punto 2.
\end{enumerate}
\end{proof}
Questo teorema dimostra che una LCS di due sequenze contiene al suo interno (come prefisso) una LCS di prefissi delle due sequenze. Quindi, il problema della più lunga sottosequenza comune gode della proprietà della \textbf{sottostruttura ottima}.

Una soluzione ricorsiva gode anche della proprietà dei \textbf{sottoproblemi ripetuti}.

Il teorema implica che ci sono uno o due sottoproblemi da esaminare per trovare una LCS di \textit{X} e \textit{Y}.
\begin{itemize}
\item Se $x_m = y_n$ si deve risolvere un solo sottoproblema. Si trova una LCS di $X_{m-1}$ e $Y_{n-1}$. Una volta trovata, accodando $x_m = y_n$ a questa LCS, si ottiene una LCS di \textit{X} e \textit{Y}.
\item Se $x_m \neq y_n$ si devono risolvere due sottoproblemi. Si deve trovare una LCS di $X_{m-1}$ e \textit{Y} e una LCS di \textit{X} e $Y_{n-1}$. La più lunga di queste due LCS è una LCS di \textit{X} e \textit{Y}.
\end{itemize}
La soluzione ricorsiva del problema della più lunga sottosequenza comune richiede la definizione di una ricorrenza per il valore di una soluzione ottima. Si definisce \textit{c}[\textit{i},\,\textit{j}] come la lunghezza di una LCS delle sequenze $X_i$ e $Y_j$. Se $i = 0$ o $j = 0$, una delle sequenze ha lunghezza 0, quindi la LCS ha lunghezza 0. La sottostruttura ottima del problema della LCS consente di scrivere la formula ricorsiva
\begin{equation*}
c[i,\,j] = \left\{
\begin{array}{ll}
0 &\text{se } i = 0 \text{ o } j = 0\\
c[i - 1,\,j - 1] + 1 &\text{se } i,\,j > 0 \text{ e } x_i = y_j\\
\text{max}(c[i,\,j - 1],\,c[i - 1,\,j]) &\text{se } i,\,j > 0 \text{ e } x_i \neq y_j
\end{array}
\right.
\end{equation*}
Secondo questa formulazione ricorsiva, una condizione del problema riduce il numero di sottoproblemi che si possono considerare. Quando $x_i = y_j$, si deve considerare soltanto il sottoproblema di trovare la LCS di $X_{i-1}$ e $Y_{j-1}$. Altrimenti, quando $x_i \neq y_j$, si devono risolvere solo due sottoproblemi: trovare la LCS di $X_i$ e $Y_{j-1}$ e trovare la LCS di $X_{i-1}$ e $Y_j$. Per il teorema non è stata esclusa nessuna soluzione. 

Utilizzando la formula ricorsiva appena definita è possibile scrivere un algoritmo ricorsivo per calcolare la lunghezza di una LCS di due sequenze. La procedura \textsc{LCS-Length} riceve come input due sequenze \textit{X} e \textit{Y}, di dimensioni \textit{m} e \textit{n} rispettivamente, e memorizza i valori \textit{c}[\textit{i},\,\textit{j}] in una tabella \textit{c}[0\,...\,\textit{m},\,0\,...\,\textit{n}]. La tabella \textit{c}[\textit{i},\,\textit{j}] contiene la lunghezza ottima di LCS per $X_i$ e $Y_j$. Si usa anche la tabella \textit{b}[1\,...\,\textit{m},\,1\,...\,\textit{n}] per semplificare la costruzione di una soluzione ottima. L'elemento \textit{b}[\textit{i},\,\textit{j}] punta alla posizione della tabella che corrisponde alla soluzione ottima del sottoproblema che è stata scelta per calcolare \textit{c}[\textit{i},\,\textit{j}]; ovvero, \textit{b}[\textit{i},\,\textit{j}] indica la strada seguita per risolvere LCS di $X_i$ e $Y_j$.\\\\
\textsc{LCS-Length(\textit{X},\,\textit{Y})}\\
1\firsttab\textit{m} $\leftarrow$ \textit{X.length}\\
2\firsttab\textit{n} $\leftarrow$ \textit{Y.length}\\
3\firsttab Siano \textit{b}[1\,...\,\textit{m},\,1\,...\,\textit{n}] e \textit{c}[0\,...\,\textit{m},\,0\,...\,\textit{n}] due nuove tabelle\\
4\firsttab\textbf{for} \textit{i} $\leftarrow$ 1 \textbf{to} \textit{m}\\
5\secondtab\textit{c}[\textit{i},\,0] $\leftarrow$ 0\\
6\firsttab\textbf{for} \textit{j} $\leftarrow$ 0 \textbf{to} \textit{n}\\
7\secondtab\textit{c}[0,\,\textit{j}] $\leftarrow$ 0\\
8\firsttab\textbf{for} \textit{i} $\leftarrow$ 1 \textbf{to} \textit{m}\\
9\secondtab\textbf{for} \textit{j} $\leftarrow$ 1 \textbf{to} \textit{n}\\
10\thirdtab\textbf{if} $x_i = y_j$\\
11\fourthtab\textit{c}[\textit{i},\,\textit{j}] $\leftarrow$ \textit{c}[\textit{i} - 1,\,\textit{j} - 1] + 1\\
12\fourthtab\textit{b}[\textit{i},\,\textit{j}] $\leftarrow \,"\nwarrow"$\\
13\thirdtab\textbf{elseif} \textit{c}[$i - 1$,\,\textit{j}] $\geq$ \textit{c}[\textit{i},\,$j - 1$]\\
14\fourthtab\textit{c}[\textit{i},\,\textit{j}] $\leftarrow$ \textit{c}[\textit{i} - 1,\,\textit{j}]\\
15\fourthtab\textit{b}[\textit{i},\,\textit{j}] $\leftarrow \,"\uparrow"$\\
16\thirdtab\textbf{else} \textit{c}[\textit{i},\,\textit{j}] $\leftarrow$ \textit{c}[\textit{i},\,\textit{j} - 1]\\
17\fourthtab\textit{b}[\textit{i},\,\textit{j}] $\leftarrow \,"\leftarrow"$\\
18\firsttab\textbf{return} \textit{c} e \textit{b}\\\\
Commenti:
\begin{enumerate}
\item[12]Indica dove era il massimo precedente
\end{enumerate}
Il tempo di esecuzione di \textsc{LCS-Length} è $\Theta(m\cdot n)$, perché il calcolo di ogni posizione della tabella richiede un tempo $\Theta(1)$.

Partendo da \textit{b}[\textit{m},\,\textit{n}] e attraversando la tabella  \textit{b} seguendo le frecce, è possibile ottenere una LSC di \textit{X} e \textit{Y}. Ogni volta che si incontra una freccia "$\nwarrow$" in posizione \textit{b}[\textit{i},\,\textit{j}], significa che $x_i = y_j$ è un elemento della LCS. In questo modo gli elementi della LCS si incontrano in ordine inverso. La procedura ricorsiva \textsc{Print-LSC} stampa una LSC di \textit{X} e \textit{Y} nell'ordine corretto.\\\\
\textsc{Print-LSC(\textit{b},\,\textit{X},\,\textit{i},\,\textit{j})}\\
1\firsttab\textbf{if} \textit{i} = 0 or \textit{j} = 0\\
2\secondtab\textbf{return}\\
3\firsttab\textbf{if} \textit{b}[\textit{i},\,\textit{j}] = "$\nwarrow$"\\
4\secondtab\textsc{Print-LSC(\textit{b},\,\textit{X},\,\textit{i} - 1,\,\textit{j} - 1)}\\
5\secondtab print $x_i$\\
6\firsttab\textbf{elseif} \textit{b}[\textit{i},\,\textit{j}] = " $\uparrow$ "\\
7\secondtab\textsc{Print-LSC(\textit{b},\,\textit{X},\,\textit{i - 1},\,\textit{j})}\\
8\firsttab\textbf{else} \textsc{Print-LSC(\textit{b},\,\textit{X},\,\textit{i},\,\textit{j - 1})}\\\\
Commenti:
\begin{enumerate}
\item[3 e 6]Verificano la provenienza del massimo attuale
\end{enumerate}
La chiamata iniziale è \textsc{Print-LSC(\textit{b},\,\textit{X},\,\textit{X.length},\,\textit{Y.length})}, la procedura impiega un tempo $O(m + n)$, perché a ogni chiamata ricorsiva decrementa almeno uno dei valori \textit{i} e \textit{j}.
\subsubsection{Esempio}
\begin{tabular}{cp{-5cm}cp{-5cm}cp{-5cm}cp{-5cm}cp{-5cm}cp{-5cm}cp{-5cm}cp{-5cm}cp{-5cm}cp{-5cm}cp{-5cm}c}
&&&&\textbf{a}&&\textbf{m}&&\textbf{p}&&\textbf{u}&&\textbf{t}&&\textbf{a}&&\textbf{t}&&\textbf{i}&&\textbf{o}&&\textbf{n}\\
&&0&$\leftarrow$&0&$\leftarrow$&0&&0&&0&&0&&0&&0&&0&&0&&0\\
&&&&&&$\uparrow$\\
&\textbf{s} &0&&0&&0&&0&&0&&0&&0&&0&&0&&0&&0\\
&&&&&&&$\nwarrow$\\
&\textbf{p} &0&&0&&0&&\textbf{1}&$\leftarrow$&1&$\leftarrow$&1&&1&&1&&1&&1&&1\\
&&&&&&&&&&&&&$\nwarrow$\\
&\textbf{a} &0&&1&&1&&1&&1&&1&&\textbf{2}&&2&&2&&2&&2\\
&&&&&&&&&&&&&&$\uparrow$\\
&\textbf{n} &0&&1&&1&&1&&1&&1&&2&&2&&2&&2&&2\\
&&&&&&&&&&&&&&$\uparrow$\\
&\textbf{k} &0&&1&&1&&1&&1&&1&&2&$\leftarrow$&2&&2&&2&&2\\
&&&&&&&&&&&&&&&&&$\nwarrow$\\
&\textbf{i} &0&&1&&1&&1&&1&&1&&2&&2&&\textbf{3}&$\leftarrow$&3&&3\\
&&&&&&&&&&&&&&&&&&&&&$\nwarrow$\\
&\textbf{n} &0&&1&&1&&1&&1&&1&&2&&2&&3&&3&&\textbf{4}\\
&&&&&&&&&&&&&&&&&&&&&&$\uparrow$\\
&\textbf{g} &0&&1&&1&&1&&1&&1&&2&&2&&3&&3&&4\\
&&&&&&&&\textbf{p}&&&&&&\textbf{a}&&&&\textbf{i}&&&&\textbf{n}
\end{tabular}
\\\\La più lunga sottosequenza comune delle parole \textsl{amputation} e\textsl{ spanking} è \textsl{pain}. Il percorso che individua la LCS deve andare lungo la diagonale.
\subsection{Miglioramenti}
Nell'algoritmo della LCS si potrebbe eliminare completamente la tabella \textit{b}. \textit{c}[\textit{i},\,\textit{j}] dipende soltanto da altre tre posizioni della tabella \textit{c}: \textit{c}[\textit{i} - 1,\,\textit{j - 1}], \textit{c}[\textit{i - 1},\,\textit{j}] e \textit{c}[\textit{i},\,\textit{j - 1}]. Dato il valore di \textit{c}[\textit{i},\,\textit{j}], si può determinare nel tempo $O(1)$ quale di questi tre valori è stato utilizzato per calcolare \textit{c}[\textit{i},\,\textit{j}], senza ispezionare la tabella \textit{b}. Quindi, si può ricostruire una LCS nel tempo $O(m + n)$ utilizzando una procedura simile a \textsc{Print-LSC}. Sebbene queste metodo permetta di risparmiare uno spazio $\Theta(m\,n)$ in memoria, tuttavia lo spazio ausiliario richiesto per calcolare una LCS non diminuisce asintoticamente, perché occorre comunque uno spazio $\Theta(m\,n)$ per la tabella \textit{c}. È però possibile ridurre il fabbisogno asintotico di memoria per \textsc{LCS-Length}, perché questa procedura usa soltanto due righe alla volta della tabella \textit{c}: la riga da calcolare e la riga precedente (si potrebbe utilizzare uno spazio soltanto un pò più grande di quello richiesto da una riga di \textit{c} per calcolare la lunghezza di una LCS). Questo miglioramento funziona se occorre calcolare soltanto la lunghezza di una LCS; se si vuole ricostruire gli elementi di una LCS, la tabella più piccola non può contenere le informazioni necessarie per rifare il percorso inverso nel tempo $O(m + n)$.
\section{Edit distance}
Date le due stringhe \textit{X} e \textit{Y} di dimensioni \textit{m} e \textit{n}, l'obiettivo è quello di effettuare una serie di trasformazioni che cambiano \textit{X} in \textit{Y}. Ci sono sei operazioni elementari di trasformazione:
\begin{enumerate}
\item Copia
\item Sostituzione
\item Cancellazione
\item Inserimento
\item Scambio
\item Distruzione
\end{enumerate}

Date due sequenze \textit{X} e \textit{Y} e un insieme di costi delle operazioni di tarsformazione, la \textbf{distanza di editing} tra \textit{X} e \textit{Y} è il costo della sequenza di operazioni più economica che trasforma \textit{X} in \textit{Y}.

Ciascuna delle operazioni di trasformazione ha un costo associato. Il costo di un'operazione dipende dalla specifica applicazione ma si suppone che il costo di ciascuna operazione sia una costante nota. Si suppone inoltre che i singoli costi delle operazioni di copia e sostituzione siano minori dei costi combinati delle operazioni di cancellazione e inserimento. Il costo di una data sequenza di operazioni di trasformazione è la somma dei costi delle singole operazioni nella sequenza.

Come nel caso di LCS, date due sequenze $X = \langle x_1,\,...\,,\,x_m \rangle$ e $Y = \langle y_1,\,...\,,\,y_n \rangle$, si definiscono i prefissi $X_i = \langle x_1,\,...\,,\,x_i \rangle$ e $Y_j = \langle y_1,\,...\,,\,y_j \rangle$ con $0 \leq i \leq m$ e $0 \leq j \leq n$. L'obiettivo in ciascun sottoproblema sarà di trovare una sequenza minima di operazioni elementari che converta $X_i$ in $Y_j$. Si vuole quindi minimizzare il numero di operazioni che rappresenterà poi la distanza tra le due stringhe. Secondo l'idea generale \textit{c}[\textit{i},\,\textit{j}] è il costo di una soluzione ottima al problema $X_i \rightarrow Y_j$. Supponendo di conoscere l'ultima operazione usata per $X_i \rightarrow Y_j$ si può calcolare \textit{c}[\textit{i},\,\textit{j}] in funzione dei valori precedenti.

Se l'ultima operazione era una \textbf{copia}: doveva essere $x_i = y_j$. Resta dunque da risolvere il problema $X_{i-1}$ e $Y_{j-1}$. Per la proprietà di sottostruttura ottima, una soluzione ottima al problema $X_i \rightarrow Y_j$ deve includere una soluzione ottima a $X_{i-1} \rightarrow Y_{j-1}$. Quindi, supponendo che l'ultima operazione fosse una copia
\begin{equation*}
c[i,\,j] = c[i - 1,\,j - 1] + \text{costo(copia)}
\end{equation*}
Se era una \textbf{sostituzione}: doveva essere  $x_i \neq y_j$. Come nel caso della copia, per la proprietà di sottostruttura ottima, una soluzione ottima al problema $X_i \rightarrow Y_j$ deve includere una soluzione ottima a $X_{i-1} \rightarrow Y_{j-1}$. Supponendo che l'ultima operazione fosse una sostituzione
\begin{equation*}
c[i,\,j] = c[i - 1,\,j - 1] + \text{costo(sostituzione)}
\end{equation*}
Se era uno \textbf{scambio}: doveva essere $x_i = y_{j-1}$ e $x_{i-1} = y_j$, con $i,j \geq 2$. In questo caso, una soluzione ottima al problema $X_i \rightarrow Y_j$ deve includere una soluzione ottima a $X_{i-2} \rightarrow Y_{j-2}$. Supponendo che l'ultima operazione fosse uno scambio
\begin{equation*}
c[i,\,j] = c[i - 2,\,j - 2] + \text{costo(scambio)}
\end{equation*}
Se era una \textbf{cancellazione} non si hanno restrizioni su \textit{X} e \textit{Y}. La cancellazione comporta la rimozione di un carattere da $X_i$ lasciando $Y_j$ invariato. Una soluzione ottima al problema $X_i \rightarrow Y_j$ deve includere una soluzione ottima a $X_{i-1} \rightarrow Y_j$. Supponendo che l'ultima operazione fosse una cancellazione
\begin{equation*}
c[i,\,j] = c[i - 1,\,j] + \text{costo(cancellazione)}
\end{equation*}
Se era un \textbf{inserimento} non si hanno restrizioni su \textit{X} e \textit{Y}. L'inserimento comporta la rimozione di un carattere da $Y_j$ lasciando $X_i$ invariato. Una soluzione ottima al problema $X_i \rightarrow Y_j$ deve includere una soluzione ottima a $X_i \rightarrow Y_{j-1}$. Supponendo che l'ultima operazione fosse un in inserimento
\begin{equation*}
c[i,\,j] = c[i,\,j - 1] + \text{costo(inserimento)}
\end{equation*}
Per quanto riguarda i \textbf{casi base}, se $i = 0$ o $j = 0$, $X_0$ e $Y_0$ sono stringhe vuote. Si converte la stringa vuota in $Y_j$ con \textit{j} inserimenti
\begin{equation*}
c[0,\,j] = j \cdot \text{costo(inserimento)}
\end{equation*}
Si converte la stringa $X_i$ in $Y_0$ con \textit{i} cancellazioni
\begin{equation*}
c[i,\,0] = i \cdot \text{costo(cancellazione)}
\end{equation*}
Con $i = j = 0$ si ha $c[0,\,0] = 0$, non c'è costo per convertire la stringa vuota nella stringa vuota. Si arriva così a definire la formulazione ricorsiva per il calcolo della distanza di editing tra due sequenze \textit{X} e \textit{Y}. Applicando le formule precedenti si definirà \textit{c}[\textit{i},\,\textit{j}], per $i,j > 0$, come:
\begin{equation*}
c[i,\,j] = \left\{
\begin{array}{ll}
c[i - 1,\,j - 1] + \text{costo(copia)} &\text{se } x[i] = y[j]\\
c[i - 1,\,j - 1] + \text{costo(sostituzione)} &\text{se } x[i] \neq y[j]\\
c[i,\,j] = c[i - 2,\,j - 2] + \text{costo(scambio)} &\text{se } i,j \geq 2,\\
&x[i] = y[j-1]\\
&\text{e }x[i-1] = y[j]\\
c[i,\,j] = c[i - 1,\,j] + \text{costo(cancellazione)} &\text{sempre}\\
c[i,\,j] = c[i,\,j - 1] + \text{costo(inserimento)} &\text{sempre}
\end{array}
\right.
\end{equation*}
Ogni volta che trova il minimo popola la tabella. Alla fine, l'ultimo valore nella tabella è la distanza di editing delle due sequenze.

L'algoritmo bottom-up per il calcolo della distanza di editing riempie la tabella per righe (funzionerebbe anche per colonne), \textit{op}[\textit{i},\,\textit{j}] memorizza l'operazione usata. Esiste anche una versione top-bottom ma richiede \textsc{Memoization}. La procedura \textsc{Edit-Distance} riceve in ingresso le due sequenze \textit{X} e \textit{Y} di cui si vuole trovare la distanza di editing.\\\\
\textsc{Edit-Distance(\textit{x},\textit{y})}\\
1\firsttab\textit{m} $\leftarrow$ \textit{x.length}\\
2\firsttab\textit{n} $\leftarrow$ \textit{y.length}\\
3\firsttab Siano \textit{c}[0\,...\,\textit{m},\,0\,...\,\textit{n}] e \textit{op}[0\,...\,\textit{m},\,0\,...\,\textit{n}] due nuove tabelle\\
4\firsttab\textbf{for} \textit{i} $\leftarrow$ 0 \textbf{to} \textit{m}\\
5\secondtab\textit{c}[\textit{i},\,0] $\leftarrow$ \textit{i} $\cdot$ cost(delete)\\
6\secondtab\textit{op}[\textit{i},\,0] $\leftarrow$ \textsc{delete}\\
7\firsttab\textbf{for} \textit{j} $\leftarrow$ 0 \textbf{to} \textit{n}\\
8\secondtab\textit{c}[0,\,\textit{j}] $\leftarrow$ \textit{j} $\cdot$ cost(insert)\\
9\secondtab\textit{op}[0,\,\textit{j}] $\leftarrow$ \textsc{insert}\\
10\firsttab\textbf{for} \textit{i} $\leftarrow$ 0 \textbf{to} \textit{m}\\
11\secondtab\textbf{for} \textit{j} $\leftarrow$ 0 \textbf{to} \textit{n}\\
12\thirdtab\textit{c}[\textit{i},\,\textit{j}] $\leftarrow$ $\infty$\\
13\thirdtab\textbf{if} $x_i = y_j$\\
14\fourthtab\textit{c}[\textit{i},\,\textit{j}] $\leftarrow$ \textit{c}[\textit{i} - 1,\,\textit{j} - 1] + cost(copy)\\
15\fourthtab\textit{op}[\textit{i},\,\textit{j}] $\leftarrow$ \textsc{copy}\\
16\thirdtab\textbf{if} $x_i \neq y_j$ and \textit{c}[$i - 1$,\,$j - 1$] + cost(replace) $<$ \textit{c}[\textit{i},\,\textit{j}]\\
17\fourthtab\textit{c}[\textit{i},\,\textit{j}] $\leftarrow$ \textit{c}[\textit{i} - 1,\,\textit{j} - 1] + cost(raplace)\\
18\fourthtab\textit{op}[\textit{i},\,\textit{j}] $\leftarrow$ \textsc{replace($y_j$)}\\
19\thirdtab\textbf{if} $i,j \geq 2$ \,and \textit{c}[\textit{i} - 2,\,\textit{j} - 2] + cost(twiddle) $<$ \textit{c}[\textit{i},\,\textit{j}]\\
\fourthtab\thirdtab and $x_i = y_{j-1}$ and $x_{i-1} = y_j$\\
20\fourthtab\textit{c}[\textit{i},\,\textit{j}] $\leftarrow$ \textit{c}[\textit{i} - 2,\,\textit{j} - 2] + cost(twiddle)\\
21\fourthtab\textit{op}[\textit{i},\,\textit{j}] $\leftarrow$ \textsc{twiddle}\\
22\thirdtab\textbf{if} \textit{c}[$i - 1$,\,\textit{j}] + cost(delete) $<$ \textit{c}[\textit{i},\,\textit{j}]\\
23\fourthtab\textit{c}[\textit{i},\,\textit{j}] $\leftarrow$ \textit{c}[\textit{i} - 1,\,\textit{j}] + cost(delete)\\
24\fourthtab\textit{op}[\textit{i},\,\textit{j}] $\leftarrow$ \textsc{delete}\\
25\thirdtab\textbf{if} \textit{c}[\textit{i},\,$j - 1$] + cost(insert) $<$ \textit{c}[\textit{i},\,\textit{j}]\\
26\fourthtab\textit{c}[\textit{i},\,\textit{j}] $\leftarrow$ \textit{c}[\textit{i},\,\textit{j} - 1] + cost(insert)\\
27\fourthtab\textit{op}[\textit{i},\,\textit{j}] $\leftarrow$ \textsc{insert($y_j$)}\\
28\firsttab\textbf{return} \textit{c} e \textit{op}\\\\
La procedura viene eseguita nel tempo $\Theta(m\cdot n)$ e richiede uno spazio $\Theta(m\,n)$. Per risparmiare spazio, basterebbe la riga $i - 1$ e nel caso dello scambio anche la riga $i - 2$; quindi si potrebbe sovrascrivere queste due righe e mettere come colonne la stringa più corta.
\subsection{Ricostruire una soluzione}
Per poter ricostruire la sequenza ottima di operazioni da eseguire per poter trasformare la sequenza \textit{X} nella sequenza \textit{Y} si usa la tabella \textit{op} restituita dalla procedura \textsc{Edit-Distance}. La procedura \textsc{Op-Sequence} è un algoritmo ricorsivo che nella prima chiamata riceve in ingresso la tabella \textit{op} e le lunghezze \textit{m} ed \textit{n} delle due sequenze \textit{X} e \textit{Y}. Nelle chiamate successive riceverà gli indici \textit{i} e \textit{j} per scorrere la matrice \textit{op}.\\\\
\textsc{Op-Sequence(\textit{op},\,\textit{i},\,\textit{j})}\\
1\firsttab\textbf{if} \textit{i} = 0 and \textit{j} = 0\\
2\secondtab\textbf{return}\\
3\firsttab\textbf{if} \textit{op}[\textit{i},\,\textit{j}] = \textsc{copy} or \textit{op}[\textit{i},\,\textit{j}] = \textsc{replace}\\
4\secondtab\textit{i'} $\leftarrow$ \textit{i} - 1\\
5\secondtab\textit{j'} $\leftarrow$ \textit{j} - 1\\
6\firsttab\textbf{elseif} \textit{op}[\textit{i},\,\textit{j}] = \textsc{twiddle}\\
7\secondtab\textit{i'} $\leftarrow$ \textit{i} - 2\\
8\secondtab\textit{j'} $\leftarrow$ \textit{j} - 2\\
9\firsttab\textbf{elseif} \textit{op}[\textit{i},\,\textit{j}] = \textsc{delete}\\
10\secondtab\textit{i'} $\leftarrow$ \textit{i} - 1\\
11\secondtab\textit{j'} $\leftarrow$ \textit{j}\\
12\firsttab\textbf{else} // Deve essere \textit{op}[\textit{i},\,\textit{j}] = \textsc{insert}\\
13\secondtab\textit{i'} $\leftarrow$ \textit{i}\\
14\secondtab\textit{j'} $\leftarrow$ \textit{j} - 1\\
15\firsttab\textsc{Op-Sequence(\textit{op},\,\textit{i'},\,\textit{j'})}\\
16\firsttab\textsc{Print} \textit{op}[\textit{i},\,\textit{j}]
\subsection{Utilizzi di edit distance}
L'edit distance viene principalmente utilizzato per:
\begin{description}
\item[Correzione ortografica] Usata sia per correggere documenti con parole scritte in modo errato, sia per suggerire query all'utente. Vengono utilizzati due approcci principali:
\begin{description}
\item[Parole isolate]Si controlla ogni parola indipendentemente dalle altre ma non si trovano errori di parole scambiate
\item[Context-sensitive]Si guarda il contesto della frase
\end{description}
\item[Correzione di documenti]Necessario per documenti letti con OCR. In questo caso si considerano errori specifici usando una conoscenza specifica del dominio (OCR può confondere O e D). Anche i documenti elettronici e pagine Web presentano errori dovuti, per esempio, all'adiacenza delle lettere nella tastiera QWERTY (per esempio si confondono O e I). Spesso non si modifica il documento ma si ottimizza il match query-documenti memorizzati 
\item[Correzione di parole isolate]In questo caso si ipotizza che esista un lessico con lo spelling corretto di tutte le parole. Due possibili approcci:
\begin{description}
\item[Usare lessico Standard]Quindi Websters English Dictionary o un lessico specifico per documenti in domini specifici
\item[Usare parole della collezione]Quindi utilizzare tutte le parole nel Web, tutti i nomi, acronimi ecc ma includendo anche gli errori
\end{description}
\end{description}
Dato un lessico \textit{L} e la stringa \textit{Q}, si vogliono trovare le parole in \textit{L} più vicine a \textit{Q}; si deve però dare una definizione di \textsl{più vicino}. Le alternative, oltre alla edit distance già vista, sono la Weighted edit distance e l' intersezione di n-gram.

La \textbf{Weighted edit distance} è una distanza di editing dove il costo di una operazione dipende dai caratteri coinvolti e non solo dal tipo di operazione (tiene conto dell'errore). Viene usata per gestire errori di OCR o di battitura in quanto il costo è proporzionale alla distanza sulla tastiera. Per poterla utilizzare serve una matrice di pesi \textit{W} che dipende dall'applicazione. La procedura \textsc{Weighted-Eddit-Distance} è uguale a \textsc{Edit-Distance} con la differenza che se $x_i \neq y_j$ si dovrà leggere la tabella \textit{W} e considerare il peso.

Confrontare \textit{Q} con tutte le parole in \textit{L} è troppo costoso, una possibilità è di elencare tutte le sequenze di caratteri da \textit{Q} con edit distance inferiore ad una certa soglia, intersecare questo insieme con \textit{L} e mostrare infine i risultati.

Un modo per ridurre l'insieme dei termini candidati nel dizionario è quello di utilizzare l'intersezione di n-gram. Con l'\textbf{intersezione di n-gram} si enumerano tutti gli n-gram (n caratteri consecutivi) in \textit{Q} e in \textit{L}. Si usa un indice di n-gram per trovare tutti i termini in \textit{L} che contengono qualunque n-gram di \textit{Q} oppure si cercano tutti i termini che contengono abbastanza n-gram di \textit{Q}. Una sequenza di lunghezza ha \textit{l} ha $l - n + 1$ n-gram.

Per poter avere una misura di sovrapposizione normalizzata si utilizza il \textbf{coefficiente di Jaccard} definito come:
\begin{equation*}
JC = \frac{|X \cap Y|}{|X \cup Y|}
\end{equation*}
Dove \textit{X} e \textit{Y} sono due insiemi che non devono avere la stessa dimensione. Il coefficiente di Jaccard è definito nell'intervallo $0 \leq JC \leq 1$; vale 1 se \textit{X} e \textit{Y} hanno gli stessi elementi e 0 se sono disgiunti. Nel caso in esame \textit{X} e \textit{Y} sono insiemi di n-gram. Per trovare i termini si considera una soglia, se JC è maggiore di tale soglia si calcola l'edit distance.
\chapter{Algoritmi golosi}
Gli algoritmi per i problemi di ottimizzazione eseguono una sequenza di passi, con una serie di scelte a ogni passo. Per molti problemi di ottimizzazione è uno spreco applicare le tecniche della programmazione dinamica per effettuare le scelte migliori: è preferibile utilizzare algoritmi più semplici ed efficienti. Un \textbf{algoritmo goloso} (greedy) fa sempre la scelta che sembra ottima in un determinato momento, ovvero fa una scelta localmente ottima, nella speranza che tale scelta porterà a una soluzione globalmente ottima. Tuttavia, gli algoritmi golosi non sempre riescono a trovare le soluzioni ottime. Esempi di applicazione degli algoritmi golosi sono:
\begin{itemize}
\item \textbf{Problema della selezione di attività} Si suppone di avere un insieme di \textit{n} attività $S = \{a_1,\,a_2,\,...\,,\,a_n\}$ che devono utilizzare la stessa risorsa che può essere utilizzata per svolgere una sola attività alla volta. Ogni attività $a_i$ ha un tempo di inizio $s_i$ e di fine $f_i$, con $0 \leq s_i < f_i < \infty$. Quando viene selezionata, l'attività $a_i$ si svolge durante l'intervallo semiaperto $[s_i,f_i)$. Le attività $a_i$ e $a_j$ sono compatibili se gli intervalli $[s_i,f_i)$ e $[s_j,f_j)$ non si sovrappongono, ovvero se $s_i \geq f_j$ o $s_j \geq f_i$. Il problema della selezione di attività consiste nel selezionare il sottoinsieme che contiene il maggior numero di attività mutualmente compatibili.
\item \textbf{I codici di Huffman} Tecnica molto efficiente per comprimere i dati ottenendo risparmi dal 20\% al 90\% a seconda delle caratteristiche dei dati da comprimere. I dati vengono considerati come una sequenza di caratteri. L'algoritmo goloso di Huffman usa una tabella che contiene quante volte compare ciascun carattere (la sua frequenza) per realizzare un metodo ottimo per rappresentare ciascun carattere con una stringa binaria.
\item \textbf{Problema di programmazione dei lavori} In particolare si considerano lavori di durata unitaria, ovvero lavori che richiedono una sola unità di tempo per essere completati. Dato un insieme finito \textit{S} di lavori di durata unitaria, un piano di programmazione per l'insieme \textit{S} è una permutazione di \textit{S} che specifica l'ordine in cui questi lavori devono essere eseguiti. Il problema della programmazione dei lavori di durata unitaria con scadenza e penalità per un singolo processore ha tre input: un insieme $S = \{a_1,\,a_2,\,...\,,\,a_n\}$ di \textit{n} lavori di durata unitaria, un insieme di \textit{n} interi che rappresentano le scadenze $d_1,\,d_2,\,...\,,\,d_n$ per cui la generica scadenza $d_i$ è tale che $1 \leq d_i \leq n$ (si suppone inoltre che il generico lavoro $a_i$ termini al tempo $d_i$) e un insieme di \textit{n} pesi non negativi o penalità $w_1,\,w_2,\,...\,,\,w_n$; si paga la penalità $w_i$ se il lavoro $a_i$ non termina entro il tempo $d_i$, mentre non c'è alcuna penalità se un lavoro termina entro la sua scadenza. Il problema è trovare un piano di programmazione per \textit{S} che minimizza le penalità totali da pagare per le scadenze non rispettate.
\item \textbf{Algoritmo di Dijkstra}
\item \textbf{Algoritmi per gli alberi di connessione minimi}
\end{itemize}
Un algoritmo goloso produce una soluzione ottima di una problema effettuando una sequenza di scelte. Ad ogni punto di decisione l'algoritmo fa la scelta che in quel momento sembra la migliore. Questa strategia non sempre produce una soluzione ottima ma a volte ci riesce. Gli algoritmi golosi vengono progettati secondo una sequenza di tre passi
\begin{enumerate}
\item Esprimere il problema di ottimizzazione in una forma in cui, fatta una scelta, resta un solo sottoproblema da risolvere
\item Dimostrare che esiste sempre una soluzione ottima del problema originale che fa la scelta golosa, quindi la scelta golosa è sempre sicura
\item Dimostrare la sottostruttura ottima verificando che, dopo aver fatto la scelta golosa, ciò che resta è un sottoproblema con la proprietà che, se si combina una soluzione ottima del sottoproblema con la scelta golosa che è stata fatta, si arriva ad una soluzione ottima del problema originale
\end{enumerate}
Sotto ogni algoritmo goloso c'è quasi sempre una soluzione più onerosa di programmazione dinamica.

Non c'è un modo generale per dire se un algoritmo goloso risolverà un particolare problema di ottimizzazione ma la proprietà della scelta golosa e la sottostruttura ottima sono i due punti chiave. Se si dimostra che un problema soddisfa queste proprietà, allora ci si trova sulla buona strada per sviluppare un algoritmo goloso per questo problema.
\section{La proprietà della scelta golosa}
Uno dei punti chiave nello sviluppo degli algoritmi golosi è la \textbf{proprietà della scelta golosa}: una soluzione globalmente ottima può essere ottenuta facendo una scelta localmente ottima. In altre parole, quando si valuta la scelta da fare, si fa la scelta che sembra migliore per il problema corrente, senza considerare le soluzioni di sottoproblemi. È qui che gli algoritmi golosi differiscono dalla programmazione dinamica. Nella programmazione dinamica, si fa una scelta a ogni passo, ma di solito la scelta dipende dalla soluzioni dei sottoproblemi. Di conseguenza, tipicamente si risolvono i problemi di programmazione dinamica secondo uno schema bottom-up, elaborando prima i sottoproblemi più piccoli per arrivare a quelli più grandi. In un algoritmo goloso, si fa la scelta che sembra migliore in un determinato momento e poi si risolve il sottoproblema che deriva da tale scelta. La scelta fatta da un algoritmo goloso può dipendere dalle precedenti scelte, ma non può dipendere dalle scelte future o dalle soluzioni dei sottoproblemi. Quindi, diversamente dalla programmazione dinamica, che risolve i sottoproblemi prima di fare la prima scelta, un algoritmo goloso fa la sua prima scelta prima di risolvere qualsiasi sottoproblema. Un algoritmo di programmazione dinamica procede dal basso verso l'alto, mentre una strategia golosa di solito precede dall'alto verso il basso, facendo una scelta golosa dopo l'altra e riducendo ogni istanza del problema a una più piccola. Di solito la scelta golosa si effettua in modo più efficiente che se si dovesse prendere in considerazione un numero maggiore di scelte. Spesso, grazie a un'elaborazione preliminare dell'input o all'impiego di una struttura dati appropriata (spesso una coda di priorità), si riesce a fare rapidamente delle scelte golose, ottenendo così un algoritmo efficiente.
\section{Sottostruttura ottima}
Il secondo punto chiave nello sviluppo degli algoritmi golosi è la \textbf{sottostruttura ottima}. Un problema ha una sottostruttura ottima se una soluzione ottima del problema contiene al suo interno soluzioni ottime dei sottoproblemi.

Nel confronto tra programmazione dinamica e algoritmi golosi si verifica che, di solito, si utilizza un approccio più diretto alla sottostruttura ottima quando la si applica agli algoritmi golosi. Come detto, si arriva a un sottoproblema facendo la scelta golosa nel problema originale. Tutto ciò che si deve fare è dedurre che una soluzione ottima del sottoproblema, combinata con la scelta golosa già fatta, genera una soluzione ottima del problema originale. Questo schema applica implicitamente l'induzione ai sottoproblemi per dimostrare che, facendo la scelta golosa a ogni passo, si ottiene una soluzione ottima.
\chapter{Analisi ammortizzata}
Nell'\textbf{analisi ammortizzata} il tempo richiesto per eseguire una sequenza di operazioni su una struttura dati viene calcolato come media dei tempi di tutte le operazioni eseguite. L'analisi ammortizzata può essere utilizzata per dimostrare che il costo medio di un'operazione è piccolo, se si considera la media di una sequenza di operazioni, anche se una singola operazione all'interno della sequenza può essere costosa. L'analisi ammortizzata differisce dall'analisi del caso medio perché non applica la teoria della probabilità; l'analisi ammortizzata valuta le prestazioni medie di ciascuna operazione nel caso peggiore. I tre metodi più utilizzati nell'analisi ammortizzata sono
\begin{itemize}
\item \textbf{Metodo dell'aggregazione}
\item \textbf{Metodo degli accantonamenti}
\item \textbf{Metodo del potenziale}
\end{itemize}
I costi assegnati durante l'analisi ammortizzata servono esclusivamente all'analisi, nel senso che non devono apparire nel codice. Se, per esempio, viene assegnato un credito a un oggetto \textit{x} quando viene utilizzato il metodo degli accantonamenti, non occorre assegnare un valore corrispondente a qualche attributo \textit{x.credito} nel codice.

Le informazioni su una particolare struttura dati che si ottengono dall'analisi ammortizzata possono servire a ottimizzare il progetto degli algoritmi.
\section{Metodo dell'aggregazione}
L'analisi basata sul \textbf{metodo dell'aggregazione} dimostra che, per ogni \textit{n}, una sequenza di \textit{n} operazioni impiega nel caso peggiore un tempo totale $T(n)$. Nel caso peggiore, il costo medio o \textbf{costo ammortizzato} per ogni operazione è quindi $T(n)/n$. Questo costo ammortizzato si applica a ciascuna operazione, anche quando ci sono più tipi di operazioni nella sequenza. Gli altri due metodi potrebbero attribuire costi ammortizzati differenti ai diversi tipi di operazioni.\\

Come esempio si analizza lo stack che include una nuova operazione. Le due operazioni fondamentali sullo stack sono \textsc{Push(\textit{S},\,\textit{x})}, che inserisce l'oggetto \textit{x} nello stack \textit{S}, e \textsc{Pop(\textit{S})} che elimina l'oggetto in cima allo stack \textit{S} e restituisce l'oggetto eliminato (se si chiama \textsc{Pop} su uno stack vuoto, si genera un errore). Poiché ciascuna di queste operazioni impiega un tempo $O(1)$, si assume che il costo di ciascuna di esse sia 1. Quindi, il costo totale di una sequenza di \textit{n} operazioni di \textsc{Push} e \textsc{Pop} è \textit{n}, e il tempo di esecuzione effettivo di \textit{n} operazioni è $\Theta(n)$.

Si aggiunge la nuova operazione \textsc{Multipop(\textit{S},\,\textit{k})} che elimina i primi \textit{k} oggetti dalla cima dello stack \textit{S} o svuota l'intero stack se questo contiene meno di \textit{k} oggetti. Si assume che \textit{k} sia positivo; altrimenti l'operazione \textsc{Multipop} lascia lo stack invariato. Nello pseudocodice di \textsc{Multipop}, l'operazione \textsc{Stack-Empty} restituisce \textsc{true} se non ci sono oggetti nello stack, altrimenti restituisce \textsc{false}.\\\\
\textsc{Multipop(\textit{S},\,\textit{k})}\\
1\firsttab\textbf{while} not \textsc{Stack-Empty(\textit{S})} and $k > 0$\\
2\secondtab\textsc{Pop(\textit{S})}\\
3\secondtab\textit{k} $\leftarrow$ \textit{k} - 1\\\\
Il tempo di esecuzione effettivo è lineare nel numero di operazioni \textsc{Pop} effettivamente eseguite; quindi è sufficiente analizzare \textsc{Multipop} in funzione del costo astratto 1 per \textsc{Push} e per \textsc{Pop}. Il numero di iterazioni del ciclo \textbf{while} è il numero min(\textit{s},\,\textit{k}) di oggetti eliminati dallo stack. Per ogni iterazione del ciclo viene effettuata una chiamata \textsc{Pop} nella riga 2. Quindi, il costo totale di \textsc{Multipop} è min(\textit{s},\,\textit{k}) e il tempo di esecuzione effettivo è una funzione lineare di questo costo.

Si analizza ora una sequenza di \textit{n} operazioni \textsc{Push}, \textsc{Pop} e \textsc{Multipop} su uno stack inizialmente vuoto. Il costo nel caso peggiore di un'operazione \textsc{Multipop} nella sequenza è $O(n)$, in quanto la dimensione dello stack è al massimo \textit{n}. Il tempo nel caso peggiore di qualsiasi operazione sullo stack è quindi $O(n)$; pertanto una sequenza di \textit{n} operazioni costa $O(n^2)$, perché si potrebbero avere $O(n)$ operazioni \textsc{Multipop} che costano $O(n)$ ciascuna. Sebbene questa analisi sia corretta, il risultato $O(n^2)$, che è stato ottenuto considerando il costo nel caso peggiore di ogni operazione, non è stretto.

Applicando il metodo dell'aggregazione si può ottenere un limite superiore più stretto che considera l'intera sequenza di \textit{n} operazioni. Sebbene una singola operazione \textsc{Multipop} possa essere costosa, qualsiasi sequenza di \textit{n} operazioni \textsc{Push}, \textsc{Pop} e \textsc{Multipop} su uno stack inizialmente vuoto può costare al più $O(n)$. Questo perché ogni oggetto può essere eliminato al massimo una volta  per ogni volta che viene inserito. Di conseguenza, il numero di volte che l'operazione \textsc{Pop} può essere chiamata su uno stack non vuoto, incluse le chiamate all'interno di \textsc{Multipop}, è al massimo il numero di operazioni \textsc{Push}, che è al più \textit{n}. Per ogni \textit{n}, qualsiasi sequenza di \textit{n} operazioni \textsc{Push}, \textsc{Pop} e \textsc{Multipop} impiega complessivamente un tempo $O(n)$. Il costo medio di un'operazione è $O(n)/n = O(1)$. Nel metodo dell'aggregazione si attribuisce il costo medio quale costo ammortizzato di ogni operazione. In questo esempio, quindi, tutte e tre le operazioni sullo stack hanno un costo armonizzato pari a $O(1)$.
\section{Metodo degli accantonamenti}
Nel \textbf{metodo degli accantonamenti} dell'analisi ammortizzata vengono assegnati costi variabili a operazioni differenti; qualche operazione potrebbe essere associata a un costo maggiore o minore del suo costo effettivo. Il costo che viene imputato a un'operazione è detto \textbf{costo ammortizzato}. Quando il costo ammortizzato di un'operazione supera il costo effettivo, la differenza viene assegnata a specifici oggetti nella struttura dati sotto forma di \textbf{credito}. Il credito potrà essere successivamente utilizzato  per contribuire a pagare le operazioni il cui costo ammortizzato è minore del costo effettivo. Quindi, il costo ammortizzato di un'operazione può essere visto come se fosse suddiviso fra il costo effettivo  e il credito, che può essere depositato o prelevato.

Indicato con $c_i$ il costo effettivo della \textit{i}-esima operazione e con $\widehat{c_i}$ il costo ammortizzato della \textit{i}-esima operazione, deve essere
\begin{equation*}
\sum_{i=1}^{n}\widehat{c_i} \geq \sum_{i=1}^{n}c_i
\end{equation*}
per ogni sequenza di \textit{n} operazioni. Il credito totale memorizzato nella struttura dati è la differenza fra il costo ammortizzato totale e il costo effettivo totale, ovvero
\begin{equation*}
\text{credito totale = } \sum_{i=1}^{n}\widehat{c_i} - \sum_{i=1}^{n}c_i
\end{equation*}
Per la precedente disequazione, il credito totale associato alla struttura dati deve essere sempre non negativo. Se il credito totale potesse diventare negativo, allora i costi ammortizzati totali sostenuti fino a quel momento sarebbero inferiori ai costi effettivi totali; per la sequenza delle operazioni eseguite fino a quel momento, il costo ammortizzato totale non potrebbe essere un limite superiore per il costo effettivo totale. Quindi, si deve controllare che il credito totale nella struttura dati non diventi mai negativo.\\

Si riprende l'esempio dello stack ricordando che i costi effettivi delle operazioni erano\\\\
\begin{tabular}{ll}
\textsc{Push} &1\\
\textsc{Pop} &1\\
\textsc{Multipop} &min(\textit{s},\,\textit{k})
\end{tabular}
\\\\dove \textit{k} è l'argomento passato a \textsc{Multipop} e \textit{s} è la dimensione dello stack quando viene chiamata l'operazione \textsc{Multipop}. Si assegnano i seguenti costi ammortizzati\\\\
\begin{tabular}{ll}
\textsc{Push} &2\\
\textsc{Pop} &0\\
\textsc{Multipop} &0
\end{tabular}
\\\\Si dimostra che qualsiasi sequenza di operazioni su stack può essere pagata utilizzando i costi ammortizzati. Si suppone di utilizzare un conto in dollari \$ per rappresentare ciascuna unità di costo. Si parte da uno stack vuoto. Si considera l'analogia fra uno stack e un pila di piatti di una tavola calda. Quando si aggiunge un piatto alla pila (operazione \textsc{Push}), si spende un dollaro per pagare il costo effettivo di questa operazione e resta un credito di un dollaro (dei due dollari del costo ammortizzato), che viene lasciato sul piatto. In qualsiasi momento, ogni piatto della pila ha un dollaro di credito su di esso.

Il dollaro lasciato sul piatto è il credito prepagato per il costo richiesto per toglierlo dalla pila (operazione \textsc{Pop}). Quando si esegue un'operazione \textsc{Pop}, non si imputa un costo ammortizzato all'operazione e si paga il suo costo effettivo utilizzando il credito rimasto nella pila. Per togliere un piatto dalla pila, si prende il dollaro di credito che è sul piatto e lo si utilizza per pagare il costo effettivo dell'operazione. Quindi, assegnando un costo ammortizzato un po' alto all'operazione \textsc{Push}, non c'è bisogno di attribuire un costo ammortizzato all'operazione \textsc{Pop}.

Non occorre attribuire un costo ammortizzato neanche all'operazione \textsc{Multipop}. Per togliere il primo piatto, si prende il dollaro di credito sul piatto e lo si utilizza per pagare il costo effettivo di un'operazione \textsc{pop}. Per togliere il secondo piatto, si ha di nuovo a disposizione un dollaro di credito sul piatto per pagare l'operazione \textsc{Pop} e così via. Quindi, si ha sempre un credito sufficiente per pagare le operazioni \textsc{Multipop}.

In altre parole, poiché ogni piatto nella pila ha un dollaro di credito su di esso e la pila ha sempre un numero non negativo di piatti, si ha la garanzia che l'ammontare del credito sarà sempre non negativo. Quindi, per qualsiasi sequenza di \textit{n} operazioni \textsc{Push}, \textsc{Pop} e \textsc{Multipop}, il costo ammortizzato totale è un limite superiore per il costo effettivo totale. Poiché il costo ammortizzato totale è $O(n)$, anche il costo effettivo totale sarà $O(n)$.
\section{Metodo del potenziale}
Anziché rappresentare il lavoro pagato come credito memorizzato con specifici oggetti nella struttura dati, il \textbf{metodo del potenziale} dell'analisi armonizzata rappresenta il lavoro prepagato come energia potenziale (o semplicemente potenziale) che può essere liberata per pagare operazioni future. Il potenziale è associato alla struttura dati nel suo insieme, anziché a specifici oggetti all'interno della struttura dati.

Il metodo del potenziale parte da una struttura dati iniziale $D_0$ sulla quale vengono eseguite \textit{n} operazioni. Per ogni $i = 1,\,2,\,...\,,\,n$, si indica con $c_i$ il costo effettivo della \textit{i}-esima operazione e con $D_i$ la struttura dati che si ottiene dopo aver applicato la \textit{i}-esima operazione alla struttura dati $D_{i-1}$. Una \textbf{funzione potenziale $\Phi$} associa ciascuna struttura dati $D_i$ a un numero reale $\Phi(D_i)$, che è il \textbf{potenziale} della struttura dati $D_i$. Il \textbf{costo ammortizzato} $\widehat{c_i}$ della \textit{i}-esima operazione rispetto alla funzione potenziale $\Phi$ è definito dall'equazione
\begin{equation*}
\widehat{c_i} = c_i + \Phi(D_i) - \Phi(D_{i-1})
\end{equation*}
Il costo ammortizzato di ciascuna operazione è quindi il suo costo effettivo più l'incremento di potenziale dovuto all'operazione. Per l'equazione che definisce $\widehat{c_i}$, il costo ammortizzato totale delle \textit{n} operazioni è
\begin{align*}
\sum_{i=1}^{n}\widehat{c_i} &= \sum_{i=1}^{n}(c_i + \Phi(D_i) - \Phi(D_{i-1}))\\
&= \sum_{i=1}^{n}c_i + \Phi(D_n) - \Phi(D_0)
\end{align*}
Se si definisce una funzione potenziale $\Phi$ tale che $\Phi(D_n) \geq \Phi(D_0)$, allora il costo ammortizzato totale $\sum_{i=1}^{n}\widehat{c_i}$ è un limite superiore per il costo effettivo totale $\sum_{i=1}^{n}c_i$. In pratica, non sempre si sa quante operazioni potrebbero essere eseguite. Quindi, se si impone che $\Phi(D_i) \geq \Phi(D_0)$ per ogni \textit{i}, allora si ha la garanzia, come nel metodo degli accantonamenti, che si paga in anticipo. Spesso è comodo porre $\Phi(D_0) = 0$ e poi dimostrare che $\Phi(D_i) \geq 0$ per ogni \textit{i}.

Intuitivamente, se la differenza di potenziale $\Phi(D_i) - \Phi(D_{i-1})$ della \textit{i}-esima operazione è positiva, allora il costo ammortizzato $\widehat{c_i}$ rappresenta un valore sovrastimato per la \textit{i}-esima operazione, e il potenziale della struttura dati aumenta. Se la differenza di potenziale è negativa, allora il costo ammortizzato rappresenta un valore sottostimato per la \textit{i}-esima operazione, e il costo effettivo dell'operazione è pagato dalla riduzione del potenziale. I costi ammortizzati definiti dalle due equazioni precedenti dipendono dalla scelta della funzione potenziale $\Phi$. Differenti funzioni potenziale possono produrre costi ammortizzati differenti, che sono comunque limiti superiori per i costi effettivi. Spesso la scelta della funzione potenziale è il risultato di qualche compromesso; la funzione potenziale migliore da utilizzare dipende dai limiti di tempo desiderati.\\

Per applicare il metodo del potenziale si riprende l'esempio dello stack con le operazioni \textsc{Push}, \textsc{Pop} e \textsc{Multipop}. Si definisce la funzione potenziale $\Phi$ per uno stack come il numero di oggetti nello stack. Per uno stack vuoto $D_0$, dal quale si inizia, si ha $\Phi(D_0) = 0$. Poiché il numero di oggetti nello stack non è mai negativo, lo stack $D_i$ che si ottiene dopo la \textit{i}-esima operazione ha un potenziale non negativo e quindi
\begin{align*}
\Phi(D_i) &\geq 0\\
&= \Phi(D_0)
\end{align*}
Il costo ammortizzato totale di \textit{n} operazioni rispetto a $\Phi$, quindi, rappresenta un limite superiore per il costo effettivo.

Si calcolano adesso i costi ammortizzati delle varie operazioni sullo stack. Se la \textit{i}-esima operazione su uno stack che contiene \textit{s} oggetti è un'operazione \textsc{Push}, allora la differenza di potenziale è
\begin{align*}
\Phi(D_i) - \Phi(D_{i-1}) &= (s + 1) - s\\
&= 1
\end{align*}
Per la precedente equazione che definisce $\widehat{c_i}$, il costo ammortizzato di questa operazione \textsc{Push} è
\begin{align*}
\widehat{c_i} &= c_i + \Phi(D_i) - \Phi(D_{i-1})\\
&= 1 + 1\\
&= 2
\end{align*}
Supponendo che l'\textit{i}-esima operazione sullo stack sia \textsc{Multipop(\textit{S},\,\textit{k})} e che $k' = min(k,\,s)$ oggetti vengano eliminati dallo stack, il costo effettivo dell'operazione è $k'$ e la differenza di potenziale è
\begin{equation*}
\Phi(D_i) - \Phi(D_{i-1}) = -k'
\end{equation*}
Quindi, il costo ammortizzato dell'operazione \textsc{Multipop} è
\begin{align*}
\widehat{c_i} &= c_i + \Phi(D_i) - \Phi(D_{i-1})\\
&= k' - k'\\
&= 0
\end{align*}
Analogamente, il costo ammortizzato di un'ordinaria operazione \textsc{Pop} è 0.

Il costo ammortizzato di ciascuna delle tre operazioni è $O(1)$, quindi il costo ammortizzato totale di una sequenza di \textit{n} operazioni è $O(n)$. Avendo già dimostrato che $\Phi(D_i) \geq \Phi(D_0)$, il costo totale ammortizzato di \textit{n} operazioni è un limite superiore per il costo totale effettivo. Il costo nel caso peggiore di \textit{n} operazioni è quindi $O(n)$.
\section{Tavole dinamiche}
In alcune applicazioni non si sa in anticipo quanti oggetti saranno memorizzati in una tavola. Se dopo aver allocato dello spazio in memoria per la tavola, tale spazio non fosse più sufficiente, si dovrebbe allocare nuovamente la tavola con una dimensione maggiore e tutti gli oggetti memorizzati nella tavola originale dovrebbero essere copiati nella nuova tavola più grande. Analogamente, se sono stati cancellati molti elementi dalla tavola, potrebbe essere conveniente riallocare la tavola con una dimensione più piccola. Applicando l'analisi ammortizzata si dimostra che il costo ammortizzato per eseguire un inserimento o una cancellazione in una tavola dinamica è soltanto $O(1)$, anche se il costo effettivo di un'operazione è grande quando viene eseguita un'espansione o una contrazione della tavola. Inoltre, è importante garantire che lo spazio inutilizzato in una tavola dinamica non superi mai una frazione costante dello spazio totale.

Si suppone che la tavola dinamica supporti le operazioni \textsc{Table-Insert} e \textsc{Table-Delete}. \textsc{Table-Insert} inserisce nella tavola un elemento che occupa una singola \textbf{cella}, ovvero uno spazio per un elemento. Analogamente, \textsc{Table-Delete} può essere vista come l'eliminazione di un elemento dalla tavola, con conseguente liberazione della corrispondente cella. Nell'analisi ammortizzata è utile considerare il \textbf{fattore di carico} $\alpha(T)$ di una tavola non vuota \textit{T} che definisce il numero di elementi memorizzati nella tavola diviso per la dimensione della tavola. Per definizione, una tavola vuota ha dimensione 0 e il suo fattore di carico è 1. Se il fattore di carico di una tavola dinamica è limitato inferiormente da una costante, lo spazio inutilizzato nella tavola non supera mai una frazione costante della quantità totale di spazio.
\subsection{Espansione di una tavola}
Una tavola si riempie quando tutte le celle sono state utilizzate ovvero quando il suo fattore di carico è 1. Se un elemento viene inserito in una tavola piena, si può \textbf{espandere} la tavola allocando una nuova tavola che ha più celle della vecchia tavola. Poiché si vuole che la tavola risieda in spazi di memoria contigui, si deve allocare un nuovo array per la tavola più grande e poi copiare gli elementi della vecchia tavola in quella nuova.

Un tipico metodo consiste nell'allocare una nuova tavola che ha il doppio di celle della vecchia tavola. Se si effettuano soltanto inserimenti, il fattore di carico di una tavola è sempre almeno 1/2 e quindi, la quantità di spazio sprecato non supera mai la metà dello spazio totale nella tavola.

Nello pseudocodice di \textsc{Table-Insert} si suppone che \textit{T} sia un oggetto che rappresenta la tavola. L'attributo \textit{T.table} contiene un puntatore al blocco di memoria che rappresenta la tavola. L'attributo \textit{T.num} contiene il numero di elementi della tavola; l'attributo \textit{T.size} è il numero totale di celle nella tavola. Inizialmente, la tavola è vuota: \textit{T.num} = \textit{T.size} = 0. Ci sono due procedure di inserimento: la stessa procedura \textsc{Table-Insert} e l'\textbf{inserimento elementare} in una tavola nelle righe 6 e 10.\\\\
\textsc{Table-Insert(\textit{T},\,\textit{x})}\\
1\firsttab\textbf{if} \textit{T.size} = 0\\
2\secondtab alloca \textit{T.table} con una cella\\
3\secondtab\textit{T.size} $\leftarrow$ 1\\
4\firsttab\textbf{if} \textit{T.num} = \textit{T.size}\\
5\secondtab alloca \textit{new-table} con $2 \cdot T.size$ celle\\
6\secondtab inserisce tutti gli elementi di \textit{T.table} in \textit{new-table}\\
7\secondtab rilascia \textit{T.table}\\
8\secondtab\textit{T.table} $\leftarrow$ \textit{new-table}\\
9\secondtab\textit{T.size} $\leftarrow$ $2 \cdot T.size$\\
10\firsttab inserisce \textit{x} in \textit{T.table}\\
11\firsttab\textit{T.num} = \textit{T.num} + 1\\\\
È possibile analizzare il tempo di esecuzione di \textsc{Table-Insert} in base al numero di inserimenti elementari, assegnando un costo 1 a ogni inserimento elementare. Si suppone che il tempo di esecuzione effettivo di \textsc{Table-Insert} sia lineare nel tempo per inserire i singoli elementi e che quindi il costo aggiuntivo per allocare una tavola iniziale nella riga 2 sia costante e il costo aggiuntivo per allocare e rilasciare lo spazio nelle righe 5 e 7 sia dominato dal costo di trasferimento degli elementi nella riga 6. Si chiama \textbf{espansione} l'evento che si verifica quando viene eseguita la clausola \textbf{then} nelle righe 5 - 9.

Si determina ora il costo $c_i$ della \textit{i}-esima operazione in una sequenza di \textit{n} operazioni \textsc{Table-Insert} su una tavola inizialmente vuota. Se c'è spazio nella tavola corrente, allora $c_i = 1$, perché si deve eseguire l'unico inserimento elementare nella riga 10. Se invece la tavola corrente è piena e si verifica un'espansione, allora $c_i = i$: il costo è 1 per l'inserimento elementare nella riga 10 più $i - 1$ per gli elementi che devono essere copiati dalla vecchia tavola in quella nuova (riga 6). Se vengono eseguite \textit{n} operazioni, il costo nel caso peggiore di un'operazione è $O(n)$, che determina un limite superiore pari a $O(n^2)$ per il tempo di esecuzione totale di \textit{n} operazioni. Questo limite non è stretto, perché la tavola viene espansa raramente durante l'esecuzione di \textit{n} operazioni \textsc{Table-Insert}. Più precisamente, la \textit{i}-esima operazione provoca un'espansione soltanto se $i - 1$ è una potenza esatta di 2. Infatti, il costo ammortizzato di un'operazione è $O(1)$, come è possibile dimostrare applicando il metodo dell'aggregazione. Il costo della \textit{i}-esima operazione è
\begin{equation*}
c_i = \left\{
\begin{array}{ll}
i &\text{se } i - 1 \text{ è una potenza esatta di 2}\\
1 &\text{negli altri casi}
\end{array}\right.
\end{equation*}
Il costo totale di \textit{n} operazioni \textsc{Table-Insert} è quindi
\begin{align*}
\sum_{i=1}^{n}c_i &\leq n + \sum_{j=0}^{\lfloor lg\,n\rfloor}2^j\\
&< n + 2n\\
&= 3n
\end{align*}
perché ci sono al massimo \textit{n} operazioni che costano 1 e i costi delle restanti operazioni formano una serie geometrica. Poiché il costo totale di \textit{n} operazioni \textsc{Table-Insert} è 3n, il costo ammortizzato di una singola operazione è 3.

Intuitivamente, applicando il metodo degli accantonamenti, ogni elemento paga per tre inserimenti elementari: inserire sé stesso nella tavola corrente, spostare sé stesso quando la tavola viene espansa e spostare un altro elemento, che è già stato spostato una volta, quando la tavola viene espansa. Supponendo che la  dimensione della tavola sia \textit{m} immediatamente dopo un'espansione. Allora, il numero di elementi nella tavola è $m/2$ e la tavola non contiene alcun credito. Si addebita un costo di 3 dollari per ogni inserimento. L'inserimento elementare che viene effettuato subito costa 1 dollaro. Un altro dollaro viene posto come credito sull'elemento inserito. Il terzo dollaro è posto come credito su uno degli $m/2$ elementi già presenti nella tavola. Il riempimento della tavola richiede altri $m/2 - 1$ inserimenti; pertanto, quando la tavola contiene \textit{m} elementi ed è piena, ogni elemento ha un dollaro per pagare il suo reinserimento durante l'espansione.

Anche il metodo del potenziale può essere utilizzato per analizzare una sequenza di \textit{n} operazioni \textsc{Table-Insert} e anche in tal caso si ottiene un costo $c_i$ pari a 3; inoltre verrà anche utilizzato per progettare un'operazione \textsc{Table-Delete} anch'essa con un costo ammortizzato $O(1)$.
\subsection{Contrazione di una tavola}
Per implementare un'operazione \textsc{Table-Delete}, è sufficiente eliminare l'elemento specificato dalla tavola. Tuttavia, spesso è preferibile \textbf{contrarre} la tavola quando il fattore di carico della tavola diventa troppo piccolo, in modo che lo spazio sprecato non sia eccessivo. La contrazione della tavola è simile all'espansione: quando il numero di elementi nella tavola diventa troppo piccolo, si alloca una nuova tavola più piccola e poi si copiano gli elementi della vecchia tavola in quella nuova. Lo spazio in memoria per la vecchia tavola può essere poi rilasciato restituendolo al sistema di gestione della memoria. L'ideale sarebbe che fossero preservate due proprietà:
\begin{itemize}
\item Il fattore di carico della tavola dinamica è limitato inferiormente da una costante
\item Il costo ammortizzato di un'operazione sulla tavola è limitato superiormente da una costante
\end{itemize}
Si suppone che il costo possa essere misurato in base al numero di inserimenti e cancellazioni elementari. Si potrebbe ritenere che si debba raddoppiare la dimensione della tavola quando un elemento viene inserito in una tavola piena e dimezzare la dimensione quando una cancellazione fa sì che la tavola sia piena per meno della metà. Questa strategia assicura che il fattore di carico della tavola non sia mai maggiore di 1/2, tuttavia può comportare un aumento eccessivo del costo ammortizzato di un'operazione.

Il difetto di questa strategia è dovuto al fatto che dopo un'espansione, non si eseguono un numero sufficiente di cancellazioni per pagare una contrazione. Analogamente, dopo una contrazione, non si eseguono un numero sufficiente di inserimenti per pagare un'espansione.

È possibile migliorare questa strategia consentendo al fattore di carico della tavola di scendere sotto 1/2. Specificatamente, si continua a raddoppiare la dimensione della tavola quando un elemento viene inserito in una tavola piena, ma si dimezza la dimensione della tavola quando una cancellazione porta la tavola a essere piena per meno di 1/4, anziché per meno di 1/2. Il fattore di carico della tavola è quindi limitato inferiormente dalla costante 1/4.

Si considera come ideale il fattore di carico 1/2, nel qual caso il potenziale della tavola sarà 0. Quando il fattore di carico si discosta da 1/2, il potenziale aumenta in modo che, quando la tavola si espande o contrae, essa ha acquisito un potenziale sufficiente per pagare la copia di tutti gli elementi nella tavola appena allocata. Quindi, occorre una funzione potenziale che cresca fino a \textit{T.num} (numero di elementi nella tavola) quando il fattore di carico aumenta fino a 1 o diminuisce fino a 1/4. Dopo un'espansione o una contrazione della tabella, il fattore di carico ritorna a 1/2 e il potenziale della tabella ritorna a 0.

Il codice della procedura \textsc{Table-Delete} è simile a quello di \textsc{Table-Insert} e anch'essa ha un costo ammortizzato $O(1)$. Per l'analisi è utile supporre che, se il numero di elementi nella tavola scende a 0, lo spazio in memoria della tavola venga rilasciato; ovvero, se \textit{T.num} = 0, allora \textit{T.size} = 0.

Per l'analisi del costo di una sequenza di \textit{n} operazioni \textsc{Table-Insert} e \textsc{Table-Delete} si utilizza il metodo del potenziale e la funzione potenziale
\begin{equation*}
\Phi(T) = \left\{
\begin{array}{ll}
2 \cdot T.num - T. size &\text{se } \alpha(T) \geq 1/2\\
T.size/2 - T.num &\text{se } \alpha(T) < 1/2
\end{array}\right.
\end{equation*}
Il potenziale di una tavola vuota è 0 e il potenziale non è mai negativo. Quindi, il costo ammortizzato totale di una sequenza di operazioni rispetto a $\Phi$ è un limite superiore per il costo effettivo della sequenza.

Applicando il metodo del potenziale si arriva ad ottenere un costo ammortizzato $\widehat{c_i}$ pari a 0 o 3 per \textsc{Table-Insert} e pari a 1 o 2 per \textsc{Table-Delete}. Quindi, anche il costo ammortizzato è limitato superiormente da una costante (le due proprietà sono quindi preservate).

In sintesi, poiché il costo ammortizzato di ciascuna operazione è limitato superiormente da una costante, il tempo effettivo per qualsiasi sequenza di \textit{n} operazioni su una tavola dinamica è $O(n)$.
\chapter{Algoritmi elementari per grafi}
Un \textbf{grafo orientato} (diretto) è una coppia ordinata $G = (V,E)$ di insiemi, dove \textit{V} è un insieme finito ed \textit{E} è una relazione binaria in \textit{V}. L'insieme \textit{V} è detto \textbf{insieme dei vertici} di \textit{G} e i suoi elementi sono detti vertici. L'insieme \textit{E} è detto \textbf{insieme degli archi} di \textit{G} e i suoi elementi sono detti archi. I vertici sono rappresentati da cerchi; gli archi sono rappresentati da frecce. La cardinalità dell'insieme \textit{E} può essere al minimo 0 (nessun arco) e al massimo $V^2$. Un arco del grafo \textit{G} è un qualsiasi insieme $\{u,v\}$ tale che $u,v \in V$ e $u \neq v$. Pur essendo un insieme, per convenzione l'arco viene indicato con $(u,v)$. Se $(u,v)$ è un arco in un grafo orientato $G = (V,E)$, si dirà che $(u,v)$ esce dal vertice \textit{u} ed entra nel vertice \textit{v}. In un grafo orientato, il grado uscente di un vertice è il numero di archi che escono nel vertice; il grado entrante di un vertice è il numero di archi che entrano nel vertice. Il grado di un vertice in un grafo orientato è la somma del suo grado entrante e del suo grado uscente; rappresenta il numero di archi che incidono nel vertice. Un vertice il cui grado è 0 si dice isolato.

In un \textbf{grafo non orientato} (indiretto) $G = (V,E)$, l'insieme degli archi \textit{E} è composto da coppie di vertici non ordinate, anziché da coppie ordinate. Se $(u,v)$ è un arco in un grafo non orientato $G = (V,E)$, si dirà che $(u,v)$ è incidente nei vertici \textit{u} e \textit{v}.

Se $(u,v)$ è un arco di un grafo $G = (V,E)$, si dirà che il vertice \textit{v} è adiacente al vertice \textit{u}. Se il grafo non è orientato, la relazione di adiacenza è simmetrica. Se il grafo è orientato, la relazione di adiacenza non è necessariamente simmetrica.

Un \textbf{cammino} di lunghezza k da un vertice \textit{u} a un vertice $u'$ in un grafo $G = (V,E)$ è una sequenza $\langle v_0,\,v_1,\,v_2,\,...\,,\,v_k\rangle$ di vertici tali che $u = v_0$, $u' = v_k$ e $(v_{i-1},v_i) \in E$ per $i = 1,\,2,\,...\,,\,k$. La lunghezza del cammino è il numero di archi nel cammino.

In un grafo orientato, un cammino $\langle v_0,\,v_1,\,v_2,\,...\,,\,v_k\rangle$ forma un \textbf{ciclo} se $v_0 = v_k$ e il cammino contiene almeno un arco. Un grafo senza ciclo è \textbf{aciclico} (per esempio gli alberi).

Un grafo orientato è \textbf{connesso} se ogni coppia di vertici è collegata attraverso un cammino. Le \textbf{componenti connesse} di un grafo sono le classi di equivalenza dei vertici secondo la relazione "è raggiungibile da". Un grafo non orientato è connesso se ha esattamente una componente connessa, ovvero se ogni vertice è raggiungibile da ogni altro vertice.

Un grafo orientato è \textbf{fortemente connesso} se due vertici qualsiasi sono raggiungibili l'uno dall'altro. Le \textbf{componenti fortemente connesse} di un grafo orientato sono le classi di equivalenza dei vertici seconda la relazione "sono mutuamente raggiungibili". Un grafo orientato è fortemente connesso se ha una sola componente fortemente connessa.
\section{Rappresentazione dei grafi}
I due modi principali per rappresentare un grafo $G = (V,E)$ sono:
\begin{enumerate}
\item Liste di adiacenza
\item Matrice di adiacenza
\end{enumerate}
Entrambi possono essere applicati sia a grafi orientati che a quelli non orientati. Di solito si preferisce la rappresentazione con liste di adiacenza perché permette di rappresentare in modo compatto i grafi \textbf{sparsi}, ovvero quei grafi in cui $|E|$ è molto più piccolo di $|V|^2$.  Tuttavia, potrebbe essere preferibile una rappresentazione con matrice di adiacenza, quando il grafo è \textbf{denso}, ovvero quando $|E|$ è prossimo a $|V|^2$, o quando si deve essere in grado di dire rapidamente se c'è un arco che collega due vertici particolari.

Il tempo di esecuzione richiesto dalle varie operazioni e lo spazio richiesto dalle due rappresentazioni vengono spesso espressi considerando sia $|V|$ che $|E|$. Nella notazione asintotica si omette la cardinalità.
\subsection{Liste di adiacenza}
La \textbf{rappresentazione con liste di adiacenza} di un grafo $G = (V,E)$ consiste in un vettore \textit{Adj} di $|V|$ liste, una per ogni vertice di \textit{V}. Per ogni nodo $u \in V$, la lista di adiacenza $Adj[u]$ contiene tutti i vertici \textit{v} tali che esista un arco $(u,v) \in E$. Ovvero $Adj[u]$ include tutti i vertici adiacenti a \textit{u} in \textit{G} (per i grafi indiretti si considera sia $(u,v)$ che $(v,u)$).

Se \textit{G} è un grafo orientato, la somma delle lunghezze di tutte le liste di adiacenza è $|E|$, perché un arco della forma $(u,v)$ è rappresentato inserendo \textit{v} in $Adj[u]$. Se \textit{G} è un grafo non orientato, la somma delle lunghezze di tutte le liste di adiacenza è $2|E|$, perché se $(u,v)$ è un arco non orientato, allora \textit{u} appare nella lista di adiacenza di \textit{v} e viceversa.

Per i grafi orientati e non orientati, la rappresentazione con liste di adiacenza richiede la quantità di memoria $\Theta(V + E)$ (questo perché ci sono tutti e soli gli archi del grafo, quindi si considera $\Theta$).

Tramite le liste di adiacenza è possibile rappresentare anche i \textbf{grafi pesati}, cioè, i grafi per i quali ogni arco ha un \textbf{peso} associato, definito tramite la \textbf{funzione peso} $w : E \rightarrow \mathbb{R}$. Per esempio, sia $G = (V,E)$ un grafo pesato con la funzione peso \textit{w}; il peso $w(u,v)$ dell'arco $(u,v) \in E$ viene memorizzato insieme al vertice \textit{v} nella lista di adiacenza di \textit{v} come se fosse un attributo. La rappresentazione con liste di adiacenza è molto robusta, nel senso che può essere modificata per supportare molte altre varianti di grafi.

Il tempo necessario per elencare tutti i nodi adiacenti ad un nodo \textit{u} è proporzionale al numero di nodi adiacenti, ovvero è $\Theta(u.degree)$, dove \textit{degree} indica il numero di archi uscenti da \textit{u} (si una $\Theta$ perché si scorre la lista fino in fondo). Il tempo per determinare se $(u,v) \in E$ è invece $O(u.degree)$; stavolta si usa $O$ perché ci si potrebbe fermare prima di essere arrivati alla fine della lista.

Uno svantaggio potenziale della rappresentazione con liste di adiacenza è che non c'è un modo più veloce per determinare se un particolare arco $(u,v)$ è presente nel grafo che cercare \textit{v} nella lista di adiacenza $Adj[u]$. Per porre rimedio a questo svantaggio, si può rappresentare il grafo con una matrice di adiacenza, al costo di usare asintoticamente una maggiore quantità di memoria.
\subsection{Matrice di adiacenza}
Per la \textbf{rappresentazione con matrice di adiacenza} di un grafo $G = (V,E)$ si suppone che i vertici siano numerati $1,\,2,\,...\,,\,|V|$ in modo arbitrario. La rappresentazione con matrice di adiacenza di un grafo \textit{G} consiste in una matrice $A = (a_{ij})$ di dimensioni $|V| \times |V|$ tale che
\begin{equation*}
a_{ij} = \left\{
\begin{array}{ll}
1 &\text{se } (i,j) \in E\\
0 &\text{negli altri casi}
\end{array}\right.
\end{equation*}
La matrice di adiacenza di un grafo richiede una memoria $\Theta(V^2)$, indipendentemente dal numero di archi nel grafo. Il tempo necessario per elencare tutti i vertici adiacenti a \textit{u} è $\Theta(V)$ perché si deve scorrere una riga fino alla fine; il tempo necessario per determinare se $(u,v) \in E$ è $\Theta(1)$.

Nel caso di un grafo non orientato la matrice è simmetrica rispetto alla diagonale principale. Poiché $(u,v)$ e $(v,u)$ rappresentano lo stesso arco in un grafo non orientato, la matrice di adiacenza di \textit{A} di un grafo non orientato è uguale alla sua trasposta: $A = A^T$.

Come la rappresentazione con liste di adiacenza di un grafo, anche la rappresentazione con matrice di adiacenza può essere utilizzata per i grafi pesati. Il peso di ogni arco $(u,v)$ è memorizzato come l'elemento nella riga \textit{u} e nella colonna \textit{v} della matrice di adiacenza.

Sebbene la rappresentazione con liste di adiacenza sia asintoticamente efficiente almeno quanto la rappresentazione con matrice di adiacenza, tuttavia quando i grafi sono abbastanza piccoli potrebbe essere preferita la matrice di adiacenza per la sua semplicità. Inoltre, se il grafo non è pesato, c'è un'ulteriore vantaggio per la rappresentazione con matrice di adiacenza che riguarda la memoria richiesta. Anziché utilizzare una parola della memoria del calcolatore per ogni elemento della matrice di adiacenza, basta utilizzare un solo bit per ogni elemento.

Nelle liste di adiacenza solitamente si utilizzano i puntatori ai vertici che sono quindi più lenti. Per scegliere tra liste di adiacenza e matrice di adiacenza si considerano i byte (pesi) necessari. In genere, le liste di adiacenza hanno costanti più alte. Per le liste di adiacenza si dovrebbe conoscere il peso \textit{w}, il numero di byte per ciascun puntatore \textit{p} e la dimensione \textit{k} della chiave definita come $k = log_2\lceil V \rceil$. Si ottiene così una dimensione pari a $(k + p + w)E + (k + p)V$. Per la matrice di adiacenza, invece, la dimensione è pari a $wV^2 + kV$, dove tuttavia V è probabilmente irrilevante asintoticamente. Si confronta quindi $(k + p + w)E $ con $wV^2$ e se
\begin{equation*}
E > \frac{wV^2}{k + p + w}
\end{equation*}
è più conveniente utilizzare la matrice di adiacenza.
\section{Visita in ampiezza}
Dato un grafo $G = (V,E)$ e un vertice distinto \textit{s}, detto \textbf{sorgente}, la visita in ampiezza ispeziona sistematicamente gli archi di \textit{G} per scoprire tutti i vertici che sono raggiungibili da \textit{s}. Per ogni arco $v \in V$ calcola la distanza (numero minimo di archi) $v.d$ da \textit{s} a \textit{v} e il vertice $u = v.\pi$, detto \textbf{predecessore} di \textit{v}, tale che $(u,v)$ è l'ultimo arco nel cammino minimo $s \rightsquigarrow v$. Genera anche un albero BF (breadth-first tree) con radice \textit{s} che contiene tutti i vertici raggiungibili. Per ogni vertice \textit{v} raggiungibile da \textit{s}, il cammino semplice nell'albero BF che va da \textit{s} a \textit{v} corrisponde ad un cammino minimo da \textit{s} a \textit{v} in \textit{G}. L'algoritmo opera sui grafi orientati e non orientati.

La visita in ampiezza è chiamata così perché espande la frontiera fra i vertici scoperti e quelli da scoprire in maniera uniforme lungo l'ampiezza della frontiera (i vertici vengono scoperti per livelli). Ovvero l'algoritmo scopre tutti i vertici che si trovano a distanza \textit{k} da \textit{s}, prima di scoprire i vertici a distanza $k + 1$.

L'algoritmo usa anche una coda \textit{Q} con schema \textsc{FIFO} su cui esegue le operazioni \textsc{Enqueue} e \textsc{Dequeue} aventi costo costante. La lista può essere implementata come una lista collegata.

Per tenere traccia del lavoro svolto, la visita in ampiezza colora i vertici di bianco, grigio o di nero. Inizialmente tutti i vertici sono bianchi. Quando un vertice viene incontrato per la prima volta durante la visita si dice che viene scoperto e diventa grigio. Quando sono stati visitati tutti i vertici adiacenti di un vertice, tale vertice diventa nero. Se $(u,v) \in E$ e il vertice \textit{u} è nero, allora il vertice \textit{v} è grigio oppure nero; ovvero tutti i vertici adiacenti ai vertici neri sono stati scoperti. I vertici grigi possono avere qualche vertice bianco adiacente; essi rappresentano la frontiera fra i vertici scoperti e quelli da scoprire.\\\\
\textsc{BFS(\textit{G},\,\textit{s})}\\
\begin{tabular}{rl}
1&\textbf{for} ogni vertice $u \in G.V - \{s\}$\\
2&\firsttab\textit{u.color} $\leftarrow$ \textsc{white}\\
3&\firsttab\textit{u.d} $\leftarrow \infty$\\
4&\firsttab\textit{u.}$\pi \leftarrow$ \textsc{nil}\\
5&\textit{s.color} $\leftarrow$ \textsc{gray}\\
6&\textit{s.d} $\leftarrow$ 0\\
7&\textit{s.}$\pi \leftarrow$ \textsc{nil}\\
8&\textit{Q} $\leftarrow \emptyset$\\
9&\textsc{Enqueue(\textit{Q},\,\textit{s})}\\
10&\textbf{while} $Q \neq \emptyset$\\
11&\firsttab\textit{u} $\leftarrow$ \textsc{Dequeue(\textit{Q})}\\
12&\firsttab\textbf{for} ogni vertice $u \in G.Adj[u]$\\
13&\secondtab\textbf{if} \textit{v.color} = \textsc{white}\\
14&\thirdtab\textit{v.color} $\leftarrow$ \textsc{gray}\\
15&\thirdtab\textit{v.d} $\leftarrow u.d + 1$\\
16&\thirdtab\textit{v.}$\pi \leftarrow u$\\
17&\thirdtab\textsc{Enqueue(\textit{Q},\,\textit{v})}\\
18&\firsttab\textit{u.color} $\leftarrow$ \textsc{black}
\end{tabular}\\\\
Commenti:
\begin{enumerate}
\item[2]Ancora non è stato trovato
\item[5]È stato scoperto ma ancora non sono stati trovati tutti i suoi vicini
\item[9]Inizializza la coda \textsc{FIFO}
\item[10]Finché c'è qualcosa nella coda
\item[11]Prende il primo elemento messo nella coda. All'inizio c'è \textit{s}
\item[12]Guarda tutti i nodi raggiungibili da \textit{u}
\item[15]È stato scoperto dopo \textit{u}
\item[16]È stato scoperto tramite \textit{u}
\item[18]Ha finito di visitare \textit{u}
\end{enumerate}
La procedura \textsc{BFS} suppone che il grafo di input $G = (V,E)$ sia rappresentato con le liste di adiacenza. Il colore di ogni vertice $u \in V$ è memorizzato nell'attributo $u.color$ e il predecessore di \textit{u} è memorizzato nell'attributo $u.\pi$.

L'idea è che l'algoritmo manda un'onda da \textit{s}, prima colpisce tutti i nodi a distanza 1 da \textit{s}, poi colpisce tutti i nodi a distanza 2 da \textit{s} e così via. Memorizza il fronte d'onda nella coda \textit{Q}, $v \in Q$ se e solo se l'onda ha colpito \textit{v}, ma non è ancora uscita da \textit{v}. Con l'eccezione del vertice sorgente \textit{s}, le righe 1 - 4 colorano di bianco tutti i vertici, assegnano all'attributo $u.d$ il valore infinito per ogni vertice \textit{u} e assegnano al padre di ogni vertice il valore \textsc{nil}. La riga 5 colora \textit{s} di grigio, perché questo vertice è considerato scoperto quando inizia la procedura. La riga 6 inizializza $s.d$ a 0; la riga 7 assegna al predecessore della sorgente il valore \textsc{nil}. Le righe 8 - 9 inizializzano \textit{Q} con la coda che contiene il solo vertice \textit{s}. Il ciclo \textbf{while} (righe 10 - 18) si ripete finché restano dei vertici grigi, che sono vertici scoperti le cui liste di adiacenza non sono state ancora completamente esaminate. Questo ciclo conserva la seguente invariante di ciclo:
\begin{quote}
\textit{Quando viene eseguito il test della riga 10, la coda \textit{Q} è formata dall'insieme dei vertici grigi}
\end{quote}
Per determinare il tempo di esecuzione di \textsc{BFS} si può usare il metodo dell'aggregazione. Le operazioni di inserimento e cancellazione dalla coda richiedono un tempo $O(1)$, quindi il tempo totale dedicato alle operazioni per la coda è $O(V)$ perché ogni nodo è messo nella coda al massimo una volta. Poiché la lista di adiacenza di ciascun vertice viene ispezionata soltanto quando il vertice viene rimosso dalla coda, ogni lista di adiacenza viene ispezionata al più una volta. Poiché la somma delle lunghezze di tutte le liste di adiacenza è $\Theta(E)$, il tempo totale impiegato per ispezionare le liste di adiacenza è $O(E)$ (ogni nodo è tolto dalla coda al massimo una volta e si esamina $(u,v)$ solo quando \textit{u} è tolto dalla coda, inoltre, ogni arco è analizzato al massimo una volta se diretto e al massimo due volte se non diretto). Il costo aggiuntivo di inizializzazione è $O(V)$, quindi il tempo di esecuzione totale di \textsc{BFS} è $O(V + E)$.
\section{Visita in profondità}
Nella visita in profondità, gli archi vengono ispezionati a partire dall'ultimo vertice scoperto \textit{v} che ha ancora archi non ispezionati che escono da esso. Quando tutti gli archi di \textit{v} sono stati ispezionati, la visita \textsl{fa marcia indietro} per ispezionare gli archi che escono dal vertice dal quale \textit{v} era stato scoperto. Questo processo continua finché non saranno stati scoperti tutti i vertici che sono raggiungibili dal vertice sorgente originale. Se restano dei vertici non scoperti, allora uno di essi viene selezionato come nuovo vertice sorgente e la visita riparte da questa sorgente. L'intero processo viene ripetuto finché non saranno scoperti tutti i vertici del grafo.

Come nella visita in ampiezza, quando un vertice \textit{v} viene scoperto durante un'ispezione della lista di adiacenza di un vertice \textit{u} già scoperto, la visita in profondità registra questo evento assegnando \textit{u} all'attributo $v.\pi$ di \textit{v} (il predecessore).

Diversamente dalla visita in ampiezza, il cui sottografo dei predecessori forma un albero, il sottografo dei predecessori prodotto da una visita in profondità può essere formato da più alberi, perché la visita può essere ripetuta da più sorgenti. Il \textbf{sottografo dei predecessori} di una visita in profondità forma una \textbf{foresta DF} (depth-first forest) composta da veri \textbf{alberi DF}.

Come nella visita in ampiezza, i vertici vengono colorati durante la visita in profondità per indicare il loro stato. Inizialmente, tutti i vertici sono bianchi. Un vertice diventa grigio quando viene \textbf{scoperto} durante la visita; diventa nero quando viene \textbf{completato}, ovvero quando la sua lista di adiacenza è stata completamente ispezionata. Questa tecnica garantisce che ogni vertice vada a finire in un solo albero DF, in modo che questi alberi siano disgiunti.

Oltre a creare un foresta DF, la visita in profondità associa anche a ciascun vertice delle informazioni temporali. Ogni vertice \textit{v} ha due informazioni temporali: la prima $v.d$ registra il momento in cui il vertice \textit{v} viene scoperto (e colorato di grigio); la seconda $v.f$ registra il momento in cui la visita completa l'ispezione della lista di adiacenza del vertice \textit{v} (che diventa nero).

La procedura \textsc{DFS} registra nell'attributo $u.d$ il momento in cui scopre il vertice \textit{u} e nell'attributo $u.f$ il momento in cui completa la visita del vertice \textit{u}. Queste informazioni temporali sono numeri interi compresi fra 1 e $2|V|$ (ciascuno dei $|V|$ vertici è scoperto una sola volta e la sua visita è completata una sola volta). Per ogni vertice \textit{u} si ha $u.d < u.f$. Il vertice \textit{u} è \textsc{white} prima del tempo $u.d$, \textsc{gray} fra il tempo $u.d$ e il tempo $u.f$, e \textsc{black} successivamente.\\\\
\textsc{DFS(\textit{G})}\\
1\firsttab\textbf{for} ogni vertice $u \in G.V$\\
2\secondtab\textit{u.color} $\leftarrow$ \textsc{white}\\
3\secondtab\textit{u.}$\pi \leftarrow$ \textsc{nil}\\
4\firsttab\textit{time} $\leftarrow 0$\\
5\firsttab\textbf{for} ogni vertice $u \in G.V$\\
6\secondtab\textbf{if} \textit{u.color} = \textsc{white}\\
7\thirdtab\textsc{DFS-Visit(\textit{G},\,\textit{u})}\\\\
Commenti:
\begin{enumerate}
\item[1-4]Inizializzazione
\item[6-7]Se il nodo \textit{u} non era già stato visitato, quindi era bianco, lo visita
\end{enumerate}
\textsc{DFS-Visit(\textit{G},\,\textit{u})}\\
\begin{tabular}{rl}
1&\textit{time} $\leftarrow$ \textit{time} + 1\\
2&\textit{u.d} $\leftarrow$ \textit{time}\\
3&\textit{u.color} $\leftarrow$ \textsc{gray}\\
4&\textbf{for} ogni $v \in G.Adj[u]$\\
5&\firsttab\textbf{if} \textit{v.color} = \textsc{white}\\
6&\secondtab\textit{v.}$\pi \leftarrow u$\\
7&\secondtab\textsc{DFS-Visit(\textit{G},\,\textit{v})}\\
8&\textit{u.color} $\leftarrow$ \textsc{black}\\
9&\textit{time} $\leftarrow$ \textit{time + 1}\\
10&\textit{u.f} $\leftarrow$ \textit{time}
\end{tabular}\\\\
Commenti:
\begin{enumerate}
\item[2]Il tempo di scoperta coincide con il tempo attuale
\item[3]Non controlla se è bianco perché il controllo è già stato fatto in \textsc{DFS}
\item[4]Valuta i vicini di \textit{u}
\item[5]Se il vicino è bianco lo visita
\item[8]Quando ha visto tutti i vicini di \textit{u}, il vertice diventa nero
\end{enumerate}
La righe 1 - 3 di \textsc{DFS} colorano di bianco tutti i vertici e inizializzano i loro attributi $\pi$ e \textsc{nil}. La riga 4 azzera il contatore globale del tempo. Le righe 5 - 7 controllano, uno alla volta, tutti i vertici in \textit{V} e, quando trovano un vertice bianco, lo visitano utilizzando la procedura \textsc{DFS-Visit}. Ogni volta che viene chiamata la procedura \textsc{DFS-Visit(\textit{u})} nella riga 7, il vertice \textit{u} diventa la radice di un nuovo albero della foresta DF. Quando la procedura \textsc{DFS} termina, ad ogni vertice \textit{u} è stato assegnato un \textbf{tempo di scoperta} $u.d$ e un \textbf{tempo di completamento} $u.f$.

In ogni chiamata di \textsc{DFS-Visit(\textit{u})}, il vertice \textit{u} è inizialmente bianco. La riga 1 incrementa la variabile globale \textit{time}, la riga 2 registra il nuovo valore di \textit{time} come il tempo di scoperta $u.d$ e la riga 3 colora di grigio \textit{u}. Le righe 4 - 7 ispezionano ogni vertice \textit{v} adiacente a \textit{u} e visitano in modo ricorsivo il vertice \textit{v}, se è bianco. Dopo che tutti i nodi che escono da \textit{u} sono stati ispezionati, le righe 8 - 10 colorano di nero \textit{u}, incrementano \textit{time} e registrano in $u.f$ il tempo di completamento della visita.

I risultati della visita in profondità potrebbero dipendere dall'ordine in cui i vertici sono ispezionati nella riga 5 della procedura \textsc{DFS} e dall'ordine in cui i vicini di un vertice vengono visitati nella riga 4 della procedura \textsc{DFS-Visit}. In pratica, queste differenze nell'ordine in cui vengono effettuate le visite non causano problemi, in quanto qualsiasi risultato della visita in profondità di solito può essere efficacemente utilizzato, perché i risultati ottenuti sono essenzialmente equivalenti.

I cicli nelle righe 1 - 3 e nelle righe 5 - 7 di \textsc{DFS} impiegano un tempo $\Theta(V)$, escluso il tempo per eseguire le chiamate di \textsc{DFS-Visit}. Applicando il metodo dell'aggregazione e considerando che la procedura \textsc{DFS-Visit} è chiamata esattamente una volta per ogni vertice $v \in V$ (viene invocata soltanto se un vertice è bianco e la prima cosa che fa è colorarlo di grigio), si ottiene che il ciclo nelle righe 4 - 7 di \textsc{DFS-Visit} ha un costo totale di $\Theta(E)$. Il tempo di esecuzione di \textsc{DFS} è dunque $\Theta(V + E)$ ($\Theta$ e non solo $O$ perché esplora ogni nodo e arco).
\subsection{Teoremi sui grafi}
La visita in profondità fornisce informazioni preziose sulla struttura di un grafo. Una delle più importanti è che i tempi di scoperta e di completamento hanno una \textbf{struttura di parentesi}. Se si rappresenta le scoperta del vertice \textit{u} con una parentesi aperta $(u$ e il suo completamento con una parentesi chiusa $u)$, allora la storia delle scoperte e dei completamenti produce una sequenza di parentesi opportunamente annidate.
\begin{theorem}[\textbf{Teorema delle parentesi}]
In una visita in profondità di un grafo $G = (V,E)$ (orientato o non orientato), per ogni coppia di vertici \textit{u} e \textit{v}, è soddisfatta una sola delle seguenti tre condizioni:
\begin{enumerate}
\item Gli intervalli [$u.d, u.f$] e [$v.d, v.f$] sono completamente disgiunti ovvero $u.d < u.f < v.d < v.f$ oppure $v.d < v.f < u.d < u.f$; inoltre \textit{u} e \textit{v} non sono discendenti l'uno dell'altro in un albero DF
\item L'intervallo [$u.d, u.f$] è interamente contenuto nell'intervallo [$v.d, v.f$] cioè $u.d < v.d < v.f < u.f$; inoltre \textit{u} è un discendente di \textit{v} in un albero DF
\item L'intervallo [$v.d, v.f$] è interamente contenuto nell'intervallo [$u.d, u.f$] cioè $v.d < u.d < u.f < v.f$; inoltre \textit{v} è un discendente di \textit{u} in un albero DF
\end{enumerate}
Non può succedere che $u.d < v.d < u.f < v.f$, non c'è possibilità di intersezione.
\end{theorem}
\begin{corollario}
Il vertice \textit{v} è un discendente del vertice \textit{u} nella foresta DF per un grafo \textit{G} (orientato o non orientato) se e soltanto se $u.d < v.d < v.f < u.f$.
\end{corollario}
\begin{theorem}[\textbf{Teorema del cammino bianco}]
In una foresta DF di un grafo $G = (V,E)$ (orientato o non orientato), il vertice \textit{v} è un discendente del vertice \textit{u} se e soltanto se, al tempo $u.d$ in cui viene scoperto \textit{u}, il vertice \textit{v} può essere raggiunto da \textit{u} lungo un cammino $u \rightsquigarrow v$ che è formato esclusivamente da vertici bianchi (ad eccezione di \textit{u} che è stato appena colorato di grigio).
\end{theorem}
\subsection{Classificazione degli archi}
La visita in profondità permette di classificare gli archi del grafo. Questa classificazione può essere usata per raccogliere informazioni su un grafo. Ci sono quattro tipi di archi in base alla foresta della visita in profondità del grafo \textit{G}:
\begin{description}
\item[Archi d'albero T] Gli archi nella foresta DF trovati esplorando l'arco $(u,v)$
\item[Archi all'indietro B] Sono quegli archi $(u,v)$ che collegano un vertice \textit{u} a un antenato \textit{v} in un albero DF
\item[Archi in avanti F] Sono gli archi $(u,v)$ che collegano un vertice \textit{u} a un discendente \textit{v} in un albero DF, ma non sono T
\item[Archi trasversali C] Tutti gli altri archi. Possono connettere i vertici nello stesso albero DF, purché un vertice non sia un antenato dell'altro, oppure possono connettere vertici di alberi DF differenti
\end{description}
L'algoritmo \textsc{DFS} possiede le informazioni necessarie per classificare gli archi che incontra.

L'idea chiave è che ogni arco $(u,v)$ può essere classificato in base al colore del vertice \textit{v} che viene raggiunto quando l'arco viene ispezionato per la prima volta:
\begin{itemize}
\item Se $v.color$ = \textsc{white}, allora l'arco è un arco d'albero T
\item Se $v.color$ = \textsc{gray}, allora l'arco è un arco all'indietro B
\item Se $v.color$ = \textsc{black}, allora è un arco F o un arco C. Se $u.d < v.d$ è un arco F, se $u.d > v.d$ è invece un arco C e i due vertici non sono connessi
\end{itemize}
\begin{theorem}
In una visita in profondità di un grafo non orientato \textit{G}, gli archi di \textit{G} possono essere archi d'albero T o archi all'indietro B. Non possono esserci archi F o C perché tutti i nodi sono raggiunti da un attraversamento.
\end{theorem}
\section{Ordinamento topologico}
Un \textbf{ordinamento topologico} di un grafo aciclico o dag (directed acyclic graph) $G = (V,E)$ è un ordinamento lineare di tutti i suoi vertici tali che, se \textit{G} contiene un arco $(u,v)$, allora \textit{u} appare prima di \textit{v} nell'ordinamento (da qualche parte, non per forza subito prima). Può essere visto come un ordinamento dei suoi vertici lungo una linea orizzontale in modo che tutti gli archi orientati siano diretti da sinistra a destra. È utile per gestire oggetti che hanno un \textbf{ordinamento parziale}: se $a > b$ e $b > c$ allora $a > c$ ma si può avere \textit{a} e \textit{b} tali che non si sa se $a > b$ o $b > c$. Si può sempre avere un ordinamento \textbf{totale} ($a > b$ o $b > a$ $\forall a \neq b$) da un ordinamento parziale. Se il grafo non è aciclico non si può effettuare un ordinamento lineare.
\begin{theorem}
Un grafo diretto \textit{G} è \textbf{aciclico} se e solo se una visita \textsc{DFS} di \textit{G} non genere archi all'indietro B.
\end{theorem}
\begin{proof}
Bisogna dimostrare in entrambi le direzioni:
\begin{itemize}
\item\textbf{Se c'è un arco all'indietro allora c'è un ciclo}: si suppone che ci sia un arco all'indietro $(u,v)$. Allora il vertice \textit{v} è un antenato del vertice \textit{u} nella foresta DF. Quindi esiste un percorso $v \rightsquigarrow u$ nel grafo \textit{G} che, insieme all'arco all'indietro $(u,v)$, completa il ciclo.
\item\textbf{Se c'è un ciclo allora c'è un arco all'indietro}: si suppone che il grafo \textit{G} contenga un ciclo \textit{c}. Si dimostra che una visita in profondità di \textit{G} genera un arco all'indietro. Sia \textit{v} il primo vertice che viene scoperto in \textit{c} e sia $(u,v)$ l'arco precedente in \textit{c}. Al tempo $v.d$ i vertici di \textit{c} formano un cammino bianco $v \rightsquigarrow u$ (poiché \textit{v} è il primo vertice scoperto in \textit{c}). Per il teorema del cammino bianco, il vertice \textit{u} diventa un discendente di \textit{v} nella foresta DF. Dunque $(u,v)$ è un arco all'indietro.
\end{itemize}
\end{proof}
\textsc{Topological-Sort(\textit{G})}\\
1\firsttab Chiama \textsc{DFS(\textit{G})} per calcolare i tempi $v.f$ per ogni vertice \textit{v}\\
2\firsttab Completata l'ispezione di un vertice,\\
\secondtab inserisce il vertice in testa a una lista concatenata\\
3\firsttab\textbf{return} la lista concatenata dei vertici\\\\
Commenti:
\begin{enumerate}
\item[1]Non interessa $v.d$
\item[3]Equivale a "emetti i vertici in ordine di tempo di terminazione decrescente"
\end{enumerate}
È possibile eseguire un ordinamento topologico nel tempo $\Theta(V + E)$, perché la visita in profondità impiega un tempo $\Theta(V + E)$ e occorre un tempo $O(1)$ per inserire ciascuno dei $|V|$ vertici in testa alla lista concatenata.
\subsection{Correttezza}
\begin{theorem}
\textsc{Topological-Sort(\textit{G})} produce un ordinamento topologico di un grafo orientato aciclico \textit{G}.
\end{theorem}
\begin{proof}
Si suppone che la procedura \textsc{DFS} venga eseguita su un dato dag $G = (V,E)$ per determinare i tempi di completamento dei suoi vertici. È sufficiente dimostrare che se $(u,v) \in E$, allora $v.f < u.f$. Si considera un arco qualsiasi $(u,v)$ ispezionato dalla procedura \textsc{DFS}. Quando l'arco viene ispezionato \textit{u} è grigio. Il vertice \textit{v} non può essere grigio, perché altrimenti \textit{v} sarebbe un antenato di \textit{u} e $(u,v)$ sarebbe un arco all'indietro, contraddicendo il lemma precedente (dag non ha archi all'indietro). Quindi, il vertice \textit{v} deve essere bianco o nero. Se \textit{v} è bianco, diventa un discendente di \textit{u} e, dal teorema delle parentesi, si ha $u.d < v.d < v.f < u.f$ cioè $v.f < u.f$. Se \textit{v} è nero, la sua ispezione è stata già completata, quindi il valore di $v.f$ è già stato impostato. Poiché si sta ancora ispezionando dal vertice \textit{u}, si deve ancora assegnare un'informazione temporale a $u.f$ e, quando verrà fatto, si avrà ancora $v.f < u.f$. Quindi, per qualsiasi arco $(u,v)$ nel dag, si ha $v.f < u.f$, e questo dimostra il teorema.
\end{proof}
\section{Componenti fortemente connesse}
Una componente fortemente connessa di un grafo orientato $G = (V,E)$ è un insieme massimale di vertici $C \subseteq V$ tale che per ogni coppia di vertici \textit{u} e \textit{v} in \textit{C}, si ha $u \rightsquigarrow v$ e $v \rightsquigarrow u$; ovvero i vertici \textit{u} e \textit{v} sono raggiungibili l'uno dall'altro.

L'algoritmo per trovare le componenti fortemente connesse di $G = (V,E)$ utilizza il grafo trasposto di \textit{G}, che è definito come il grafo $G^T = (V,E^T)$, dove $E^T = \{(u,v) : (v,u \in E)\}$. Ovvero $E^T$ è formato dagli archi di \textit{G} con direzioni inverse. Data una rappresentazione con liste di adiacenza di \textit{G}, il tempo richiesto per creare $G^T$ è $O(V + E)$. I grafi \textit{G} e $G^T$ hanno esattamente le stesse componenti fortemente connesse: i vertici \textit{u} e \textit{v} sono raggiungibili l'uno dall'altro in \textit{G}, se e soltanto se sono raggiungibili l'uno dall'altro in $G^T$.

L'idea che sta alla base dell'algoritmo per il calcolo delle componenti fortemente connesse di un grafo deriva da una proprietà fondamentale del \textbf{grafo delle componenti} $G^{SCC} = (V^{SCC},E^{SCC})$. Supponendo che un grafo \textit{G} abbia le componenti fortemente connesse $C_1,\,C_2,\,...\,,\,C_k$, l'insieme dei vertici $V^{SCC}$ è $\{v_1,\,v_2,\,...\,,\,v_k\}$ e contiene un vertice $v_i$ per ogni componente fortemente connessa $C_i$ di \textit{G}. Esiste un arco $(v_i,v_j) \in E^{SCC}$ se \textit{G} contiene un arco orientato $(x,y)$ per qualche $x \in C_i$ e qualche $y \in C_j$. Ovvero, $E^{SCC}$ ha un arco se c'è un arco fra le corrispondenti componenti fortemente connesse di \textit{G}. In altri termini, contraendo tutti gli archi i cui vertici incidenti sono all'interno della stessa componente fortemente connessa di \textit{G}, si ottiene $G^{SCC}$.

La proprietà fondamentale è che il grafo delle componenti fortemente connesse è un grafo orientato aciclico, cioè un dag, che implica il seguente lemma
\begin{lemma}
Siano \textit{C} e $C'$ due componenti fortemente connesse distinte nel grafo orientato \textit{G}. Se $u,v \in C$ e $u',v' \in C'$ e supponendo che ci sia un cammino $u \rightsquigarrow u'$ in \textit{G}, allora non può esistere anche un cammino $v' \rightsquigarrow v$ in \textit{G}.
\end{lemma}
\begin{proof}
Se esiste un cammino $v' \rightsquigarrow v$ in \textit{G}, allora esistono i cammini $u \rightsquigarrow u' \rightsquigarrow  v'$ e $v' \rightsquigarrow v \rightsquigarrow  u$ in \textit{G}. Quindi, \textit{u} e $v'$ sono raggiungibili l'uno dall'altro, contraddicendo l'ipotesi che \textit{C} e $C'$ siano \textit{SCC} e distinte.
\end{proof}
L'algoritmo \textsc{Strongly-Connected-Components} calcola con tempo lineare $\Theta(V + E)$ le componenti fortemente connesse di un grafo orientato \textit{G} utilizzando due visite in profondità, una su \textit{G} e una su $G^T$.\\\\
\textsc{Strongly-Connected-Components(\textit{G})}\\
1\firsttab Chiama \textsc{DFS(\textit{G})} per calcolare i tempi di completamento $v.f$\\
\secondtab per ogni vertice \textit{v}\\
2\firsttab Calcola $G^T$\\
3\firsttab Chiama \textsc{DFS($G^T$)}, nel ciclo in \textsc{DFS} considera i vertici in\\
\secondtab ordine decrescente rispetto ai tempi $u.f$ (calcolati nella riga 1)\\
4\firsttab Genere l'output dei vertici di ciascun albero della foresta DF\\
\secondtab che è stata prodotta nella riga 3 come una singola\\
\secondtab componente fortemente connessa\\\\
Esaminando i vertici nella seconda visita in profondità in ordine decrescente rispetto ai tempi di completamento che sono stati calcolati nella prima visita in profondità si stanno visitando i vertici del grafo delle componenti (corrispondenti a una componente fortemente connessa) secondo un ordinamento topologico.

I valori $u.d$ e $u.f$ si riferiscono ai tempi di scoperta e di completamento che sono stati calcolati dalla prima visita in profondità nella riga 1. Si estende la notazione dei tempi di scoperta e di completamento agli insiemi di vertici. Se $U \subseteq V$, si definiscono
\begin{equation*}
d(U) = \min_{u \in U}\{u.d\}
\end{equation*}
e
\begin{equation*}
f(U) = \max_{u \in U}\{u.f\}
\end{equation*}
Ovvero $d(U)$ e $f(U)$ sono, rispettivamente, il primo tempo di scoperta e l'ultimo tempo di completamento di un vertice qualsiasi in \textit{U}.
\subsection{Teoremi sulle SCC}
\begin{theorem}
Siano \textit{C} e $C'$ delle componenti fortemente connesse e distinte nel grafo orientato $G = (V,E)$. Si suppone che esista un arco $(u,v) \in E$, dove $u \in C$ e $v \in C'$. Allora $f(C) > f(C')$.
\end{theorem}
\begin{proof}
Due casi, a seconda di quale componente fortemente connessa, \textit{C} o $C'$, contiene il primo vertice che viene scoperto durante la visita in profondità. Se $d(C) < d(C')$, si indica con \textit{x} il primo vertice scoperto in \textit{C}. Al tempo $x.d$, tutti i vertici in \textit{C} e $C'$ sono bianchi. Esiste un cammino in \textit{G} da \textit{x} a ciascun vertice di \textit{C} che è formato soltanto da vertici bianchi. Poiché $(u,v) \in E$, per un vertice qualsiasi $w \in C'$, al tempo $x.d$ esiste anche un cammino da \textit{x} a \textit{w} in \textit{G} che è formato soltanto da vertici bianchi: $x \rightsquigarrow u \rightarrow v \rightsquigarrow w$. Per il teorema del cammino bianco, tutti i vertici in \textit{C} e $C'$ diventano discendenti di \textit{x} nell'albero DF. Per il teorema delle parentesi: $x.f = f(C) > f(C')$. Se, invece, $d(C) > d(C')$, si indica con \textit{y} il primo vertice scoperto in $C'$. Al tempo $y.d$, tutti i vertici in $C'$ sono bianchi ed esiste un cammino in \textit{G} da \textit{y} a ciascun vertice in $C'$ che è formato soltanto da vertici bianchi. Per il teorema del cammino bianco, tutti i vertici in $C'$ diventano discendenti di \textit{y} nell'albero DF e $y.f = f(C')$. Al tempo $y.d$, tutti i vertici in \textit{C} sono bianchi. Poiché c'è un arco $(u,v)$ da \textit{C} a $C'$, per il lemma $(16.1)$ non può esistere un cammino da \textit{C'} a \textit{C}. Pertanto, nessun vertice in \textit{C} è raggiungibile da \textit{y}. Al tempo $y.f$ quindi tutti i vertici in \textit{C} sono ancora bianchi. Dunque, per un vertice qualsiasi $w \in C$, si ha $w.f > y.f$ e questo implica che $f(C) > f(C')$.
\end{proof}
\begin{corollario}
Siano \textit{C} e $C'$ due componenti fortemente connesse e distinte nel grafo orientato $G = (V,E)$. Si suppone che esista un arco $(u,v) \in E^T$, dove $u \in C$ e $v \in C'$. Allora $f(C) < f(C')$.
\end{corollario}
\begin{proof}
Poiché $(u,v) \in E^T$, si ha $(v,u) \in E$. Poiché le componenti fortemente connesse di \textit{G} e $G^T$ sono le stesse, si ottiene $f(C) < f(C')$.
\end{proof}
\begin{corollario}
Siano \textit{C} e $C'$ due componenti fortemente connesse nel grafo orientato \textit{G}. Si suppone $f(C) > f(C')$. Allora non ci può essere un arco tra \textit{C} e \textit{C'} in $G^T$.
\end{corollario}
\begin{proof}
Supponendo per assurdo che esista l'arco, allora si avrebbe $f(C) < f(C')$ (per il corollario) contraddicendo l'ipotesi $f(C) > f(C')$.
\end{proof}
\subsection{Correttezza}
La \textsc{DFS} su $G^T$ all'interno di \textsc{Strongly-Connected-Components} inizia con la componente fortemente connessa \textit{C} tale che $f(C)$ è massimo. La visita inizia da $x \in C$ e visita tutti i vertici in \textit{C}. Poiché, da corollario, $f(C) > f(C')$ per ogni $C' \neq C$, non ci sono archi da \textit{C} a $C'$ in $G^T$ quindi \textsc{DFS} visita solo i vertici in \textit{C}. Il vertice successivo è $y \in C'$ tale che $f(C')$ è massimo in tutte le componente fortemente connesse diverse da \textit{C}. \textsc{DFS} visita tutti i vertici in $C'$ e i soli archi che escono da $C'$ vanno in \textit{C} che però è già stato visitato (è tutto nero). Si continua induttivamente per ogni componente fortemente connessa. Quando si sceglie un vertice si possono raggiungere solo i vertici nella sua componente fortemente connessa oppure vertici in componenti fortemente connesse già visitate nel secondo \textsc{DFS}.
\chapter{Strutture dati per insiemi disgiunti}
Alcune applicazioni richiedono di raggruppare \textit{n} elementi distinti in una collezione di insiemi disgiunti, la possibilità di trovare l'unico insieme che contiene un determinato elemento e unire due insiemi.

Una \textbf{struttura dati per insiemi disgiunti} è una struttura dati che mantiene una collezione $S = \{S_1,\,S_2,\,...\,,\,S_k\}$ di insiemi dinamici disgiunti. Ciascun insieme è identificato da un \textbf{rappresentante} che è un elemento dell'insieme. In alcune applicazioni non è importante quale elemento sarà utilizzato come rappresentante; l'unica condizione che si impone è che, se si richiede due volte il rappresentante di un insieme dinamico disgiunto senza modificare l'insieme fra le due richieste, si deve ottenere la stessa risposta entrambe le volte. In altre applicazioni ci potrebbe invece essere una regola prestabilita per sceglierlo.
\section{Operazioni con gli insiemi disgiunti}
Ogni elemento di un insieme è rappresentato da un oggetto. Indicando con \textit{x} un oggetto, si vogliono supportare una serie di operazioni:
\begin{description}
\item\textsc{Make-Set(\textit{x})} crea un nuovo insieme il cui unico elemento (e rappresentante) è \textit{x}. Poiché gli insiemi sono disgiunti, \textit{x} non può trovarsi in qualche altro insieme.
\item\textsc{Union(\textit{x},\,\textit{y})} unisce gli insiemi dinamici che contengono \textit{x} e \textit{y}, per esempio $S_x$ e $S_y$, in un nuovo insieme che è l'unione di questi due insiemi. Si suppone che i due insiemi siano disgiunti prima dell'operazione. Il rappresentante dell'insieme risultante è un elemento qualsiasi di $S_x \cup S_y$, sebbene molte implementazioni di \textsc{Union} scelgano specificamente il rappresentante di $S_x$ o quello di $S_y$ come nuovo rappresentante. Poiché si richiede che gli insiemi nella collezione siano disgiunti, si distruggono gli insiemi $S_x$ e $S_y$, eliminandoli dalla collezione $S$. Nella pratica, spesso gli elementi di uno degli insiemi vengono assorbiti dall'altro insieme.
\item\textsc{Find-Set(\textit{x})} Restituisce un puntatore al rappresentante dell'insieme (unico) che contiene \textit{x}.
\end{description}
I tempi di esecuzione delle strutture dati per gli insiemi disgiunti dipendono da due parametri: il numero \textit{n} di operazioni \textsc{Make-Set}, ed il numero totale \textit{m} di operazioni \textsc{Make-Set}, \textsc{Union} e \textsc{Find-Set}. Poiché gli insiemi sono disgiunti, ciascuna operazione \textsc{Union} riduce di un'unità il numero degli insiemi. Dopo $n - 1$ operazioni \textsc{Union}, quindi, resta un solo insieme. Ne consegue che il numero di operazioni \textsc{Make-Set} sono incluse nel numero totale di operazioni \textit{m}, allora $m \geq n$. Si suppone che le \textit{n} operazioni \textsc{Make-Set} siano le prime \textit{n} operazioni eseguite.
\subsection{Applicazioni delle strutture dati per insiemi disgiunti}
Una delle tante applicazioni delle strutture dati per insiemi disgiunti consiste nel determinare le componenti connesse di un grafo non orientato.

La procedura \textsc{Connected-Components} usa le operazioni degli insiemi disgiunti per calcolare le componenti connesse di un grafo. Dopo che \textsc{Connected-Components} ha preelaborato il grafo, la procedura \textsc{Same-Component} è in grado di determinare se due vertici sono nella stessa componente connessa.\\\\
\textsc{Connected-Components(\textit{G})}\\
1\firsttab\textbf{for} ogni vertice $v \in G.V$\\
2\secondtab\textsc{Make-Set(\textit{v})}\\
3\firsttab\textbf{for} ogni arco $(u,v) \in G.E$\\
4\secondtab\textbf{if} \textsc{Find-Set(\textit{u})} $\neq$ \textsc{Find-Set(\textit{v})}\\
5\thirdtab\textsc{Union(\textit{u},\,\textit{v})}\\\\
\textsc{Same-Component(\textit{u},\,\textit{v})}\\
1\firsttab\textbf{if} \textsc{Find-Set(\textit{u})} = \textsc{Find-Set(\textit{v})}\\
2\secondtab\textbf{return} \textsc{true}\\
3\firsttab\textbf{else return} \textsc{false}\\\\
Inizialmente, la procedura \textsc{Connected-Components} pone ciascun vertice \textit{v} nel proprio insieme. Poi, per ogni arco $(u,v)$, unisce gli insiemi che contengono \textit{u} e \textit{v}. Dopo che tutti gli archi sono stati elaborati, due vertici si trovano nella stessa componente connessa, se e soltanto se i corrispondenti oggetti si trovano nello stesso insieme. Dunque, \textsc{Connected-Components} calcola gli insiemi in modo tale che la procedura \textsc{Same-Components} possa determinare se due vertici si trovano nella stessa componente connessa.
\section{Rappresentazione di insiemi disgiunti tramite liste concatenate}
Un semplice modo di implementare una struttura dati per gli insiemi disgiunti consiste nel rappresentare ciascun insieme attraverso una lista concatenata. L'oggetto di ciascun insieme ha gli attributi \textit{head}, che punta al primo oggetto della lista, e \textit{tail}, che punta all'ultimo oggetto. Ogni oggetto nella lista contiene un elemento dell'insieme, un puntatore al successivo oggetto della lista e un puntatore che ritorna all'oggetto dell'insieme. All'interno di ciascuna lista concatenata, gli oggetti possono apparire in qualsiasi ordine. Il rappresentante è l'elemento dell'insieme nel primo oggetto della lista.

Con questa rappresentazione mediante liste concatenate, entrambe le operazioni \textsc{Make-Set} e \textsc{Find-Set} sono semplici da realizzare e richiedono un tempo $O(1)$. Per realizzare l'operazione \textsc{Make-Set(\textit{x})}, si crea una nuova lista concatenata il cui unico oggetto è \textit{x}. Per l'operazione \textsc{Find-Set(\textit{x})}, basta seguire il puntatore da \textit{x} per arrivare all'oggetto del suo insieme e poi ritornare all'elemento nell'oggetto cui punta \textit{head}.
\subsection{Implementazione dell'operazione di unione}
La più semplice implementazione dell'operazione \textsc{Union} che usa la rappresentazione degli insiemi mediante liste concatenate richiede molto più tempo rispetto all'operazione \textsc{Make-Set} o \textsc{Find-Set}. L'operazione \textsc{Union(\textit{x},\,\textit{y})} aggiunge la lista di \textit{y} alla fine della lista di \textit{x}. Il rappresentante della lista \textit{x} diventa il rappresentante dell'insieme risultante. Tuttavia, si deve aggiornare il puntatore all'oggetto dell'insieme per ogni oggetto che originariamente si trovava nella lista \textit{y}; questo richiede un tempo lineare nella lunghezza della lista di \textit{y}.

Indicato con \textit{m} il numero totale di operazioni eseguite, si suppone di avere \textit{n} oggetti $x_1,\,x_2,\,...\,,\,x_n$, quindi $m \geq n$. Per \textit{n} oggetti verranno eseguite \textit{n} operazioni \textsc{Make-Set} seguite, per esempio, da $n - 1$ operazioni \textsc{Union}, quindi $m = 2n - 1$. Si impiega un tempo $\Theta(n)$ per eseguire le \textit{n} operazioni \textsc{Make-Set}. Poiché l'\textit{i}-esima operazione \textsc{Union} aggiorna \textit{i} oggetti, il numero totale di oggetti aggiornati da tutte le $n - 1$ operazioni \textsc{Union} è
\begin{equation*}
\sum_{i=1}^{n-1}i = \Theta(n^2)
\end{equation*}
Nel caso peggiore, la precedente implementazione della procedura \textsc{Union} richiede un tempo medio $\Theta(n)$ per chiamata, perché si potrebbe appendere una lista più lunga a una più corta; si deve aggiornare il puntatore all'oggetto dell'insieme per ogni elemento della lista più lunga.
\subsection{Euristica dell'unione pesata}
Supponendo che ogni lista includa anche la lunghezza della lista e supponendo di appendere sempre la lista più piccola a quella più lunga, risolvendo in modo arbitrario i casi di liste aventi la stessa lunghezza. In questo modo (euristica dell'unione pesata), una singola operazione \textsc{Union} può ancora impiegare un tempo $\Omega(n)$, se entrambi gli insiemi hanno $\Omega(n)$ elementi (entrambi gli insiemi hanno $n/2$ elementi). Tuttavia:
\begin{theorem}
Una sequenza di \textit{m} operazioni \textsc{Make-Set}, \textsc{Union} e \textsc{Find-Set}, su \textit{n} elementi, impiega un tempo $O(m + n\,lg\,n)$.
\end{theorem}
\begin{proof}
Per ogni $k \leq n$, dopo che il puntatore di \textit{x} viene aggiornato $\lceil lg\,k \rceil$ volte, l'insieme risultante deve avere almeno \textit{k} elementi. Dato che l'insieme più grande ha al più \textit{n} elementi, il puntatore di ciascun oggetto è stato aggiornato al più $\lceil lg\,n \rceil$ volte in tutte le operazioni \textsc{Union}. Quindi il tempo totale speso per aggiornare i puntatori degli oggetti durante le operazioni \textsc{Union} è $O(n\,lg\,n)$. Per \textit{m} operazioni si ottiene un tempo $O(m + n\,lg\,n)$.
\end{proof}
\chapter{Heap}
Un \textbf{heap (binario)} è una struttura dati composta da un array che si può considerare come un albero binario quasi completo. Ogni nodo dell'albero corrisponde a un elemento dell'array. Tutti i livelli dell'albero sono completamente riempiti, tranne eventualmente l'ultimo che può essere riempito da sinistra verso destra fino a un certo punto. Un array \textit{A} che rappresenta un heap è un oggetto con due attributi: \textit{A.length} indica il numero di elementi nell'array; \textit{A.heap-size} indica il numero degli elementi dell'heap che sono registrati nell'array. Cioè, anche se ci possono essere dei numeri memorizzati in tutto l'array \textit{A}[\textit{1}\,...\,\textit{A.length}], soltanto i numeri in \textit{A}[\textit{1}\,...\,\textit{A.heap-size}], dove $0 \leq$ \textit{A.heap-size} $\leq A.length$, sono elementi validi dell'heap. La radice dell'albero è \textit{A}[1]. Se \textit{i} è l'indice di un nodo, gli indici di suo padre \textsc{Parent(\textit{i})}, del figlio sinistro \textsc{Left(\textit{i})} e del figlio destro \textsc{Right(\textit{i})} possono essere facilmente calcolati.\\\\
\textsc{Parent(\textit{i})}\\
1\firsttab\textbf{return} $\lfloor i/2 \rfloor$\\\\
\textsc{Left(\textit{i})}\\
1\firsttab\textbf{return} $2i$\\\\
\textsc{Right(\textit{i})}\\
1\firsttab\textbf{return} $2i + 1$\\\\
Nella maggior parte dei casi, la procedura \textsc{Left} può calcolare $2i$ con una sola istruzione, facendo scorrere semplicemente di una posizione a sinistra la rappresentazione binaria di \textit{i}. Analogamente, la procedura \textsc{Right} può rapidamente calcolare $2i + 1$, facendo scorrere la rappresentazione binaria di \textit{i} di una posizione a sinistra e aggiungendo 1 come bit meno significativo. La procedura \textsc{Parent} può calcolare $\lfloor i/2 \rfloor$ con uno scorrimento di una posizione a destra della rappresentazione di \textit{i}.

Ci sono due tipi di heap binari: max-heap e min-heap. In entrambi i tipi, i valori nei nodi soddisfano una \textbf{proprietà dell'heap}, le cui caratteristiche dipendono dal tipo di heap. In un max-heap, la \textbf{proprietà del max-heap} è che per ogni nodo \textit{i} diverso dalla radice, si ha:
\begin{equation*}
A[\textsc{Parent(\textit{i})}] \geq A[i]
\end{equation*}
ovvero il valore di un nodo è al massimo il valore di suo padre. Quindi, l'elemento più grande di un max-heap è memorizzato nella radice e il sottoalbero di un nodo contiene valori non maggiori di quello contenuto nel nodo stesso. Un min-heap è organizzato nel modo opposto; la \textbf{proprietà del min-heap} è che per ogni nodo \textit{i} diverso dalla radice, si ha:
\begin{equation*}
A[\textsc{Parent(\textit{i})}] \leq A[i]
\end{equation*}
Il più piccolo elemento in un min-heap è nella radice. I min-heap sono talvolta utilizzati nelle code di priorità.

Considerando un heap nella forma di albero, si definsice \textbf{altezza di un nodo} il numero di archi nel cammino semplice più lungo che dal nodo scende fino a una foglia. Si definisce \textbf{altezza di un heap} l'altezza della sua radice. Poiché un heap di \textit{n} elementi è basato su un albero binario completo, la sua altezza è $\Theta(lg\,n)$. Le operazioni fondamentali sugli heap vengono eseguite in un tempo che è al massimo proporzionale all'altezza dell'albero e, quindi, richiedono un tempo $O(lg\,n)$.
\begin{itemize}
\item La procedura \textsc{Max-Heapify}, che è eseguita nel tempo $O(lg\,n)$, è la chiave per conservare la proprietà del max-heap
\item La procedura \textsc{Build-Max-Heap}, che è eseguita in tempo lineare, genera un max-heap da un array di input non ordinato
\item La procedura \textsc{Heapsort}, che è eseguita nel tempo $O(n\,lg\,n)$, ordina sul posto un array
\item Le quattro procedure \textsc{Max-Heap-Insert}, \textsc{Heap-Extract-Max}, \textsc{Heap-Increase-Key} e \textsc{Heap-Maximum}, che sono eseguite nel tempo $O(lg\,n)$, consentono a un heap di essere utilizzato come una coda di priorità
\end{itemize}
In un array che rappresenta un heap di \textit{n} elementi, le foglie sono i nodi con indici $\lfloor n/2 \rfloor + 1,\,\lfloor n/2 \rfloor + 2,\,...\,,\,n$.
\section{Conservare la proprietà dell'heap}
Per mantenere la proprietà di max-heap si utilizza la procedura \textsc{Max-Heapify}. I suoi input sono un array \textit{A} e un indice \textit{i} dell'array. Quando viene chiamata, \textsc{Max-Heapify} assume che gli alberi binari con radici in \textsc{Left(\textit{i})} e \textsc{Right(\textit{i})} siano max-heap, ma che \textit{A}[\textit{i}] possa essere più piccolo dei suoi figli, violando così la proprietà del max-heap. \textsc{Max-Heapify} fa scendere il valore \textit{A}[\textit{i}] nel max-heap in modo che il sottoalbero con radice di indice \textit{i} diventi un max-heap.

A ogni passo, viene determinato il più grande tra gli elementi $A[i]$, $A[\textsc{Left(\textit{i})}]$ e $A[\textsc{Right(\textit{i})}]$; il suo indice viene memorizzato in \textit{massimo}. Se $A[i]$ è più grande, allora il sottoalbero con radice nel nodo \textit{i} è un max-heap e la procedura termina. Altrimenti, uno dei due figli ha l'elemento più grande e $A[i]$ viene scambiato con $A[massimo]$; in questo modo, il nodo \textit{i} e i suoi figli soddisfano la proprietà del max-heap. Il nodo con indice \textit{massimo}, però, adesso ha il valore originale $A[i]$ e, quindi, il sottoalbero con radice in \textit{massimo} potrebbe violare la proprietà del max-heap. Di conseguenza, deve essere chiamata ricorsivamente la subroutine \textsc{Max-Heapify} per questo sottoalbero.\\\\
\textsc{Max-Heapify(\textit{A},\,\textit{i})}\\
1\firsttab\textit{l} $\leftarrow$ \textsc{Left(\textit{i})}\\
2\firsttab\textit{r} $\leftarrow$ \textsc{Right(\textit{i})}\\
3\firsttab\textbf{if} \textit{l} $\leq$ \textit{A.heap-size} and $A[l] > A[i]$\\
4\secondtab\textit{massimo} $\leftarrow$ \textit{l}\\
5\firsttab\textbf{else} \textit{massimo} $\leftarrow$ \textit{i}\\
6\firsttab\textbf{if} \textit{r} $\leq$ \textit{A.heap-size} and $A[r] > A[massimo]$\\
7\secondtab\textit{massimo} $\leftarrow$ \textit{r}\\
8\firsttab\textbf{if} \textit{massimo} $\neq$ \textit{i}\\
9\secondtab scambia $A[i]$ con $A[massimo]$\\
10\secondtab\textsc{Max-Heapify(\textit{A.massimo})}\\\\
Il tempo di esecuzione di \textsc{Max-Heapify} in un sottoalbero di dimensione \textit{n} con radice in un nodo \textit{i} è pari al tempo $\Theta(1)$ per sistemare le relazioni fra gli elementi $A[i]$, $A[\textsc{Left(\textit{i})}]$ e $A[\textsc{Right(\textit{i})}]$, più il tempo per eseguire \textsc{Max-Heapify} in un sottoalbero con radice in uno dei figli del nodo \textit{i}. I sottoalberi dei figli hanno ciascuno una dimensione che non supera $2n/3$ - il caso peggiore si verifica quando l'ultima riga dell'albero è piena esattamente a metà - e il tempo di esecuzione di \textsc{Max-Heapify} può quindi essere descritto dalla ricorrenza
\begin{equation*}
T(n) \leq T(2n/3) + \Theta(1)
\end{equation*}
La soluzione di questa ricorrenza, per il secondo caso del teorema dell'esperto, è $T(n) = O(lg\,n)$. In alternativa, si può indicare con $O(h)$ il tempo di esecuzione di \textsc{Max-Heapify} in un nodo di altezza \textit{h}.
\section{Costruire un heap}
Si può utilizzare la procedura \textsc{Max-Heapify} dal basso verso l'alto per convertire un array $A[1\,...\,n]$ con $n = A.length$, in un max-heap. Tutti gli elementi nel sottoarray $A[(\lfloor n/2 \rfloor + 1)\,...\,n]$ sono foglie dell'albero e quindi ciascuno di essi è un heap di un solo elemento che si può usare come punto di partenza. La procedura \textsc{Build-Max-Heap} attraversa i restanti nodi dell'albero ed esegue \textsc{Max-Heapify} in ciascuno di essi.\\\\
\textsc{Build-Max-Heap(\textit{A})}\\
1\firsttab\textit{A.heap-size} $\leftarrow$ \textit{A.length}\\
2\firsttab\textbf{for} \textit{i} = $\lfloor A.length / 2 \rfloor$ \textbf{downto} 1\\
3\secondtab\textsc{Max-Heapify(\textit{A},\,\textit{i})}\\\\
Per verificare che \textsc{Build-Max-Heap} funziona correttamente, si utilizza la seguente invariante di ciclo:
\begin{quote}
\textit{All'inizio di ogni iterazione del ciclo \textbf{for}, righe 2 - 3, ogni nodo $i + 1, i + 2,\,...\,,\,n$ è la radice di un max-heap} 
\end{quote}
Ogni chiamata di \textsc{Max-Heapify} costa un tempo $O(lg\,n)$ e ci sono $O(n)$ di queste chiamate. Quindi, il tempo di esecuzione è $O(n\,lg\,n)$.
\section{Code di priorità}
Una delle applicazioni più diffuse dell'heap consiste nell'implementazione delle code di priorità. Analogamente agli heap, ci sono due tipo di code di priorità: code di max-priorità e code di min-priorità.

Una \textbf{coda di priorità} è una struttura dati che serve a mantenere un insieme \textit{S} di elementi, ciascuno con un valore associato detto \textbf{chiave}. In particolare, una \textbf{coda di max-priorità} supporta le seguenti operazioni:
\begin{description}
\item\textsc{Insert(\textit{S},\,\textit{x})} inserisce l'elemento \textit{x} nell'insieme \textit{S}, che equivale all'operazione: $S = S \cup \{x\}$.
\item\textsc{Maximum(\textit{S})} restituisce l'elemento di \textit{S} con la chiave più grande.
\item\textsc{Extract-Max(\textit{S})} rimuove e restituisce l'elemento di \textit{S} con la chiave più grande.
\item\textsc{Increase-Key(\textit{S},\,\textit{x},\,\textit{k})} aumenta il valore della chiave dell'elemento \textit{x} al nuovo valore \textit{k}, che si suppone sia almeno grande quanto il valore corrente della chiave dell'elemento \textit{x}.
\end{description}
Tra le applicazioni delle code di max-priorità  vi è quella di programmare i lavori su un computer condiviso.

In alternativa, una \textbf{coda di min-priorità} supporta le operazioni \textsc{Insert}, \textsc{Minimum}, \textsc{Extract-Min} e \textsc{Decrease-Key}. Una coda di min-priorità può essere utilizzata in un simulatore controllato da eventi.

La procedura \textsc{Heap-Maximum} implementa l'operazione \textsc{Maximum} nel tempo $\Theta(1)$.\\\\
\textsc{Heap-Maximum(\textit{A})}\\
1\firsttab\textbf{return} \textit{A}[1]\\\\
La procedura \textsc{Heap-Extract-Max} implementa l'operazione \textsc{Extract-Max}.\\\\
\textsc{Heap-Extract-Max(\textit{A})}\\
1\firsttab\textbf{if} \textit{A.heap-size} $<$ 1\\
2\secondtab\textbf{error} "underflow dell'heap"\\
3\firsttab\textit{max} $\leftarrow$ \textit{A}[1]\\
4\firsttab\textit{A}[1] $\leftarrow$ \textit{A}[\textit{A.heap-size}]\\
5\firsttab\textit{A.heap-size} $\leftarrow$ \textit{A.heap-size} - 1\\
6\firsttab\textsc{Max-Heapify(\textit{A},\,1)}\\
7\firsttab\textbf{return} \textit{max}\\\\
Il tempo di esecuzione di \textsc{Heap-Extract-Max} è $O(lg\,n)$, perché svolge una quantità costante di lavoro oltre al tempo $O(lg\,n)$ di \textsc{Max-Heapify}.

\textsc{Heap-Increase-Key} implementa l'operazione \textsc{Increase-Key}. L'elemento della coda di priorità la cui chiave deve essere aumentata è identificato da un indice \textit{i} nell'array. Innanzitutto, la procedura aggiorna la chiave dell'elemento \textit{A}[\textit{i}] con il suo nuovo valore. Successivamente, poiché l'aumento della chiave di \textit{A}[\textit{i}] potrebbe violare la proprietà del max-heap, la procedura segue un cammino semplice da questo nodo verso la radice per trovare un posto appropriato alla nuova chiave. Durante questo attraversamento, \textsc{Heap-Increase-Key} confronta ripetutamente un elemento con suo padre e scambia le loro chiavi se la chiave dell'elemento è più grande; questa operazione termina se la chiave dell'elemento è più piccola, perché in questo caso la proprietà del max-heap è soddisfatta.\\\\
\textsc{Heap-Increase-Key(\textit{A},\,\textit{i},\,\textit{key})}\\
1\firsttab\textbf{if} \textit{key} $<$ \textit{A}[\textit{i}]\\
2\secondtab\textbf{error} "la nuova chiave è più piccola di quella corrente"\\
3\firsttab\textit{A}[\textit{i}] $\leftarrow$ \textit{key}\\
4\firsttab\textbf{while} \textit{i} $>$ 1 and \textit{A}[\textsc{Parent(\textit{i})}] $<$ \textit{A}[\textit{i}]\\
5\secondtab scambia \textit{A}[\textit{i}] con \textit{A}[\textsc{Parent(\textit{i})}]\\
6\secondtab\textit{i} $\leftarrow$ \textsc{Parent(\textit{i})}\\\\
Il tempo di esecuzione di \textsc{Heap-Increase-Key} con un heap di \textit{n} elementi è $O(lg\,n)$, in quanto il cammino verso la radice percorso dal nodo aggiornato nella riga 3 ha lunghezza $O(lg\,n)$.

La procedura \textsc{Max-Heap-Insert} implementa l'operazione \textsc{Insert}. Prende come input la chiave del nuovo elemento da inserire nel max-heap \textit{A}. La procedura prima espande il max-heap aggiungendo all'albero una nuova foglia la cui chiave è $-\infty$; poi chiama \textsc{Heap-Increase-Key} per impostare la chiave di questo nuovo nodo al su valore corretto e mantenere la proprietà del max-heap.\\\\
\textsc{Max-Heap-Insert(\textit{A},\,\textit{key})}\\
1\firsttab\textit{A.heap-size} $\leftarrow$ \textit{A.heap-size} + 1\\
2\firsttab\textit{A}[\textit{A.heap-size}] $\leftarrow -\infty$\\
3\firsttab\textsc{Heap-Increase-Key(\textit{A},\,\textit{A.heap-size},\,\textit{key})}\\\\
Il tempo di esecuzione della procedura \textsc{Max-Heap-Insert} con un heap di \textit{n} elementi è $O(lg\,n)$. In sintesi, un heap può svolgere ciascuna operazione con le code di priorità nel tempo $O(lg\,n)$ su un insieme di dimensione \textit{n}.
\chapter{Alberi di connessione minimi}
Dato un grafo connesso non orientato $G = (V,E)$, ad ogni arco $(u,v) \in E$ è associato un peso $w(u,v)$. Si vuole trovare un sottoinsieme aciclico $T \subseteq E$ che collega tutti i vertici, il cui peso totale
\begin{equation*}
w(T) = \sum_{(u,v) \in T}w(u,v)
\end{equation*}
sia minimo. Poiché \textit{T} è aciclico e collega tutti i vertici, deve anche formare un albero, che è detto \textbf{albero di connessione minimo} perché connette il grafo \textit{G} (può non essere unico). Il problema di trovare l'albero \textit{T} è detto \textbf{problema dell'albero di connessione minimo}. L' albero di connessione minimo ha $|V| - 1$ archi e non ha cicli.

Tra gli algoritmi che risolvono il problema dell'albero di connessione minimo ci sono l'algoritmo di Kruskal e l'algoritmo di Prim. Entrambi gli algoritmi possono essere eseguiti nel tempo $O(E\,lg\,V)$ utilizzando dei normali heap binari. I due algoritmi sono algoritmi golosi, ma applicano l'approccio goloso in modo differente. La strategia golosa prevede di fare la scelta che in quel particolare momento è ritenuta la migliore. In generale, questa strategia non garantisce che vengano trovate le soluzioni globalmente ottime per i sottoproblemi. Tuttavia, per il problema dell'albero di connessione minimo, è possibile dimostrare che alcune strategie golose forniscono un albero di connessione con peso minimo.
\section{Creare un albero di connessione minimo}
Si suppone di avere un grafo connesso non orientato $G = (V,E)$ con una funzione peso $w : E \rightarrow \mathbb{R}$ e di volere trovare un albero di connessione minimo per il grafo \textit{G}. La strategia golosa utilizzata dagli algoritmi di Kruskal e Prim può essere sintetizzata in un metodo generico che fa crescere l'albero di connessione minimo di un arco alla volta. Il metodo generico gestisce un insieme di archi \textit{A} (inizialmente $A = \emptyset$), conservando la seguente invariante di ciclo:
\begin{quote}
\textit{Prima di ogni iterazione, A è un sottoinsieme di qualche albero di connessione minimo}
\end{quote}
Ad ogni passo, si determina un arco $(u,v)$ che può essere aggiunto ad \textit{A} senza violare questa invariante, nel senso che $A \cup \{(u,v)\}$ è anche un sottoinsieme di un albero di connessione minimo. Tale arco è detto \textbf{arco sicuro} per \textit{A}, perché può essere tranquillamente aggiunto ad \textit{A} preservando l'invariante.\\\\
\textsc{Generic-MST(\textit{G},\,\textit{w})}\\
1\firsttab$A \leftarrow \emptyset$\\
2\firsttab\textbf{while} \textit{A} non forma un albero di connessione\\
3\secondtab trova un arco $(u,v)$ che è sicuro per \textit{A}\\
4\secondtab\textit{A} $\leftarrow A \cup \{(u,v)\}$ \\
5\firsttab\textbf{return} \textit{A}\\\\
Per verificare la sua correttezza si utilizza l'invariante di ciclo:
\begin{description}
\item[Inizializzazione]Dopo la riga 1, l'insieme \textit{A} soddisfa l'invariante di ciclo perché l'insieme vuoto è un sottoinsieme di MST (minimum spanning tree)
\item[Conservazione]Il ciclo nelle righe 2 - 4 conserva l'invariante perché aggiunge soltanto archi sicuri; quindi \textit{A} rimane un sottoinsieme di MST
\item[Conclusione]Tutti gli archi aggiunti ad \textit{A} si trovano in un albero di connessione minimo, quindi l'insieme \textit{A} restituito nella riga 5 deve essere un albero di copertura che è anche un albero di connessione minimo
\end{description}
Un arco sicuro deve esistere, perché quando viene eseguita la riga 3, l'invariante impone che ci sia un albero di connessione \textit{T} tale che $A \subseteq T$. All'interno del corpo del ciclo \textbf{while}, \textit{A} deve essere un sottoinsieme proprio di \textit{T}, quindi deve esistere un arco $(u,v) \in T$ tale che $(u,v) \not\in A$ e $(u,v)$ è un arco sicuro per \textit{A}.

Un \textbf{taglio} (\textit{S},\,\textit{V - S}) di un grafo connesso non orientato $G = (V,E)$ è una partizione di \textit{V} in due insiemi disgiunti \textit{S} e \textsc{S - V}, tra loro complementari. Si dice che un arco $(u,v) \in E$ \textbf{attraversa} il taglio (\textit{S},\,\textit{V - S}) se una delle sue estremità si trova in \textit{S} e l'altra in \textit{V - S}.

Si dice che un taglio \textbf{rispetta} un insieme \textit{A} di archi se nessun arco di \textit{A} attraversa il taglio. Un arco è un \textbf{arco leggero} per un taglio se il suo peso è minimo fra i pesi degli archi che attraversano il taglio. Ci possono essere più archi leggeri che attraversano un taglio nel caso di pesi uguali. Più in generale, un arco è un arco leggero per una data proprietà se il suo peso è il minimo fra tutti gli archi che soddisfano tale proprietà.
\begin{theorem}
Sia $G = (V,E)$ un grafo non orientato con una funzione peso \textit{w} a valori reali definita in \textit{E}. Sia \textit{A} un sottoinsieme di un qualche albero di connessione minimo per \textit{G}, sia (\textit{S},\,\textit{V - S}) un taglio qualsiasi di \textit{G} che rispetta \textit{A} e sia $(u,v)$ un arco leggero che attraversa (\textit{S},\,\textit{V - S}). Allora, l'arco $(u,v)$ è sicuro per \textit{A}.
\end{theorem}
\begin{proof}
Sia \textit{T} un albero di connessione minimo che contiene \textit{A}, si suppone che \textit{T} non contenga l'arco leggero $(u,v)$, perché se lo contenesse il teorema sarebbe dimostrato. Si costruisce un altro albero di connessione minimo $T'$ che include $A \cup \{(u,v)\}$, dimostrando così che $(u,v)$ è un arco sicuro per \textit{A}.

L'arco $(u,v)$ forma un ciclo con gli archi nel cammino semplice \textit{p} che va da \textit{u} a \textit{v} in \textit{T}. Poiché \textit{u} e \textit{v} si trovano su lati opposti del taglio (\textit{S},\,\textit{V - S}), c'è almeno un altro arco in \textit{T} che appartiene al cammino semplice \textit{p} e che attraversa il taglio. Sia $(x,y)$ uno di questi archi. L'arco $(x,y)$ non appartiene ad \textit{A}, perché il taglio rispetta \textit{A}. Poiché $(x,y)$ si trova nel cammino semplice unico da \textit{u} a \textit{v} in \textit{T}, eliminando $(x,y)$, l'albero \textit{T} si spezza in due componenti. Aggiungendo $(u,v)$, le due componenti si ricongiungono per formare un nuovo albero di connessione $T' = T - \{(x,y)\} \cup \{(u,v)\}$.

Si dimostra adesso che $T'$ è un albero di connessione minimo. Poiché $(u,v)$ è un arco leggero che attraversa (\textit{S},\,\textit{V - S}) e anche l'arco $(x,y)$ attraversa questo taglio, allora $w(u,v) \leq w(x,y)$. Quindi si ha:
\begin{align*}
w(T') &= w(T) - w(x,y) + w(u,v)\\
&\leq w(T)
\end{align*}
Ma \textit{T} è un albero di connessione minimo, quindi $w(T) \leq w(T')$; di conseguenza, anche $T'$ (che è un albero di copertura) deve essere un albero di connessione minimo.

Si deve ora dimostrare che $(u,v)$ è effettivamente un arco sicuro per \textit{A}. Si sa che $A \subseteq T'$, in quanto $A \subseteq T$ e $(x,y) \not\in A$; quindi $A \cup \{(u,v)\} \subseteq T'$. Di conseguenza, poiché $T'$  è un albero di connessione minimo, $(u,v)$ è un arco sicuro per \textit{A}.
\end{proof}
Durante l'esecuzione del metodo, l'insieme \textit{A} è sempre aciclico; altrimenti un albero di connessione minimo che include \textit{A} conterebbe un ciclo, e ciò sarebbe una contraddizione. In qualsiasi momento dell'esecuzione, il grafo $G_{A} = (V,A)$ è una foresta e ciascuna delle componenti connesse di $G_{A}$ è un albero (inizialmente sono solo dei nodi, via via si costruiscono gli alberi). Inoltre, qualsiasi arco sicuro $(u,v)$ per \textit{A} collega componenti distinte di $G_{A}$, perché $A \cup \{(u,v)\}$ deve essere aciclico.

Il ciclo \textbf{while} nelle righe 2 - 4 di \textsc{Generic-MST} viene eseguito $|V| - 1$ volte, in quanto i $|V| - 1$ archi di un albero di connessione minimo vengono determinati uno dopo l'altro. Inizialmente, quando $A = \emptyset$, ci sono $|V|$  alberi in $G_{A}$ e ogni iterazione riduce questo numero di uno. Quando la foresta contiene un albero soltanto, il metodo termina.
\begin{corollario}
Sia $G = (V,E)$ un grafo connesso non orientato con una funzione peso \textit{w} a valori reali definita in \textit{E}. Sia \textit{A} un sottoinsieme di \textit{E} che è contenuto in qualche albero di connessione minimo per \textit{G} e sia $C = (V_{C},E_{C})$ una componente connessa (un albero) nella foresta $G_{A} = (V,A)$. Se $(u,v)$ è un arco leggero che collega \textit{C} a qualche altra componente in $G_{A}$, allora $(u,v)$ è sicuro per \textit{A}.
\end{corollario}
\begin{proof}
Il taglio $(V_{C},\,V - V_{C})$ rispetta \textit{A} e $(u,v)$ è un arco leggero per questo taglio. Quindi $(u,v)$ è sicuro per \textit{A}.
\end{proof}
\section{Algoritmo di Kruskal}
Gli algoritmi di Kruskal e Prim (elaborazioni del metodo generico) usano una regola specifica per determinare un arco sicuro nella riga 3 di \textsc{Generic-MST}. In Kruskal l'insieme \textit{A} è una foresta i cui vertici sono tutti quelli del grafo. L'arco sicuro aggiunto ad \textit{A} è sempre un arco di peso minimo nel grafo che collega due componenti distinte. In Prim l'insieme \textit{A} è sempre un arco di peso minimo che collega l'albero con un vertice che non appartiene all'albero. 

L'algoritmo di Kruskal trova un arco sicuro da aggiungere alla foresta in costruzione scegliendo, fra tutti gli archi che collegano due alberi qualsiasi nella foresta, un arco $(u,v)$ di peso minimo. Si indicano con $C_1$ e $C_2$ i due alberi che sono collegati da $(u,v)$. Poiché $(u,v)$ deve essere un arco leggero che collega $C_1$ a qualche altro albero, il corollario $(19.1)$ implica che $(u,v)$ è un arco sicuro per $C_1$. L'algoritmo di Kruskal è un algoritmo goloso, perché a ogni passo aggiunge alla foresta un arco con il minor peso possibile.

Usa una struttura dati per insiemi disgiunti per mantenere vari insiemi disgiunti di elementi. Ogni insieme contiene i vertici di un albero della foreste corrente. L'operazione \textsc{Find-Set(\textit{u})} restituisce un rappresentante dell'insieme che contiene \textit{u}. Quindi, si può determinare se due vertici \textit{u} e \textit{v} appartengono allo stesso albero verificando se \textsc{Find-Set(\textit{u})}è uguale a \textsc{Find-Set(\textit{v})}. L'unione degli alberi è effettuata dalla procedura \textsc{Union}.\\\\
\textsc{MST-Kruskal(\textit{G},\,\textit{w})}\\
1\firsttab\textit{A} $\leftarrow \emptyset$\\
2\firsttab\textbf{for} ogni vertice $v \in G.V$\\
3\secondtab\textsc{Make-Set(\textit{v})}\\
4\firsttab ordina gli archi di \textit{G.E} in senso non decrescente rispetto al peso \textit{w}\\
5\firsttab\textbf{for} ogni arco $(u,v) \in G.E$, preso in ordine di peso non decrescente\\
6\secondtab\textbf{if} \textsc{Find-Set(\textit{u})} $\neq$ \textsc{Find-Set(\textit{v})}\\
7\thirdtab\textit{A} $\leftarrow A \cup \{(u,v)\}$\\
8\thirdtab\textsc{Union(\textit{u},\,\textit{v})}\\
9\firsttab\textbf{return} \textit{A}\\\\
Commenti:
\begin{enumerate}
\item[3]Crea una componente connessa per ogni vertice
\item[4]Se alcuni hanno lo stesso peso stanno nello stesso insieme
\item[6]Se fosse uguale non sarebbe più un albero
\end{enumerate}
Si potrebbe aggiungere un test per fermarsi dopo $|V| - 1$ operazioni \textsc{Union}. Le righe 1 - 3 inizializzano l'insieme \textit{A} come un insieme vuoto e creano $|V|$ alberi, uno per ogni vertice. Il ciclo \textbf{for} nelle righe 5 - 8 esamina gli archi nell'ordine dal più leggero al più pesante. Il ciclo verifica, per ogni arco $(u,v)$, se l'estremità \textit{u} e \textit{v} appartengono allo stesso albero; in caso affermativo, l'arco $(u,v)$ non può essere aggiunto alla foresta senza generare un ciclo, quindi l'arco viene scartato. Altrimenti, i due vertici appartengono ad alberi differenti. In questo caso, l'arco $(u,v)$ viene aggiunto ad \textit{A} nella riga 7 e i vertici dei due alberi vengono fusi nella riga 8. L'inizializzazione dell'insieme \textit{A}  nella riga 1 richiede un tempo $O(1)$; il tempo per ordinare gli archi nella riga 4 è $O(E\,lg\,E)$. Il ciclo \textbf{for} nelle righe 5 - 8 esegue $O(E)$ operazioni \textsc{Find-Set} e \textsc{Union} sulla foresta degli insiemi disgiunti. Si tiene conto anche delle $|V|$ operazioni \textsc{Make-Set}. Si ottiene un tempo totale pari a $O(E\,lg\,V)$.
\section{Algoritmo di Prim}
L'algoritmo di Prima ha la proprietà che gli archi nell'insieme \textit{A} formano sempre un albero singolo. L'albero inizia da un arbitrario vertice radice \textit{r} e si sviluppa fino a coprire tutti i vertici in \textit{V}.A ogni passo viene aggiunto all'albero \textit{A} un arco leggero che collega \textit{A} con un vertice isolato - un vertice che non sia estremo di qualche arco in \textit{A}. Per il corollario $(19.1)$, questa regola aggiunge soltanto gli archi che sono sicuri per \textit{A}; cosicché, quando l'algoritmo termina, gli archi in \textit{A} formano un albero di connessione minimo. Questa strategia è golosa perché l'albero cresce includendo ad ogni passo un arco che contribuisce con la quantità più piccola possibile a formare il peso dell'albero.

Nella procedura \textsc{MST-Prim}, il grafo connesso \textit{G} e la radice \textit{r} dell'albero di connessione minimo da costruire sono gli input per l'algoritmo. Durante l'esecuzione dell'algoritmo, tutti i vertici che non si trovano nell'albero risiedono in una coda di min-priorità \textit{Q} basata su un campo \textit{key}. Per ogni vertice \textit{v}, l'attributo \textit{v.key} è il peso minimo di un arco qualsiasi che collega \textit{v} a un vertice nell'albero; per convenzione, $v.key = \infty$ se tale arco non esiste. L'attributo $v.\pi$ indica il padre di \textit{v} nell'albero. Quando l'algoritmo termina, la coda di min-priorità \textit{Q} è vuota.\\\\
\textsc{MST-Prim(\textit{G},\,\textit{w},\,\textit{r})}\\
1\firsttab\textbf{for} ogni $u \in G.V$\\
2\secondtab\textit{u.key} $\leftarrow \infty$\\
3\secondtab\textit{u.}$\pi \leftarrow$ \textsc{nil}\\
4\firsttab\textit{r.key} $\leftarrow$ 0\\
5\firsttab\textit{Q} $\leftarrow$ \textit{G.V}\\
6\firsttab\textbf{while} \textit{Q} $\neq \emptyset$\\
7\secondtab\textit{u} $\leftarrow$ \textsc{Extract-Min(\textit{Q})}\\
8\secondtab\textbf{for} ogni $v \in G.Adj[u]$\\
9\thirdtab\textbf{if} $v \in Q$ and $w(u,v) < v.key$\\
10\fourthtab\textit{v.}$\pi \leftarrow u$\\
11\fourthtab\textit{v.key} $\leftarrow w(u,v)$\\\\
Commenti:
\begin{enumerate}
\item[3]Peso minimo per raggiungere ciascun vertice dell'insieme (albero)
\item[4]All'inizio nessun vertice è raggiungibile, sono quindi tutti $\infty$
\item[7]Alla prima iterazione estrae la radice \textit{r}
\end{enumerate}
Le righe 1 - 5 impostano la chiave di ciascun vertice a $\infty$ ad eccezione della radice \textit{r}, la cui chiave è impostata a 0 (in questo modo la radice sarà il primo vertice ad essere elaborato), assegnano al padre di ciascun vertice il valore \textsc{nil} e inizializzano la coda di min-priorità \textit{Q} in modo che contenga tutti i vertici. La riga 7 identifica un vertice $u \in Q$ incidente su un arco leggero che attraversa la taglio (\textit{V - Q},\,\textit{Q}) (ad eccezione della prima iterazione in cui $u = r$ per la riga 4). Quando il vertice \textit{u} viene eliminato dall'insieme \textit{Q}, viene aggiunto all'insieme $V - Q$ dei vertici dell'albero, quindi $(u,\,u.\pi)$ viene aggiunto ad \textit{A}. Il ciclo \textbf{for} nelle righe 8 - 11 aggiorna i campi \textit{key} e $\pi$ di qualsiasi vertice \textit{v} adiacente a \textit{u}, ma che non appartiene all'albero.

Le prestazioni dell'algoritmo di Prim dipendono dal modo in cui viene implementata la coda di min-priorità \textit{Q}. Se \textit{Q} è implementata come un min-heap binario, si può utilizzare la procedura \textsc{Build-Min-Heap} per eseguire nel tempo $O(V)$ l'inizializzazione nelle righe 1 - 5. Il corpo del ciclo \textbf{while} viene eseguito $|V|$ volte e, poiché ogni operazione \textsc{Extract-Min}, \textsc{Decrease-Key} e \textsc{Insert} richiedono un tempo $O(lg\,V)$, il tempo totale per tutte le chiamate di \textsc{Extract-Min} è $O(V\,lg\,V)$. Il ciclo \textbf{for} (righe 8 - 11) viene eseguito $O(E)$ volte complessivamente, in quanto la somma delle lunghezze di tutte le liste di adiacenza è $2|E|$. L'assegnazione nella riga 11 richiede implicitamente un'operazione \textsc{Decrease-Key} sul min-heap (eseguita al massimo $|E|$ volte), che può essere implementata con un min-heap binario nel tempo $O(lg\,V)$. Quindi, il tempo totale dell'algoritmo di Prim è $O(V\,lg\,V + E\,lg\,V) = O(E\,lg\,V)$, che è asintoticamente uguale a quello dell'implementazione di Kruskal.

L'algoritmo di Prim conserva la seguente invariante di ciclo:
\begin{quote}
\textit{Prima di ogni iterazione del ciclo \textbf{while} (righe 6 - 11)}:
\begin{itemize}
\item$A = \{ (v,\,v,\pi) : v \in V - \{r\} - Q\}$
\item I vertici già inseriti nell'albero di connessione minimo sono quelli che appartengono a $V - Q$
\item Per ogni vertice $v \in Q$, se $v.\pi \neq \textsc{nil}$, allora $v.key < \infty$ e \textit{v.key} è il peso di un arco leggero $(v,\,v,\pi)$ che collega \textit{v} a qualche vertice che si trova già nell'albero di connessione minimo (insieme \textit{A})
\end{itemize}
Alla fine, $V_A = V$, quindi $Q = \emptyset$. e l'albero di connessione minimo è $A = \{ (v,\,v,\pi) : v \in V - \{r\} \}$.
\end{quote}
\end{document}
